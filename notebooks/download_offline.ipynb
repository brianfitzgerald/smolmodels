{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brianfitzgerald/Documents/GitHub/smolmodels/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "os.environ[\"HF_HUB_ENABLE_HF_TRANSFER\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading maximedb/twentyquestions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 5 files: 100%|██████████| 5/5 [00:00<00:00,  5.76it/s]\n",
      " 25%|██▌       | 1/4 [00:01<00:03,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/brianfitzgerald/.cache/huggingface/hub/datasets--maximedb--twentyquestions/snapshots/51fd75a81f7b31a9fed289ec82c6352980854d50\n",
      "Downloading metaeval/twentyquestions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 4 files: 100%|██████████| 4/4 [00:02<00:00,  1.42it/s]\n",
      " 50%|█████     | 2/4 [00:04<00:04,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/brianfitzgerald/.cache/huggingface/hub/datasets--metaeval--twentyquestions/snapshots/1a32ab90a6fa1a6ac03e5a2fb494a00f08ef5cad\n",
      "Downloading davidfant/natural-questions-chunk-20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 12 files: 100%|██████████| 12/12 [02:19<00:00, 11.66s/it]\n",
      " 75%|███████▌  | 3/4 [02:24<01:05, 65.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/brianfitzgerald/.cache/huggingface/hub/datasets--davidfant--natural-questions-chunk-20/snapshots/abe895987203841705ddd23972f8e288d065a9c9\n",
      "Downloading zed-industries/zeta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 617 files: 100%|██████████| 617/617 [00:24<00:00, 25.65it/s]\n",
      "100%|██████████| 4/4 [02:48<00:00, 42.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/brianfitzgerald/.cache/huggingface/hub/datasets--zed-industries--zeta/snapshots/8f7e77b7dddf5b21d36bd04f054400451eecf7f7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for dataset_name in tqdm(\n",
    "    [\n",
    "        # \"lara-martin/FIREBALL\",\n",
    "        # \"MinervaAI/Aesir-Preview\",\n",
    "        # \"hieunguyenminh/roleplay\",\n",
    "        # \"chargoddard/rpguild\",\n",
    "        # \"jondurbin/cinematika-v0.1\",\n",
    "        # \"codeparrot/apps\",\n",
    "        # \"glaiveai/glaive-code-assistant-v3\",\n",
    "        # \"jondurbin/py-dpo-v0.1\",\n",
    "        # \"lemonilia/roleplaying-forums-raw\",\n",
    "        # \"deepmind/code_contests\",\n",
    "        # \"SenseLLM/ReflectionSeq-DS\",\n",
    "        # \"openai/openai_humaneval\",\n",
    "        # \"argilla/distilabel-intel-orca-dpo-pairs\",\n",
    "        # \"Squish42/bluemoon-fandom-1-1-rp-cleaned\",\n",
    "        # \"SaylorTwift/Gutenberg\",\n",
    "        # 20 questions\n",
    "        \"maximedb/twentyquestions\",\n",
    "        \"metaeval/twentyquestions\",\n",
    "        \"davidfant/natural-questions-chunk-20\",\n",
    "        \"zed-industries/zeta\"\n",
    "    ]\n",
    "):\n",
    "    # run this fn to get the local directory of the dataset\n",
    "    print(\"Downloading\", dataset_name)\n",
    "    print(snapshot_download(dataset_name, repo_type=\"dataset\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HuggingFaceTB/SmolLM2-135M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 10 files: 100%|██████████| 10/10 [00:00<00:00, 166440.63it/s]\n",
      " 17%|█▋        | 1/6 [00:00<00:00,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/brianfitzgerald/.cache/huggingface/hub/models--HuggingFaceTB--SmolLM2-135M/snapshots/93efa2f097d58c2a74874c7e644dbc9b0cee75a2\n",
      "Qwen/Qwen2.5-0.5B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 10 files: 100%|██████████| 10/10 [00:00<00:00, 163840.00it/s]\n",
      " 33%|███▎      | 2/6 [00:00<00:00,  6.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/brianfitzgerald/.cache/huggingface/hub/models--Qwen--Qwen2.5-0.5B/snapshots/060db6499f32faf8b98477b0a26969ef7d8b9987\n",
      "Qwen/Qwen2.5-0.5B-Instruct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 10 files: 100%|██████████| 10/10 [00:00<00:00, 39643.71it/s]\n",
      " 50%|█████     | 3/6 [00:00<00:00,  7.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/brianfitzgerald/.cache/huggingface/hub/models--Qwen--Qwen2.5-0.5B-Instruct/snapshots/7ae557604adf67be50417f59c2c2f167def9a775\n",
      "HuggingFaceTB/SmolLM2-135M-Instruct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 21 files: 100%|██████████| 21/21 [00:00<00:00, 356600.74it/s]\n",
      " 67%|██████▋   | 4/6 [00:00<00:00,  8.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/brianfitzgerald/.cache/huggingface/hub/models--HuggingFaceTB--SmolLM2-135M-Instruct/snapshots/e2c3f7557efbdec707ae3a336371d169783f1da1\n",
      "Qwen/Qwen2.5-3B-Instruct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 12 files: 100%|██████████| 12/12 [00:00<00:00, 221725.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/brianfitzgerald/.cache/huggingface/hub/models--Qwen--Qwen2.5-3B-Instruct/snapshots/aa8e72537993ba99e69dfaafa59ed015b17504d1\n",
      "mistralai/Ministral-8B-Instruct-2410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Fetching 16 files: 100%|██████████| 16/16 [00:00<00:00, 259107.58it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00,  8.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/brianfitzgerald/.cache/huggingface/hub/models--mistralai--Ministral-8B-Instruct-2410/snapshots/4847e87e5975a573a2a190399ca62cd266c899ad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "for model_name in tqdm(\n",
    "    [\n",
    "        \"HuggingFaceTB/SmolLM2-135M\",\n",
    "        \"Qwen/Qwen2.5-0.5B\",\n",
    "        \"Qwen/Qwen2.5-0.5B-Instruct\",\n",
    "        \"HuggingFaceTB/SmolLM2-135M-Instruct\",\n",
    "        \"Qwen/Qwen2.5-3B-Instruct\",\n",
    "        \"mistralai/Ministral-8B-Instruct-2410\"\n",
    "    ]\n",
    "):\n",
    "    print(model_name)\n",
    "    print(snapshot_download(model_name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "import gc\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from trl_wrapper.trainer_wrapper import TrainerWrapper, WrapperConfig, SMOL_LM_135M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = WrapperConfig(\n",
    "    model_id_or_path=SMOL_LM_135M,\n",
    "    max_samples=1000,\n",
    "    data_module_choice=\"conversation\",\n",
    "    notebook_mode=True,\n",
    "    tuning_mode=\"sft\",\n",
    "    eval_data_mode=\"fixed\",\n",
    ")\n",
    "\n",
    "wrapper = TrainerWrapper(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapper.init_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "! echo $CUDA_VISIBLE_DEVICES\n",
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-01-01 20:59:56.902\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmodel.utils\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m105\u001b[0m - \u001b[1mCache dir: ../dataset_caches/conversation_data_module\u001b[0m\n",
      "\u001b[32m2025-01-01 20:59:56.904\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmodel.utils\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m123\u001b[0m - \u001b[1mLoading dataset for stage fit\u001b[0m\n",
      "\u001b[32m2025-01-01 20:59:56.904\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmodel.utils\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m125\u001b[0m - \u001b[1mProcessing dataset for stage fit, workers: 1, cache dir ../dataset_caches/conversation_data_module\u001b[0m\n",
      "\u001b[32m2025-01-01 20:59:56.904\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset.code\u001b[0m:\u001b[36mload_dataset\u001b[0m:\u001b[36m167\u001b[0m - \u001b[1mLoading dataset\u001b[0m\n",
      "Parameter 'function'=<bound method ConversationDataModule.process_samples_batch_sft of <dataset.code.ConversationDataModule object at 0x305e84d10>> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n",
      "Map: 100%|██████████| 2700/2700 [00:09<00:00, 270.77 examples/s]\n",
      "Map: 100%|██████████| 300/300 [00:01<00:00, 269.88 examples/s]\n"
     ]
    }
   ],
   "source": [
    "wrapper.init_data_module()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapper.data_module.load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer dev\n",
    "tokenized = wrapper.data_module.tokenize_conversation([wrapper.data_module.train_dataset[0][\"conversation\"]])\n",
    "for k in tokenized.keys():\n",
    "    tokenized[k] = torch.as_tensor(tokenized[k], dtype=torch.long)\n",
    "wrapper.data_module.visualize_sample(tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapper.init_trainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapper.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

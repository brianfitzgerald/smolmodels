{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydantic\n",
    "import sys\n",
    "from pydantic import BaseModel\n",
    "from datasets import load_dataset\n",
    "import asyncio\n",
    "from synthetic_data.generation import RemoteModel, get_generation_wrapper\n",
    "\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from trl_wrapper.trainer_wrapper import TrainerWrapper, PLAYWRIGHT_CONFIG, SMOL_LM_135M\n",
    "\n",
    "dataset = load_dataset(\"PygmalionAI/PIPPA\", \"pippa_deduped\", trust_remote_code=True)[\n",
    "    \"train\"\n",
    "]\n",
    "dataset_pl = dataset.to_polars()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Sequence\n",
    "from openai.types.chat.chat_completion_message_param import ChatCompletionMessageParam\n",
    "from synthetic_data.screenplay_parser import Scene\n",
    "\n",
    "\n",
    "def format_conversation_oai(sample: dict) -> Sequence[ChatCompletionMessageParam]:\n",
    "    # TODO handle interpolation and character intros\n",
    "    conversation, bot_name = sample[\"conversation\"], sample[\"bot_name\"]\n",
    "    out_conv: Sequence[dict] = []\n",
    "    for msg, is_human in zip(conversation[\"message\"], conversation[\"is_human\"]):\n",
    "        out_conv.append({\"role\": bot_name if not is_human else \"User\", \"content\": msg})\n",
    "\n",
    "    return [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"Extract the dialogue, actions, and descriptions from the conversation given by the user.\",\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": json.dumps(out_conv)},\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from synthetic_data.generation import GenWrapperArgs\n",
    "from typing import List\n",
    "from enum import Enum\n",
    "\n",
    "\n",
    "\n",
    "class SceneElementType(Enum):\n",
    "    SCENE_HEADING = \"scene_heading\"\n",
    "    ACTION = \"action\"\n",
    "    DIALOGUE = \"dialogue\"\n",
    "    TRANSITION = \"transition\"\n",
    "\n",
    "\n",
    "class SceneElement(BaseModel):\n",
    "    type: SceneElementType\n",
    "    content: str\n",
    "    character: str | None = None\n",
    "\n",
    "class Output(BaseModel):\n",
    "    items: List[SceneElement]\n",
    "\n",
    "model: str = RemoteModel.GPT_4O_MINI.value\n",
    "generation_wrapper = get_generation_wrapper(model, GenWrapperArgs(response_format=Output)) # type: ignore\n",
    "\n",
    "conv = format_conversation_oai(dataset[5])\n",
    "\n",
    "completions = await generation_wrapper.generate([conv])\n",
    "print(completions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.loads(completions[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

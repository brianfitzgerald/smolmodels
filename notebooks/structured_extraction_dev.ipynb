{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from datasets import load_dataset\n",
    "import polars as pl\n",
    "from IPython.display import Markdown\n",
    "import tiktoken\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from synthetic_data.tasks import _process_gutenberg_row\n",
    "from datasets import Dataset\n",
    "from synthetic_data.tasks import Output, SceneElementType\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\n",
    "    \"sam-paech/gutenberg3-generalfiction-scifi-fantasy-romance-adventure-dpo\",\n",
    "    trust_remote_code=True,\n",
    ")[\"train\"]\n",
    "dataset_pl: pl.DataFrame = dataset.to_polars()\n",
    "tiktoken_encoder = tiktoken.get_encoding(\"o200k_base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = []\n",
    "for i, row in enumerate(dataset_pl.head(10).iter_rows(named=True)):\n",
    "    source = row[\"source\"]\n",
    "    display(Markdown(f\"### Sample {i} - {source}\"))\n",
    "    row_processed = _process_gutenberg_row(row, tiktoken_encoder)\n",
    "    display(\n",
    "        Markdown(\n",
    "            f\"#### Original ({row_processed['encoded_length']} tokens) \\n {row_processed['text']}\"\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_pq = pl.read_parquet(\"../screenplay_scenes_summarized_full.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_pq[\"prompt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in formatted_pq[1000:1010].iter_rows(named=True):\n",
    "    output_obj = Output.model_validate_json(row[\"output\"])\n",
    "    for element in output_obj.items:\n",
    "        fmt_str = f\"{element.type.name} - {element.character}\"\n",
    "        if element.type == SceneElementType.DIALOGUE:\n",
    "            fmt_str = f\"**{element.character}**: {element.content}\"\n",
    "        elif element.type == SceneElementType.ACTION:\n",
    "            fmt_str = f\"*{element.content}*\"\n",
    "        else:\n",
    "            fmt_str = f\"{element.type.name} - {element.content}\"\n",
    "        display(Markdown(fmt_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_pq_dataset = Dataset.from_polars(formatted_pq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 10256/10256 [00:00<00:00, 15693.16 examples/s]\n",
      "Map: 100%|██████████| 9190/9190 [00:01<00:00, 5836.30 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from openai.types.chat.chat_completion_message_param import ChatCompletionMessageParam\n",
    "\n",
    "\n",
    "def _gutenberg_to_conversation(row: dict):\n",
    "    conv: list[ChatCompletionMessageParam] = [\n",
    "        {\"role\": \"user\", \"content\": row[\"prompt\"]},\n",
    "    ]\n",
    "    output_obj = Output.model_validate_json(row[\"output\"])\n",
    "    formatted_screenplay = []\n",
    "    for item in output_obj.items:\n",
    "        if item.type == SceneElementType.DIALOGUE:\n",
    "            formatted_screenplay.append(f\"**{item.character}**: {item.content}\")\n",
    "        elif item.type == SceneElementType.ACTION:\n",
    "            formatted_screenplay.append(f\"*{item.content}*\")\n",
    "        else:\n",
    "            formatted_screenplay.append(item.content)\n",
    "    conv.append({\"role\": \"assistant\", \"content\": \"\\n\".join(formatted_screenplay)})\n",
    "\n",
    "    out = {\"conversation\": conv}\n",
    "    for k in (\"category\", \"prompt\", \"author\", \"title\"):\n",
    "        out[k] = row[k]\n",
    "    return out\n",
    "\n",
    "\n",
    "def _filter_gutenberg_row(row: dict):\n",
    "    try:\n",
    "        output_obj = Output.model_validate_json(row[\"output\"])\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return False\n",
    "    if len(output_obj.items) < 5:\n",
    "        return False\n",
    "    n_dialogue, n_action = 0, 0\n",
    "    for item in output_obj.items:\n",
    "        if item.type == SceneElementType.DIALOGUE:\n",
    "            n_dialogue += 1\n",
    "        elif item.type == SceneElementType.ACTION:\n",
    "            n_action += 1\n",
    "\n",
    "    if n_action < 2 or n_dialogue < 2:\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "_gutenberg_to_conversation(formatted_pq[1000].to_dicts()[0])\n",
    "formatted_pq_dataset.filter(_filter_gutenberg_row).map(\n",
    "    _gutenberg_to_conversation, remove_columns=[\"chosen\", \"rejected\", \"source\", \"text\"],\n",
    ").to_pandas().to_parquet(\"../dataset_files/gutenberg_conversations.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brianfitzgerald/Documents/GitHub/smolmodels/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-03-27 21:08:32,464\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "\u001b[32m2025-03-27 21:08:32.857\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtrl_wrapper.trainer_wrapper\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m264\u001b[0m - \u001b[1mSetting padding side to: right\u001b[0m\n",
      "\u001b[32m2025-03-27 21:08:32.858\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtrl_wrapper.trainer_wrapper\u001b[0m:\u001b[36minit_data_module\u001b[0m:\u001b[36m315\u001b[0m - \u001b[1mUsing chat template override: llama3\u001b[0m\n",
      "\u001b[32m2025-03-27 21:08:32.858\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtrl_wrapper.wrapper_config\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1mCache dir: ../dataset_caches/connections_data_module\u001b[0m\n",
      "Map: 100%|██████████| 353/353 [00:00<00:00, 14565.70 examples/s]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from model.reasoning import ConnectionsDataModule\n",
    "from trl_wrapper.trainer_wrapper import TrainerWrapper, GRPO_MATH_CONFIG, GRPO_CONNECTIONS_CONFIG\n",
    "from trl_wrapper.wrapper_config import DatasetConfig\n",
    "from IPython.display import display\n",
    "\n",
    "wrapper = TrainerWrapper(GRPO_CONNECTIONS_CONFIG)\n",
    "\n",
    "wrapper.init_data_module()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample = data_module.train_dataset[0]\n",
    "# sample\n",
    "wrapper.data_module.train_dataset\n",
    "first_sample = wrapper.data_module.train_dataset[0]\n",
    "\n",
    "conv = first_sample['prompt']\n",
    "fake_thoughts = \"<reasoning>\\nFirst four are academic\\n</reasoning>\\n\"\n",
    "fake_response = {'role': \"assistant\", 'content': fake_thoughts + first_sample['answer'] + \"\\n\"}\n",
    "# conv = [*conv, {'role': \"assistant\", 'content': first_sample['answer']}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['dope', 'scoop', 'skinny', 'word'],\n",
       " ['con', 'dupe', 'fool', 'trick'],\n",
       " ['cant', 'lean', 'list', 'slope'],\n",
       " ['boob', 'eggshell', 'giggle', 'hello']]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print(fake_response['content'])\n",
    "display(first_sample['answer_formatted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-03-27 21:10:04.022\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmodel.reasoning\u001b[0m:\u001b[36mxmlcount_reward_func\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mXML count rewards: [0.25]\u001b[0m\n",
      "\u001b[32m2025-03-27 21:10:04.023\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmodel.reasoning\u001b[0m:\u001b[36mstrict_format_reward_func\u001b[0m:\u001b[36m107\u001b[0m - \u001b[1mStrict format rewards: [0.0]\u001b[0m\n",
      "\u001b[32m2025-03-27 21:10:04.023\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmodel.reasoning\u001b[0m:\u001b[36mconnections_reward_func\u001b[0m:\u001b[36m175\u001b[0m - \u001b[1mModel generations: ['<reasoning>\\nFirst four are academic\\n</reasoning>\\n<answer><group>dope, scoop, skinny, word</group>\\n<group>con, dupe, fool, trick</group>\\n<group>cant, lean, list, slope</group>\\n<group>boob, eggshell, giggle, hello</group></answer>\\n']\u001b[0m\n",
      "\u001b[32m2025-03-27 21:10:04.023\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmodel.reasoning\u001b[0m:\u001b[36mconnections_reward_func\u001b[0m:\u001b[36m177\u001b[0m - \u001b[1mGroups: [[['dope', 'scoop', 'skinny', 'word'], ['con', 'dupe', 'fool', 'trick'], ['cant', 'lean', 'list', 'slope'], ['boob', 'eggshell', 'giggle', 'hello']]]\u001b[0m\n",
      "\u001b[32m2025-03-27 21:10:04.023\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmodel.reasoning\u001b[0m:\u001b[36mconnections_reward_func\u001b[0m:\u001b[36m179\u001b[0m - \u001b[1mConnections scores: [4.0]\u001b[0m\n",
      "\u001b[32m2025-03-27 21:10:04.023\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmodel.reasoning\u001b[0m:\u001b[36mgroup_size_reward_func\u001b[0m:\u001b[36m188\u001b[0m - \u001b[1mGroup size rewards: [0.5]\u001b[0m\n",
      "\u001b[32m2025-03-27 21:10:04.024\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmodel.reasoning\u001b[0m:\u001b[36mn_groups_reward_func\u001b[0m:\u001b[36m196\u001b[0m - \u001b[1mNumber of groups rewards: [0.5]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "for reward_func in wrapper.data_module.reward_functions():\n",
    "    rew = reward_func([conv], [[fake_response]], answer=first_sample['answer_formatted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

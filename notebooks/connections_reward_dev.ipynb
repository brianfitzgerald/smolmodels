{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-03 21:34:50.433\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtrl_wrapper.trainer_wrapper\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m305\u001b[0m - \u001b[1mSetting padding side to: right\u001b[0m\n",
      "\u001b[32m2025-04-03 21:34:50.433\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtrl_wrapper.trainer_wrapper\u001b[0m:\u001b[36minit_data_module\u001b[0m:\u001b[36m356\u001b[0m - \u001b[1mUsing chat template override: ministral\u001b[0m\n",
      "\u001b[32m2025-04-03 21:34:50.434\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtrl_wrapper.wrapper_config\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m134\u001b[0m - \u001b[1mCache dir: ../dataset_caches/connections_data_module\u001b[0m\n",
      "Map: 100%|██████████| 100000/100000 [00:04<00:00, 20089.44 examples/s]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from model.reasoning import ConnectionsDataModule\n",
    "from trl_wrapper.trainer_wrapper import TrainerWrapper, GRPO_MATH_CONFIG, GRPO_CONNECTIONS_CONFIG\n",
    "from trl_wrapper.wrapper_config import DatasetConfig\n",
    "from IPython.display import display\n",
    "\n",
    "wrapper = TrainerWrapper(GRPO_CONNECTIONS_CONFIG)\n",
    "\n",
    "wrapper.init_data_module()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'groups': [{'reason': 'defeat badly',\n",
       "   'words': ['crush', 'rout', 'shellac', 'trash']},\n",
       "  {'reason': 'tops', 'words': ['cami', 'halter', 'tank', 'tee']},\n",
       "  {'reason': 'butt', 'words': ['bottom', 'buns', 'seat', 'tail']},\n",
       "  {'reason': 'kinds of whales', 'words': ['blue', 'fin', 'gray', 'right']}],\n",
       " 'words': ['crush',\n",
       "  'rout',\n",
       "  'shellac',\n",
       "  'trash',\n",
       "  'cami',\n",
       "  'halter',\n",
       "  'tank',\n",
       "  'tee',\n",
       "  'bottom',\n",
       "  'buns',\n",
       "  'seat',\n",
       "  'tail',\n",
       "  'blue',\n",
       "  'fin',\n",
       "  'gray',\n",
       "  'right'],\n",
       " 'prompt': [{'content': '\\nYou are an expert puzzle solving model.\\nFind groups of words that are related to each other. Each group is four words long. There are exactly four groups in total.\\nYou may only use each word in one group.\\nRespond in the following format:\\n<reasoning>\\n...\\n</reasoning>\\n<answer>\\n<group>\\n...\\n</group>\\n<group>\\n...\\n</group>\\n</answer>\\n\\n# Example\\n\\nUser: apple, orange, banana, pear, corolla, charger,\\nAssistant: <reasoning>\\nThe first group are all fruits.\\nThe second group are all cars.\\n</reasoning>\\n<answer>\\n<group>apple, orange, banana, pear</group>\\n<group>corolla, charger</group>\\n</answer>\\n\\n# Example\\n\\nUser: dog, cat, red, white,\\nAssistant: <reasoning>\\nThe first group are all animals.\\nThe second group are all colors.\\n</reasoning>\\n<answer>\\n<group>dog, cat</group>\\n<group>red, white</group>\\n</answer>\\n',\n",
       "   'role': 'system'},\n",
       "  {'content': 'crush, rout, shellac, trash, cami, halter, tank, tee, bottom, buns, seat, tail, blue, fin, gray, right',\n",
       "   'role': 'user'}],\n",
       " 'answer': '<answer><group>crush, rout, shellac, trash</group>\\n<group>cami, halter, tank, tee</group>\\n<group>bottom, buns, seat, tail</group>\\n<group>blue, fin, gray, right</group></answer>',\n",
       " 'answer_groups': [['crush', 'rout', 'shellac', 'trash'],\n",
       "  ['cami', 'halter', 'tank', 'tee'],\n",
       "  ['bottom', 'buns', 'seat', 'tail'],\n",
       "  ['blue', 'fin', 'gray', 'right']]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_sample = wrapper.data_module.train_dataset[0]\n",
    "first_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['dope', 'scoop', 'skinny', 'word'],\n",
       " ['con', 'dupe', 'fool', 'trick'],\n",
       " ['cant', 'lean', 'list', 'slope'],\n",
       " ['boob', 'eggshell', 'giggle', 'hello']]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print(fake_response['content'])\n",
    "display(first_sample['answer_formatted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-03-27 21:10:04.022\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmodel.reasoning\u001b[0m:\u001b[36mxmlcount_reward_func\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mXML count rewards: [0.25]\u001b[0m\n",
      "\u001b[32m2025-03-27 21:10:04.023\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmodel.reasoning\u001b[0m:\u001b[36mstrict_format_reward_func\u001b[0m:\u001b[36m107\u001b[0m - \u001b[1mStrict format rewards: [0.0]\u001b[0m\n",
      "\u001b[32m2025-03-27 21:10:04.023\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmodel.reasoning\u001b[0m:\u001b[36mconnections_reward_func\u001b[0m:\u001b[36m175\u001b[0m - \u001b[1mModel generations: ['<reasoning>\\nFirst four are academic\\n</reasoning>\\n<answer><group>dope, scoop, skinny, word</group>\\n<group>con, dupe, fool, trick</group>\\n<group>cant, lean, list, slope</group>\\n<group>boob, eggshell, giggle, hello</group></answer>\\n']\u001b[0m\n",
      "\u001b[32m2025-03-27 21:10:04.023\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmodel.reasoning\u001b[0m:\u001b[36mconnections_reward_func\u001b[0m:\u001b[36m177\u001b[0m - \u001b[1mGroups: [[['dope', 'scoop', 'skinny', 'word'], ['con', 'dupe', 'fool', 'trick'], ['cant', 'lean', 'list', 'slope'], ['boob', 'eggshell', 'giggle', 'hello']]]\u001b[0m\n",
      "\u001b[32m2025-03-27 21:10:04.023\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmodel.reasoning\u001b[0m:\u001b[36mconnections_reward_func\u001b[0m:\u001b[36m179\u001b[0m - \u001b[1mConnections scores: [4.0]\u001b[0m\n",
      "\u001b[32m2025-03-27 21:10:04.023\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmodel.reasoning\u001b[0m:\u001b[36mgroup_size_reward_func\u001b[0m:\u001b[36m188\u001b[0m - \u001b[1mGroup size rewards: [0.5]\u001b[0m\n",
      "\u001b[32m2025-03-27 21:10:04.024\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmodel.reasoning\u001b[0m:\u001b[36mn_groups_reward_func\u001b[0m:\u001b[36m196\u001b[0m - \u001b[1mNumber of groups rewards: [0.5]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "for reward_func in wrapper.data_module.reward_functions():\n",
    "    rew = reward_func([conv], [[fake_response]], answer=first_sample['answer_formatted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from model.reasoning import ConnectionsDataModule\n",
    "from trl_wrapper.trainer_wrapper import TrainerWrapper, GRPO_MATH_CONFIG, GRPO_CONNECTIONS_CONFIG\n",
    "from trl_wrapper.wrapper_config import DatasetConfig\n",
    "\n",
    "wrapper = TrainerWrapper(GRPO_CONNECTIONS_CONFIG)\n",
    "\n",
    "wrapper.init_data_module()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample = data_module.train_dataset[0]\n",
    "# sample\n",
    "wrapper.data_module.train_dataset\n",
    "first_sample = wrapper.data_module.train_dataset[0]\n",
    "\n",
    "conv = first_sample['prompt']\n",
    "fake_thoughts = \"<reasoning>\\nFirst four are academic\\n</reasoning>\\n\"\n",
    "fake_response = {'role': \"assistant\", 'content': fake_thoughts + first_sample['answer'] + \"\\n\"}\n",
    "# conv = [*conv, {'role': \"assistant\", 'content': first_sample['answer']}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<reasoning>\n",
      "First four are academic\n",
      "</reasoning>\n",
      "<answer><group>appendix, chapter, index, preface</group>\n",
      "<group>buzz, call, dial, ring</group>\n",
      "<group>dinky, little, minute, slight</group>\n",
      "<group>itchy, jerry, pinky, speedy</group></answer>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(fake_response['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-03-26 21:42:29.328\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmodel.reasoning\u001b[0m:\u001b[36mxmlcount_reward_func\u001b[0m:\u001b[36m59\u001b[0m - \u001b[1mXML count rewards: [0.25]\u001b[0m\n",
      "\u001b[32m2025-03-26 21:42:29.329\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmodel.reasoning\u001b[0m:\u001b[36mstrict_format_reward_func\u001b[0m:\u001b[36m105\u001b[0m - \u001b[1mStrict format rewards: [0.0]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "for reward_func in wrapper.data_module.reward_functions():\n",
    "    rew = reward_func([conv], [[fake_response]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

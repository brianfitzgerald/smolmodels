{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from model.reasoning import ConnectionsDataModule\n",
    "from trl_wrapper.trainer_wrapper import TrainerWrapper, GRPO_MATH_CONFIG, GRPO_CONNECTIONS_CONFIG\n",
    "from trl_wrapper.wrapper_config import DatasetConfig\n",
    "\n",
    "wrapper = TrainerWrapper(GRPO_CONNECTIONS_CONFIG)\n",
    "\n",
    "wrapper.init_data_module()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample = data_module.train_dataset[0]\n",
    "# sample\n",
    "wrapper.data_module.train_dataset\n",
    "first_sample = wrapper.data_module.train_dataset[0]\n",
    "\n",
    "conv = first_sample['prompt']\n",
    "fake_thoughts = \"<reasoning>\\nFirst four are academic\\n</reasoning>\\n\"\n",
    "fake_response = {'role': \"assistant\", 'content': fake_thoughts + first_sample['answer'] + \"\\n\"}\n",
    "# conv = [*conv, {'role': \"assistant\", 'content': first_sample['answer']}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<reasoning>\n",
      "First four are academic\n",
      "</reasoning>\n",
      "<answer><group>appendix, chapter, index, preface</group>\n",
      "<group>buzz, call, dial, ring</group>\n",
      "<group>dinky, little, minute, slight</group>\n",
      "<group>itchy, jerry, pinky, speedy</group></answer>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(fake_response['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-03-26 22:13:19.234\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmodel.reasoning\u001b[0m:\u001b[36mxmlcount_reward_func\u001b[0m:\u001b[36m59\u001b[0m - \u001b[1mXML count rewards: [0.25]\u001b[0m\n",
      "\u001b[32m2025-03-26 22:13:19.234\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmodel.reasoning\u001b[0m:\u001b[36mstrict_format_reward_func\u001b[0m:\u001b[36m105\u001b[0m - \u001b[1mStrict format rewards: [0.0]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['appendix', 'chapter', 'index', 'preface'], ['buzz', 'call', 'dial', 'ring'], ['dinky', 'little', 'minute', 'slight'], ['itchy', 'jerry', 'pinky', 'speedy']]]\n",
      "<answer><group>appendix, chapter, index, preface</group>\n",
      "<group>buzz, call, dial, ring</group>\n",
      "<group>dinky, little, minute, slight</group>\n",
      "<group>itchy, jerry, pinky, speedy</group></answer>\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m reward_func \u001b[38;5;129;01min\u001b[39;00m wrapper\u001b[38;5;241m.\u001b[39mdata_module\u001b[38;5;241m.\u001b[39mreward_functions():\n\u001b[0;32m----> 2\u001b[0m     rew \u001b[38;5;241m=\u001b[39m \u001b[43mreward_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mconv\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfake_response\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43manswer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfirst_sample\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43manswer\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/smolmodels/notebooks/../model/reasoning.py:175\u001b[0m, in \u001b[0;36mconnections_reward_func\u001b[0;34m(prompts, completions, **kwargs)\u001b[0m\n\u001b[1;32m    173\u001b[0m groups \u001b[38;5;241m=\u001b[39m [parse_groups(r) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m model_generations]\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28mprint\u001b[39m(groups)\n\u001b[0;32m--> 175\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mscore_connections\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43manswer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mg\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mg\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m scores\n",
      "File \u001b[0;32m~/Documents/GitHub/smolmodels/notebooks/../model/reasoning.py:175\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    173\u001b[0m groups \u001b[38;5;241m=\u001b[39m [parse_groups(r) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m model_generations]\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28mprint\u001b[39m(groups)\n\u001b[0;32m--> 175\u001b[0m scores \u001b[38;5;241m=\u001b[39m [\u001b[43mscore_connections\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43manswer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mg\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m groups]\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m scores\n",
      "File \u001b[0;32m~/Documents/GitHub/smolmodels/notebooks/../model/reasoning.py:143\u001b[0m, in \u001b[0;36mscore_connections\u001b[0;34m(solution_groups, submitted_groups)\u001b[0m\n\u001b[1;32m    140\u001b[0m correct_group_names \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28mprint\u001b[39m(solution_groups)\n\u001b[1;32m    142\u001b[0m solution_sets \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m--> 143\u001b[0m     group_name: \u001b[38;5;28mset\u001b[39m(words) \u001b[38;5;28;01mfor\u001b[39;00m group_name, words \u001b[38;5;129;01min\u001b[39;00m \u001b[43msolution_groups\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m()\n\u001b[1;32m    144\u001b[0m }\n\u001b[1;32m    145\u001b[0m solved \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()  \u001b[38;5;66;03m# Track which solution groups have been solved.\u001b[39;00m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m submitted \u001b[38;5;129;01min\u001b[39;00m submitted_groups:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "for reward_func in wrapper.data_module.reward_functions():\n",
    "    rew = reward_func([conv], [[fake_response]], answer=first_sample['answer'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

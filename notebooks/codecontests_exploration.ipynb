{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "import polars as pl\n",
    "from IPython.display import display, Markdown, Latex, clear_output\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from rich.syntax import Syntax\n",
    "from rich.console import Console\n",
    "import pandas as pd\n",
    "from enum import Enum\n",
    "from functools import partial\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from evaluation.code_execution import evaluate_sample_codecontests, evaluate_python_code_exec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://huggingface.co/datasets/deepmind/code_contests\n",
    "cc_dataset = load_dataset(\"deepmind/code_contests\")[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Language(Enum):\n",
    "    UNKNOWN = 0\n",
    "    PYTHON = 1\n",
    "    CPP = 2\n",
    "    PYTHON3 = 3\n",
    "    JAVA = 4\n",
    "\n",
    "class ProblemSource(Enum):\n",
    "    UNKNOWN = 0\n",
    "    CODECHEF = 1\n",
    "    CODEFORCES = 2\n",
    "    HACKEREARTH = 3\n",
    "    CODEJAM = 4\n",
    "    ATCODER = 5\n",
    "    AIZU = 6\n",
    "\n",
    "class Difficulty(Enum):\n",
    "    UNKNOWN_DIFFICULTY = 0\n",
    "    EASY = 1\n",
    "    MEDIUM = 2\n",
    "    HARD = 3\n",
    "    HARDER = 4\n",
    "    HARDEST = 5\n",
    "    EXTERNAL = 6\n",
    "    A = 7\n",
    "    B = 8\n",
    "    C = 9\n",
    "    D = 10\n",
    "    E = 11\n",
    "    F = 12\n",
    "    G = 13\n",
    "    H = 14\n",
    "    I = 15\n",
    "    J = 16\n",
    "    K = 17\n",
    "    L = 18\n",
    "    M = 19\n",
    "    N = 20\n",
    "    O = 21\n",
    "    P = 22\n",
    "    Q = 23\n",
    "    R = 24\n",
    "    S = 25\n",
    "    T = 26\n",
    "    U = 27\n",
    "    V = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "console = Console()\n",
    "\n",
    "\n",
    "def print_code_snippet(snippet: str, console: Console):\n",
    "    formatted_snippet = Syntax(\n",
    "        snippet,\n",
    "        \"python\",\n",
    "        theme=\"monokai\",\n",
    "        line_numbers=True,\n",
    "    )\n",
    "    console.print(formatted_snippet)\n",
    "\n",
    "\n",
    "first_n_samples = []\n",
    "\n",
    "iterator = tqdm(cc_dataset)\n",
    "for i, sample in enumerate(iterator):\n",
    "    description = sample[\"description\"]\n",
    "    test_inputs = sample[\"public_tests\"][\"input\"] + sample[\"private_tests\"][\"input\"]\n",
    "    test_outputs = sample[\"public_tests\"][\"output\"] + sample[\"private_tests\"][\"output\"]\n",
    "    problem_source = ProblemSource(sample[\"source\"])\n",
    "    difficulty = Difficulty(sample[\"difficulty\"])\n",
    "\n",
    "    should_keep_problem = True\n",
    "\n",
    "    if problem_source != ProblemSource.CODEFORCES:\n",
    "        should_keep_problem = False\n",
    "\n",
    "    if sample[\"is_description_translated\"]:  # type: ignore\n",
    "        should_keep_problem = False\n",
    "\n",
    "    if sample[\"input_file\"] or sample[\"output_file\"]:  # type: ignore\n",
    "        should_keep_problem = False\n",
    "\n",
    "    if len(sample[\"private_tests\"][\"input\"]) == 0:\n",
    "        should_keep_problem = False\n",
    "\n",
    "    # console.clear()\n",
    "    # console.print(description)\n",
    "    # display(Markdown(description))\n",
    "\n",
    "    has_python_solution = False\n",
    "\n",
    "    for j, (lang_txt, solution_code) in enumerate(\n",
    "        zip(sample[\"solutions\"][\"language\"], sample[\"solutions\"][\"solution\"])\n",
    "    ):\n",
    "        language = Language(lang_txt)\n",
    "        if language == Language.PYTHON3:\n",
    "            has_python_solution = True\n",
    "            break\n",
    "\n",
    "        # solution_code = solution_code.replace(\"sys.exit\", \"exit\")\n",
    "        # # clear_output(wait=True)\n",
    "        # display(f\"problem {i}, solution {j}\")\n",
    "        # display(Markdown(f\"```python\\n{solution_code}\\n```\"))\n",
    "        # print_code_snippet(solution_code, console)\n",
    "\n",
    "        # for inputs, outputs in zip(test_inputs, test_outputs):\n",
    "        #     # each time input is called, it will return the next input value\n",
    "        #     out = evaluate_python_code_exec(solution_code, inputs)\n",
    "\n",
    "    if not has_python_solution:\n",
    "        should_keep_problem = False\n",
    "\n",
    "    if should_keep_problem:\n",
    "        sample_to_keep = {\n",
    "            \"source\": problem_source,\n",
    "            \"difficulty\": difficulty,\n",
    "        }\n",
    "        for key in (\"name\", \"description\", \"public_tests\", \"private_tests\", \"cf_rating\", \"cf_points\"):\n",
    "            sample_to_keep[key] = sample[key]\n",
    "        first_n_samples.append(sample_to_keep)\n",
    "    \n",
    "    iterator.set_postfix({\"n_samples\": len(first_n_samples)})\n",
    "\n",
    "    if len(first_n_samples) > 2500:\n",
    "        break\n",
    "\n",
    "first_n_df = pd.DataFrame(first_n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, problem in enumerate(cc_dataset):\n",
    "    val = f\"### Problem {i}: {problem['name']}\\n{problem['description']}\"\n",
    "    display(Markdown(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for col in first_n_df.columns:\n",
    "    if pd.api.types.is_object_dtype(first_n_df[col]) and isinstance(first_n_df[col].iloc[0], Enum):\n",
    "        first_n_df[col] = first_n_df[col].apply(lambda x: x.value if isinstance(x, Enum) else x)\n",
    "\n",
    "Dataset.from_pandas(first_n_df).to_parquet(\"dataset_samples/codeforces_problems_subset.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = Dataset.from_parquet(\"../dataset_samples/codeforces_problems_subset.parquet\")\n",
    "test_df[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['passed']\n",
      "['passed']\n",
      "['passed']\n"
     ]
    }
   ],
   "source": [
    "test_code = \"\"\"\n",
    "def solution(problem_input):\n",
    "    n, m, k = map(int, problem_input[0].split())\n",
    "    edges = [list(map(int, line.split())) for line in problem_input[1:]]\n",
    "\n",
    "    adj = [[] for _ in range(n + 1)]\n",
    "\n",
    "    results = []\n",
    "    for i in range(m):\n",
    "        adj[edges[i][0]].append(edges[i][1])\n",
    "        adj[edges[i][1]].append(edges[i][0])\n",
    "\n",
    "        max_people = 0\n",
    "        for j in range(1 << n):\n",
    "            group = []\n",
    "            for bit in range(n):\n",
    "                if (j >> bit) & 1:\n",
    "                    group.append(bit + 1)\n",
    "\n",
    "            valid_group = True\n",
    "            for person in group:\n",
    "                friend_count = 0\n",
    "                for friend in adj[person]:\n",
    "                    if friend in group:\n",
    "                        friend_count += 1\n",
    "                if friend_count < k:\n",
    "                    valid_group = False\n",
    "                    break\n",
    "\n",
    "            if valid_group:\n",
    "                max_people = max(max_people, len(group))\n",
    "        results.append(max_people)\n",
    "    return results\n",
    "\"\"\"\n",
    "\n",
    "tests = {\n",
    "    \"input\": [\n",
    "        \"4 4 2\\n2 3\\n1 2\\n1 3\\n1 4\\n\",\n",
    "        \"5 8 2\\n2 1\\n4 2\\n5 4\\n5 2\\n4 3\\n5 1\\n4 1\\n3 2\\n\",\n",
    "        \"5 7 2\\n1 5\\n3 2\\n2 5\\n3 4\\n1 2\\n5 3\\n1 3\\n\",\n",
    "    ],\n",
    "    \"output\": [\"0\\n0\\n3\\n3\\n\", \"0\\n0\\n0\\n3\\n3\\n4\\n4\\n5\\n\", \"0\\n0\\n0\\n0\\n3\\n4\\n4\\n\"],\n",
    "}\n",
    "\n",
    "for test_input in tests[\"input\"]:\n",
    "    ti = test_input.strip().split(\"\\n\")\n",
    "    out = evaluate_python_code_exec(test_code + f\"solution({ti})\")\n",
    "    print(out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

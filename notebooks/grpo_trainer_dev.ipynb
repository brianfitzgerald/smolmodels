{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brianfitzgerald/Documents/GitHub/smolmodels/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-03-27 20:42:10,342\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from trl_wrapper.trainer_wrapper import TrainerWrapper, GRPO_MATH_CONFIG, GRPO_CONNECTIONS_CONFIG, SMOL_LM_135M\n",
    "\n",
    "cfg = GRPO_CONNECTIONS_CONFIG\n",
    "cfg.train_batch_size = 2\n",
    "cfg.num_generations = 2\n",
    "cfg.model_id_or_path = SMOL_LM_135M\n",
    "cfg.notebook_mode = True\n",
    "cfg.max_samples = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-03-27 20:42:13.930\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtrl_wrapper.trainer_wrapper\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m264\u001b[0m - \u001b[1mSetting padding side to: left\u001b[0m\n",
      "\u001b[32m2025-03-27 20:42:13.944\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtrl_wrapper.trainer_wrapper\u001b[0m:\u001b[36minit_model\u001b[0m:\u001b[36m275\u001b[0m - \u001b[1mUsing device: mps\u001b[0m\n",
      "\u001b[32m2025-03-27 20:42:13.944\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtrl_wrapper.trainer_wrapper\u001b[0m:\u001b[36minit_model\u001b[0m:\u001b[36m289\u001b[0m - \u001b[1mLoading model HuggingFaceTB/SmolLM2-135M-Instruct with attn_impl: sdpa\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "wrapper = TrainerWrapper(cfg)\n",
    "wrapper.init_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-03-27 20:42:44.953\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtrl_wrapper.trainer_wrapper\u001b[0m:\u001b[36minit_data_module\u001b[0m:\u001b[36m315\u001b[0m - \u001b[1mUsing chat template override: smollmv2\u001b[0m\n",
      "\u001b[32m2025-03-27 20:42:44.954\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtrl_wrapper.wrapper_config\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1mCache dir: ../dataset_caches/connections_data_module\u001b[0m\n",
      "Map: 100%|██████████| 353/353 [00:00<00:00, 12389.56 examples/s]\n"
     ]
    }
   ],
   "source": [
    "wrapper.init_data_module()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'words': ['may',\n",
       "  'can',\n",
       "  'lead',\n",
       "  'butcher',\n",
       "  'lights',\n",
       "  'wax',\n",
       "  'toilet',\n",
       "  'head',\n",
       "  'cut',\n",
       "  'scrap',\n",
       "  'prime',\n",
       "  'top',\n",
       "  'camera',\n",
       "  'could',\n",
       "  'action',\n",
       "  'might'],\n",
       " 'solution': {'groups': [{'reason': 'conditional words',\n",
       "    'words': ['can', 'could', 'may', 'might']},\n",
       "   {'reason': 'film set directives',\n",
       "    'words': ['action', 'camera', 'cut', 'lights']},\n",
       "   {'reason': 'foremost', 'words': ['head', 'lead', 'prime', 'top']},\n",
       "   {'reason': '___ paper', 'words': ['butcher', 'scrap', 'toilet', 'wax']}]},\n",
       " 'prompt': [{'content': '\\nYou are an expert puzzle solving model.\\nFind groups of words that are related to each other, and return the answer in the following format:\\nRespond in the following format:\\n<reasoning>\\n...\\n</reasoning>\\n<answer>\\n<group>\\n...\\n</group>\\n<group>\\n...\\n</group>\\n</answer>\\n\\n# Example\\n\\nUser: apple, orange, banana, pear, corolla, charger,\\nAssistant: <reasoning>\\nThe first group are all fruits.\\nThe second group are all cars.\\n</reasoning>\\n<answer>\\n<group>apple, orange, banana, pear</group>\\n<group>corolla, charger</group>\\n</answer>\\n\\n# Example\\n\\nUser: dog, cat, red, white,\\nAssistant: <reasoning>\\nThe first group are all animals.\\nThe second group are all colors.\\n</reasoning>\\n<answer>\\n<group>dog, cat</group>\\n<group>red, white</group>\\n</answer>\\n',\n",
       "   'role': 'system'},\n",
       "  {'content': 'may, can, lead, butcher, lights, wax, toilet, head, cut, scrap, prime, top, camera, could, action, might',\n",
       "   'role': 'user'}],\n",
       " 'answer': '<answer><group>can, could, may, might</group>\\n<group>action, camera, cut, lights</group>\\n<group>head, lead, prime, top</group>\\n<group>butcher, scrap, toilet, wax</group></answer>',\n",
       " 'answer_formatted': [['can', 'could', 'may', 'might'],\n",
       "  ['action', 'camera', 'cut', 'lights'],\n",
       "  ['head', 'lead', 'prime', 'top'],\n",
       "  ['butcher', 'scrap', 'toilet', 'wax']]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrapper.data_module.train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-03-27 20:42:49.105\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtrl_wrapper.trainer_wrapper\u001b[0m:\u001b[36minit_trainer\u001b[0m:\u001b[36m352\u001b[0m - \u001b[1mSaving output to: ./runs/03-27-20-42-521661-smollm2-135m-instruct-\u001b[0m\n",
      "\u001b[32m2025-03-27 20:42:49.106\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtrl_wrapper.trainer_wrapper\u001b[0m:\u001b[36minit_trainer\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mInitializing trainer, run_name: 03-27-20-42-521661-smollm2-135m-instruct-, wandb project: qwen-connections-grpo\u001b[0m\n",
      "\u001b[32m2025-03-27 20:42:49.106\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtrl_wrapper.trainer_wrapper\u001b[0m:\u001b[36minit_trainer\u001b[0m:\u001b[36m460\u001b[0m - \u001b[1mUsing vllm: False\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "wrapper.init_trainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.reasoning import SYSTEM_PROMPT\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?\",\n",
    "    },\n",
    "]\n",
    "tokenized_chat = wrapper.tokenizer.apply_chat_template(\n",
    "    messages, tokenize=True, add_generation_prompt=True, return_tensors=\"pt\", return_attention_mask=True\n",
    ")\n",
    "tokenized_chat = tokenized_chat.to(\"cuda\")\n",
    "out = wrapper.model.generate(tokenized_chat, max_length=1024)\n",
    "print(wrapper.tokenizer.decode(out[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-03-27 20:42:53.805\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtrl_wrapper.trainer_wrapper\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m624\u001b[0m - \u001b[1mStarting training.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "wrapper.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from trl_wrapper.trainer_wrapper import TrainerWrapper, GRPO_MATH_CONFIG, GRPO_CONNECTIONS_CONFIG, SMOL_LM_135M\n",
    "\n",
    "cfg = GRPO_CONNECTIONS_CONFIG\n",
    "cfg.train_batch_size = 2\n",
    "cfg.num_generations = 2\n",
    "cfg.model_id_or_path = SMOL_LM_135M\n",
    "cfg.notebook_mode = True\n",
    "cfg.max_samples = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-03-25 21:28:39.302\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtrl_wrapper.trainer_wrapper\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m266\u001b[0m - \u001b[1mSetting padding side to: left\u001b[0m\n",
      "\u001b[32m2025-03-25 21:28:39.312\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtrl_wrapper.trainer_wrapper\u001b[0m:\u001b[36minit_model\u001b[0m:\u001b[36m277\u001b[0m - \u001b[1mUsing device: mps\u001b[0m\n",
      "\u001b[32m2025-03-25 21:28:39.313\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtrl_wrapper.trainer_wrapper\u001b[0m:\u001b[36minit_model\u001b[0m:\u001b[36m291\u001b[0m - \u001b[1mLoading model HuggingFaceTB/SmolLM2-135M-Instruct with attn_impl: sdpa\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "wrapper = TrainerWrapper(cfg)\n",
    "wrapper.init_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>solution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[nets, return, heat, jazz, mom, shift, kayak, ...</td>\n",
       "      <td>{'groups': [{'words': ['bucks', 'heat', 'jazz'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[league, loafer, queue, are, pump, foot, why, ...</td>\n",
       "      <td>{'groups': [{'words': ['foot', 'league', 'mile...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[amigo, wolf, cheek, pom, stooge, lab, king, p...</td>\n",
       "      <td>{'groups': [{'words': ['chow', 'gobble', 'scar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[puma, sweep, chicago, bat, iron, adidas, vacu...</td>\n",
       "      <td>{'groups': [{'words': ['cabaret', 'carousel', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[glum, prime, low, hulu, green, plum, blue, do...</td>\n",
       "      <td>{'groups': [{'words': ['ketchup', 'mayo', 'rel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>[wee, back, champion, poster, first, here, pre...</td>\n",
       "      <td>{'groups': [{'words': ['first', 'initial', 'ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>[griddle, fringe, tease, geez, seize, pan, ket...</td>\n",
       "      <td>{'groups': [{'words': ['frill', 'fringe', 'ruf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>[quarter, down, flat, choice, natural, heel, t...</td>\n",
       "      <td>{'groups': [{'words': ['down', 'heel', 'shake'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>[evil, scented, receptive, flexible, vile, wax...</td>\n",
       "      <td>{'groups': [{'words': ['evil', 'live', 'veil',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>[daunt, bully, steer, stock, rattle, flea, bul...</td>\n",
       "      <td>{'groups': [{'words': ['direct', 'guide', 'lea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>353 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 words  \\\n",
       "0    [nets, return, heat, jazz, mom, shift, kayak, ...   \n",
       "1    [league, loafer, queue, are, pump, foot, why, ...   \n",
       "2    [amigo, wolf, cheek, pom, stooge, lab, king, p...   \n",
       "3    [puma, sweep, chicago, bat, iron, adidas, vacu...   \n",
       "4    [glum, prime, low, hulu, green, plum, blue, do...   \n",
       "..                                                 ...   \n",
       "348  [wee, back, champion, poster, first, here, pre...   \n",
       "349  [griddle, fringe, tease, geez, seize, pan, ket...   \n",
       "350  [quarter, down, flat, choice, natural, heel, t...   \n",
       "351  [evil, scented, receptive, flexible, vile, wax...   \n",
       "352  [daunt, bully, steer, stock, rattle, flea, bul...   \n",
       "\n",
       "                                              solution  \n",
       "0    {'groups': [{'words': ['bucks', 'heat', 'jazz'...  \n",
       "1    {'groups': [{'words': ['foot', 'league', 'mile...  \n",
       "2    {'groups': [{'words': ['chow', 'gobble', 'scar...  \n",
       "3    {'groups': [{'words': ['cabaret', 'carousel', ...  \n",
       "4    {'groups': [{'words': ['ketchup', 'mayo', 'rel...  \n",
       "..                                                 ...  \n",
       "348  {'groups': [{'words': ['first', 'initial', 'ma...  \n",
       "349  {'groups': [{'words': ['frill', 'fringe', 'ruf...  \n",
       "350  {'groups': [{'words': ['down', 'heel', 'shake'...  \n",
       "351  {'groups': [{'words': ['evil', 'live', 'veil',...  \n",
       "352  {'groups': [{'words': ['direct', 'guide', 'lea...  \n",
       "\n",
       "[353 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.read_json(\"../dataset_files/connections_prompts.jsonl\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-03-25 21:34:25.351\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtrl_wrapper.trainer_wrapper\u001b[0m:\u001b[36minit_data_module\u001b[0m:\u001b[36m317\u001b[0m - \u001b[1mUsing chat template override: smollmv2\u001b[0m\n",
      "\u001b[32m2025-03-25 21:34:25.352\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtrl_wrapper.wrapper_config\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1mCache dir: ../dataset_caches/connections_data_module\u001b[0m\n",
      "Map: 100%|██████████| 353/353 [00:00<00:00, 16892.45 examples/s]\n"
     ]
    }
   ],
   "source": [
    "wrapper.init_data_module()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'words': ['risk',\n",
       "  'bond',\n",
       "  'trouble',\n",
       "  'sorry',\n",
       "  'smart',\n",
       "  'tongue',\n",
       "  'soul',\n",
       "  'cement',\n",
       "  'duckie',\n",
       "  'band',\n",
       "  'hunt',\n",
       "  'sole',\n",
       "  'clue',\n",
       "  'lace',\n",
       "  'heel',\n",
       "  'ryan'],\n",
       " 'solution': {'groups': [{'reason': 'board games',\n",
       "    'words': ['clue', 'risk', 'sorry', 'trouble']},\n",
       "   {'reason': 'shoe parts', 'words': ['heel', 'lace', 'sole', 'tongue']},\n",
       "   {'reason': 'fictional spies', 'words': ['bond', 'hunt', 'ryan', 'smart']},\n",
       "   {'reason': 'rubber ___', 'words': ['band', 'cement', 'duckie', 'soul']}]},\n",
       " 'prompt': [{'content': '\\nYou are an expert puzzle solving model.\\nFind groups of words that are related to each other, and return the answer in the following format:\\nRespond in the following format:\\n<reasoning>\\n...\\n</reasoning>\\n<answer>\\n<group>\\n...\\n</group>\\n<group>\\n...\\n</group>\\n</answer>\\n\\n# Example\\n\\nUser: apple, orange, banana, pear, corolla, charger,\\nAssistant: <reasoning>\\nThe first group are all fruits.\\nThe second group are all cars.\\n</reasoning>\\n<answer>\\n<group>apple, orange, banana, pear</group>\\n<group>corolla, charger</group>\\n</answer>\\n\\n# Example\\n\\nUser: dog, cat, red, white,\\nAssistant: <reasoning>\\nThe first group are all animals.\\nThe second group are all colors.\\n</reasoning>\\n<answer>\\n<group>dog, cat</group>\\n<group>red, white</group>\\n</answer>\\n',\n",
       "   'role': 'system'},\n",
       "  {'content': 'risk, bond, trouble, sorry, smart, tongue, soul, cement, duckie, band, hunt, sole, clue, lace, heel, ryan',\n",
       "   'role': 'user'}],\n",
       " 'answer': '<answer><group>clue, risk, sorry, trouble</group>\\n<group>heel, lace, sole, tongue</group>\\n<group>bond, hunt, ryan, smart</group>\\n<group>band, cement, duckie, soul</group></answer>'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrapper.data_module.train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-03-25 21:35:05.279\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtrl_wrapper.trainer_wrapper\u001b[0m:\u001b[36minit_trainer\u001b[0m:\u001b[36m354\u001b[0m - \u001b[1mSaving output to: ./runs/03-25-21-35-952469-smollm2-135m-instruct-\u001b[0m\n",
      "\u001b[32m2025-03-25 21:35:05.280\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtrl_wrapper.trainer_wrapper\u001b[0m:\u001b[36minit_trainer\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mInitializing trainer, run_name: 03-25-21-35-952469-smollm2-135m-instruct-, wandb project: qwen-connections-grpo\u001b[0m\n",
      "\u001b[32m2025-03-25 21:35:05.280\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtrl_wrapper.trainer_wrapper\u001b[0m:\u001b[36minit_trainer\u001b[0m:\u001b[36m462\u001b[0m - \u001b[1mUsing vllm: False\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "wrapper.init_trainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 13\u001b[0m\n\u001b[1;32m      3\u001b[0m messages \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      4\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: SYSTEM_PROMPT},\n\u001b[1;32m      5\u001b[0m     {\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m     },\n\u001b[1;32m      9\u001b[0m ]\n\u001b[1;32m     10\u001b[0m tokenized_chat \u001b[38;5;241m=\u001b[39m wrapper\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mapply_chat_template(\n\u001b[1;32m     11\u001b[0m     messages, tokenize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, add_generation_prompt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, return_attention_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     12\u001b[0m )\n\u001b[0;32m---> 13\u001b[0m tokenized_chat \u001b[38;5;241m=\u001b[39m \u001b[43mtokenized_chat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m out \u001b[38;5;241m=\u001b[39m wrapper\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mgenerate(tokenized_chat, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(wrapper\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mdecode(out[\u001b[38;5;241m0\u001b[39m], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n",
      "File \u001b[0;32m~/Documents/GitHub/smolmodels/.venv/lib/python3.11/site-packages/torch/cuda/__init__.py:310\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    308\u001b[0m     )\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m    313\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    314\u001b[0m     )\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "from model.reasoning import SYSTEM_PROMPT\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?\",\n",
    "    },\n",
    "]\n",
    "tokenized_chat = wrapper.tokenizer.apply_chat_template(\n",
    "    messages, tokenize=True, add_generation_prompt=True, return_tensors=\"pt\", return_attention_mask=True\n",
    ")\n",
    "tokenized_chat = tokenized_chat.to(\"cuda\")\n",
    "out = wrapper.model.generate(tokenized_chat, max_length=1024)\n",
    "print(wrapper.tokenizer.decode(out[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-03-25 21:35:29.499\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtrl_wrapper.trainer_wrapper\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m626\u001b[0m - \u001b[1mStarting training.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'words': ['tombstone', 'cherry', '20,000', 'bat', 'firefly', 'bell', '24', '451', 'cobweb', 'bar', '7', 'bones', '22', '2001', 'weeds', 'pumpkin'], 'solution': {'groups': [{'reason': 'tv shows', 'words': ['24', 'bones', 'firefly', 'weeds']}, {'reason': 'halloween decorations', 'words': ['bat', 'cobweb', 'pumpkin', 'tombstone']}, {'reason': 'slot machine symbols', 'words': ['7', 'bar', 'bell', 'cherry']}, {'reason': 'numbers in book titles', 'words': ['22', '451', '2001', '20,000']}]}, 'prompt': [{'content': '\\nYou are an expert puzzle solving model.\\nFind groups of words that are related to each other, and return the answer in the following format:\\nRespond in the following format:\\n<reasoning>\\n...\\n</reasoning>\\n<answer>\\n<group>\\n...\\n</group>\\n<group>\\n...\\n</group>\\n</answer>\\n\\n# Example\\n\\nUser: apple, orange, banana, pear, corolla, charger,\\nAssistant: <reasoning>\\nThe first group are all fruits.\\nThe second group are all cars.\\n</reasoning>\\n<answer>\\n<group>apple, orange, banana, pear</group>\\n<group>corolla, charger</group>\\n</answer>\\n\\n# Example\\n\\nUser: dog, cat, red, white,\\nAssistant: <reasoning>\\nThe first group are all animals.\\nThe second group are all colors.\\n</reasoning>\\n<answer>\\n<group>dog, cat</group>\\n<group>red, white</group>\\n</answer>\\n', 'role': 'system'}, {'content': 'tombstone, cherry, 20,000, bat, firefly, bell, 24, 451, cobweb, bar, 7, bones, 22, 2001, weeds, pumpkin', 'role': 'user'}], 'answer': '<answer><group>24, bones, firefly, weeds</group>\\n<group>bat, cobweb, pumpkin, tombstone</group>\\n<group>7, bar, bell, cherry</group>\\n<group>22, 451, 2001, 20,000</group></answer>'}\n",
      "user\n",
      "{'words': ['tombstone', 'cherry', '20,000', 'bat', 'firefly', 'bell', '24', '451', 'cobweb', 'bar', '7', 'bones', '22', '2001', 'weeds', 'pumpkin'], 'solution': {'groups': [{'reason': 'tv shows', 'words': ['24', 'bones', 'firefly', 'weeds']}, {'reason': 'halloween decorations', 'words': ['bat', 'cobweb', 'pumpkin', 'tombstone']}, {'reason': 'slot machine symbols', 'words': ['7', 'bar', 'bell', 'cherry']}, {'reason': 'numbers in book titles', 'words': ['22', '451', '2001', '20,000']}]}, 'prompt': [{'content': '\\nYou are an expert puzzle solving model.\\nFind groups of words that are related to each other, and return the answer in the following format:\\nRespond in the following format:\\n<reasoning>\\n...\\n</reasoning>\\n<answer>\\n<group>\\n...\\n</group>\\n<group>\\n...\\n</group>\\n</answer>\\n\\n# Example\\n\\nUser: apple, orange, banana, pear, corolla, charger,\\nAssistant: <reasoning>\\nThe first group are all fruits.\\nThe second group are all cars.\\n</reasoning>\\n<answer>\\n<group>apple, orange, banana, pear</group>\\n<group>corolla, charger</group>\\n</answer>\\n\\n# Example\\n\\nUser: dog, cat, red, white,\\nAssistant: <reasoning>\\nThe first group are all animals.\\nThe second group are all colors.\\n</reasoning>\\n<answer>\\n<group>dog, cat</group>\\n<group>red, white</group>\\n</answer>\\n', 'role': 'system'}, {'content': 'tombstone, cherry, 20,000, bat, firefly, bell, 24, 451, cobweb, bar, 7, bones, 22, 2001, weeds, pumpkin', 'role': 'user'}], 'answer': '<answer><group>24, bones, firefly, weeds</group>\\n<group>bat, cobweb, pumpkin, tombstone</group>\\n<group>7, bar, bell, cherry</group>\\n<group>22, 451, 2001, 20,000</group></answer>'}\n",
      "user\n"
     ]
    }
   ],
   "source": [
    "wrapper.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

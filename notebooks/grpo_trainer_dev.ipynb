{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brianf/smolmodels/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-03-29 08:34:26,664\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from trl_wrapper.trainer_wrapper import TrainerWrapper, GRPO_CONNECTIONS_CONFIG\n",
    "\n",
    "cfg = GRPO_CONNECTIONS_CONFIG\n",
    "cfg.train_batch_size = 2\n",
    "cfg.num_generations = 2\n",
    "# cfg.model_id_or_path = SMOL_LM_135M\n",
    "cfg.notebook_mode = True\n",
    "cfg.max_samples = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-03-29 08:34:45.252\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtrl_wrapper.trainer_wrapper\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mSetting padding side to: left\u001b[0m\n",
      "\u001b[32m2025-03-29 08:34:45.386\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtrl_wrapper.trainer_wrapper\u001b[0m:\u001b[36minit_model\u001b[0m:\u001b[36m276\u001b[0m - \u001b[1mUsing device: cuda:0\u001b[0m\n",
      "\u001b[32m2025-03-29 08:34:45.387\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtrl_wrapper.trainer_wrapper\u001b[0m:\u001b[36minit_model\u001b[0m:\u001b[36m290\u001b[0m - \u001b[1mLoading model Qwen/Qwen2.5-1.5B-Instruct with attn_impl: flash_attention_2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "wrapper = TrainerWrapper(cfg)\n",
    "wrapper.init_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-03-29 08:36:42.319\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtrl_wrapper.wrapper_config\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1mCache dir: ../dataset_caches/connections_data_module\u001b[0m\n",
      "Map: 100%|██████████| 353/353 [00:00<00:00, 5290.22 examples/s]\n"
     ]
    }
   ],
   "source": [
    "wrapper.init_data_module()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'words': ['nba',\n",
       "  'chest',\n",
       "  'hoop',\n",
       "  'band',\n",
       "  'limit',\n",
       "  'cap',\n",
       "  'circle',\n",
       "  'pearl',\n",
       "  'curb',\n",
       "  'traffic',\n",
       "  'basket',\n",
       "  'check',\n",
       "  'paper',\n",
       "  'bin',\n",
       "  'hamper',\n",
       "  'ring'],\n",
       " 'solution': {'groups': [{'reason': 'circular shapes',\n",
       "    'words': ['band', 'circle', 'hoop', 'ring']},\n",
       "   {'reason': 'containers', 'words': ['basket', 'bin', 'chest', 'hamper']},\n",
       "   {'reason': 'restrict', 'words': ['cap', 'check', 'curb', 'limit']},\n",
       "   {'reason': '___ jam', 'words': ['nba', 'paper', 'pearl', 'traffic']}]},\n",
       " 'prompt': [{'content': '\\nYou are an expert puzzle solving model.\\nFind groups of words that are related to each other. Each group is four words long.\\nYou may only use each word in one group.\\nRespond in the following format:\\n<reasoning>\\n...\\n</reasoning>\\n<answer>\\n<group>\\n...\\n</group>\\n<group>\\n...\\n</group>\\n</answer>\\n\\n# Example\\n\\nUser: apple, orange, banana, pear, corolla, charger,\\nAssistant: <reasoning>\\nThe first group are all fruits.\\nThe second group are all cars.\\n</reasoning>\\n<answer>\\n<group>apple, orange, banana, pear</group>\\n<group>corolla, charger</group>\\n</answer>\\n\\n# Example\\n\\nUser: dog, cat, red, white,\\nAssistant: <reasoning>\\nThe first group are all animals.\\nThe second group are all colors.\\n</reasoning>\\n<answer>\\n<group>dog, cat</group>\\n<group>red, white</group>\\n</answer>\\n',\n",
       "   'role': 'system'},\n",
       "  {'content': 'nba, chest, hoop, band, limit, cap, circle, pearl, curb, traffic, basket, check, paper, bin, hamper, ring',\n",
       "   'role': 'user'}],\n",
       " 'answer': '<answer><group>band, circle, hoop, ring</group>\\n<group>basket, bin, chest, hamper</group>\\n<group>cap, check, curb, limit</group>\\n<group>nba, paper, pearl, traffic</group></answer>',\n",
       " 'answer_formatted': [['band', 'circle', 'hoop', 'ring'],\n",
       "  ['basket', 'bin', 'chest', 'hamper'],\n",
       "  ['cap', 'check', 'curb', 'limit'],\n",
       "  ['nba', 'paper', 'pearl', 'traffic']]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrapper.data_module.train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapper.init_trainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.reasoning import GSM8K_SYSTEM_PROMPT, CONNECTIONS_PROMPT\n",
    "from model.utils import get_available_device\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": CONNECTIONS_PROMPT},\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"train, panda, dove, series, wind, bear, orca, bass, string, skunk, speed, sand, zebra, tourist, desert, chain\",\n",
    "    },\n",
    "]\n",
    "tokenized_chat = wrapper.tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=True,\n",
    "    add_generation_prompt=True,\n",
    "    return_tensors=\"pt\",\n",
    "    return_attention_mask=True,\n",
    ")\n",
    "\n",
    "device = get_available_device()\n",
    "tokenized_chat = tokenized_chat.to(device)\n",
    "out = wrapper.model.generate(tokenized_chat, max_length=1024)\n",
    "print(wrapper.tokenizer.decode(out[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapper.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

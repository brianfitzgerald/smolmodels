{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import os\n",
    "import sys\n",
    "os.environ[\"HF_HUB_ENABLE_HF_TRANSFER\"] = \"1\"\n",
    "sys.path.append(\"..\")\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brianfitzgerald/Documents/GitHub/smolmodels/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from synthetic_data.tasks.writing import WritingScoreAnnotate, GutenbergBacktranslationFromTxt\n",
    "from synthetic_data.utils import ldictl\n",
    "# df = pl.read_parquet(\"pile.parquet\")\n",
    "\n",
    "# input_df: pl.DataFrame = pl.read_parquet(\"../dataset_files/gutenberg_backtranslate.parquet\")\n",
    "task = GutenbergBacktranslationFromTxt()\n",
    "\n",
    "# mock_batch = ldictl(input_df.head(4).to_dicts())\n",
    "dataset = task.load_custom()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-03-16 08:53:43.872\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthetic_data.tasks.writing\u001b[0m:\u001b[36m_get_paragraph_chunks\u001b[0m:\u001b[36m329\u001b[0m - \u001b[1mChunk length: 720\u001b[0m\n",
      "\u001b[32m2025-03-16 08:53:44.173\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthetic_data.tasks.writing\u001b[0m:\u001b[36m_get_paragraph_chunks\u001b[0m:\u001b[36m329\u001b[0m - \u001b[1mChunk length: 733\u001b[0m\n",
      "\u001b[32m2025-03-16 08:53:44.174\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthetic_data.tasks.writing\u001b[0m:\u001b[36m_get_paragraph_chunks\u001b[0m:\u001b[36m329\u001b[0m - \u001b[1mChunk length: 703\u001b[0m\n",
      "\u001b[32m2025-03-16 08:53:44.174\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthetic_data.tasks.writing\u001b[0m:\u001b[36m_get_paragraph_chunks\u001b[0m:\u001b[36m329\u001b[0m - \u001b[1mChunk length: 655\u001b[0m\n",
      "\u001b[32m2025-03-16 08:53:44.175\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthetic_data.tasks.writing\u001b[0m:\u001b[36m_get_paragraph_chunks\u001b[0m:\u001b[36m329\u001b[0m - \u001b[1mChunk length: 695\u001b[0m\n",
      "\u001b[32m2025-03-16 08:53:44.175\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthetic_data.tasks.writing\u001b[0m:\u001b[36m_get_paragraph_chunks\u001b[0m:\u001b[36m329\u001b[0m - \u001b[1mChunk length: 741\u001b[0m\n",
      "\u001b[32m2025-03-16 08:53:44.176\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthetic_data.tasks.writing\u001b[0m:\u001b[36m_get_paragraph_chunks\u001b[0m:\u001b[36m329\u001b[0m - \u001b[1mChunk length: 645\u001b[0m\n",
      "\u001b[32m2025-03-16 08:53:44.176\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthetic_data.tasks.writing\u001b[0m:\u001b[36m_get_paragraph_chunks\u001b[0m:\u001b[36m329\u001b[0m - \u001b[1mChunk length: 608\u001b[0m\n",
      "\u001b[32m2025-03-16 08:53:44.177\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthetic_data.tasks.writing\u001b[0m:\u001b[36m_get_paragraph_chunks\u001b[0m:\u001b[36m329\u001b[0m - \u001b[1mChunk length: 786\u001b[0m\n",
      "\u001b[32m2025-03-16 08:53:44.178\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthetic_data.tasks.writing\u001b[0m:\u001b[36m_get_paragraph_chunks\u001b[0m:\u001b[36m329\u001b[0m - \u001b[1mChunk length: 791\u001b[0m\n",
      "\u001b[32m2025-03-16 08:53:44.178\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthetic_data.tasks.writing\u001b[0m:\u001b[36m_get_paragraph_chunks\u001b[0m:\u001b[36m329\u001b[0m - \u001b[1mChunk length: 819\u001b[0m\n",
      "\u001b[32m2025-03-16 08:53:44.179\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthetic_data.tasks.writing\u001b[0m:\u001b[36m_get_paragraph_chunks\u001b[0m:\u001b[36m329\u001b[0m - \u001b[1mChunk length: 824\u001b[0m\n",
      "\u001b[32m2025-03-16 08:53:44.179\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthetic_data.tasks.writing\u001b[0m:\u001b[36m_get_paragraph_chunks\u001b[0m:\u001b[36m329\u001b[0m - \u001b[1mChunk length: 706\u001b[0m\n",
      "\u001b[32m2025-03-16 08:53:44.180\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthetic_data.tasks.writing\u001b[0m:\u001b[36m_get_paragraph_chunks\u001b[0m:\u001b[36m329\u001b[0m - \u001b[1mChunk length: 833\u001b[0m\n",
      "\u001b[32m2025-03-16 08:53:44.180\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthetic_data.tasks.writing\u001b[0m:\u001b[36m_get_paragraph_chunks\u001b[0m:\u001b[36m329\u001b[0m - \u001b[1mChunk length: 877\u001b[0m\n",
      "\u001b[32m2025-03-16 08:53:44.444\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthetic_data.tasks.writing\u001b[0m:\u001b[36m_get_paragraph_chunks\u001b[0m:\u001b[36m329\u001b[0m - \u001b[1mChunk length: 811\u001b[0m\n",
      "\u001b[32m2025-03-16 08:53:44.444\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthetic_data.tasks.writing\u001b[0m:\u001b[36m_get_paragraph_chunks\u001b[0m:\u001b[36m329\u001b[0m - \u001b[1mChunk length: 630\u001b[0m\n",
      "\u001b[32m2025-03-16 08:53:44.445\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthetic_data.tasks.writing\u001b[0m:\u001b[36m_get_paragraph_chunks\u001b[0m:\u001b[36m329\u001b[0m - \u001b[1mChunk length: 1032\u001b[0m\n",
      "\u001b[32m2025-03-16 08:53:45.342\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthetic_data.tasks.writing\u001b[0m:\u001b[36m_get_paragraph_chunks\u001b[0m:\u001b[36m329\u001b[0m - \u001b[1mChunk length: 758\u001b[0m\n",
      "\u001b[32m2025-03-16 08:53:45.452\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthetic_data.tasks.writing\u001b[0m:\u001b[36m_get_paragraph_chunks\u001b[0m:\u001b[36m329\u001b[0m - \u001b[1mChunk length: 632\u001b[0m\n",
      "\u001b[32m2025-03-16 08:53:45.452\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthetic_data.tasks.writing\u001b[0m:\u001b[36m_get_paragraph_chunks\u001b[0m:\u001b[36m329\u001b[0m - \u001b[1mChunk length: 664\u001b[0m\n",
      "\u001b[32m2025-03-16 08:53:45.453\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthetic_data.tasks.writing\u001b[0m:\u001b[36m_get_paragraph_chunks\u001b[0m:\u001b[36m329\u001b[0m - \u001b[1mChunk length: 991\u001b[0m\n",
      "\u001b[32m2025-03-16 08:53:45.453\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthetic_data.tasks.writing\u001b[0m:\u001b[36m_get_paragraph_chunks\u001b[0m:\u001b[36m329\u001b[0m - \u001b[1mChunk length: 618\u001b[0m\n",
      "\u001b[32m2025-03-16 08:53:45.644\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msynthetic_data.tasks.writing\u001b[0m:\u001b[36mformat_input_conversation\u001b[0m:\u001b[36m389\u001b[0m - \u001b[33m\u001b[1mNo chunks found for conundrum-jeff-crook(ThoseBooks).Epub.txt\u001b[0m\n",
      "\u001b[32m2025-03-16 08:53:45.644\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msynthetic_data.tasks.writing\u001b[0m:\u001b[36mformat_input_conversation\u001b[0m:\u001b[36m389\u001b[0m - \u001b[33m\u001b[1mNo chunks found for 9781681775180(1).epub.txt\u001b[0m\n",
      "\u001b[32m2025-03-16 08:53:45.644\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msynthetic_data.tasks.writing\u001b[0m:\u001b[36mformat_input_conversation\u001b[0m:\u001b[36m389\u001b[0m - \u001b[33m\u001b[1mNo chunks found for 9781472819260(1).epub.txt\u001b[0m\n",
      "\u001b[32m2025-03-16 08:53:45.644\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msynthetic_data.tasks.writing\u001b[0m:\u001b[36mformat_input_conversation\u001b[0m:\u001b[36m389\u001b[0m - \u001b[33m\u001b[1mNo chunks found for the-eventide-child-c-a-hines(ThoseBooks).Epub.txt\u001b[0m\n",
      "\u001b[32m2025-03-16 08:53:45.645\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msynthetic_data.tasks.writing\u001b[0m:\u001b[36mformat_input_conversation\u001b[0m:\u001b[36m389\u001b[0m - \u001b[33m\u001b[1mNo chunks found for the-citadel-richard-a-knaak(ThoseBooks).Epub.txt\u001b[0m\n",
      "\u001b[32m2025-03-16 08:53:45.645\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msynthetic_data.tasks.writing\u001b[0m:\u001b[36mformat_input_conversation\u001b[0m:\u001b[36m389\u001b[0m - \u001b[33m\u001b[1mNo chunks found for 9780385541787(1).epub.txt\u001b[0m\n",
      "\u001b[32m2025-03-16 08:53:45.645\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msynthetic_data.tasks.writing\u001b[0m:\u001b[36mformat_input_conversation\u001b[0m:\u001b[36m389\u001b[0m - \u001b[33m\u001b[1mNo chunks found for glyphbinder-t-eric-bakutis(ThoseBooks).Epub.txt\u001b[0m\n",
      "\u001b[32m2025-03-16 08:53:45.645\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msynthetic_data.tasks.writing\u001b[0m:\u001b[36mformat_input_conversation\u001b[0m:\u001b[36m389\u001b[0m - \u001b[33m\u001b[1mNo chunks found for 9781542515481(1).epub.txt\u001b[0m\n",
      "\u001b[32m2025-03-16 08:53:45.645\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msynthetic_data.tasks.writing\u001b[0m:\u001b[36mformat_input_conversation\u001b[0m:\u001b[36m389\u001b[0m - \u001b[33m\u001b[1mNo chunks found for past-life-strife-christina-mcmullen(ThoseBooks).Epub.txt\u001b[0m\n",
      "\u001b[32m2025-03-16 08:53:45.645\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msynthetic_data.tasks.writing\u001b[0m:\u001b[36mformat_input_conversation\u001b[0m:\u001b[36m389\u001b[0m - \u001b[33m\u001b[1mNo chunks found for 9780441018529(1).epub.txt\u001b[0m\n",
      "\u001b[32m2025-03-16 08:53:45.646\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msynthetic_data.tasks.writing\u001b[0m:\u001b[36mformat_input_conversation\u001b[0m:\u001b[36m389\u001b[0m - \u001b[33m\u001b[1mNo chunks found for 9781613749937(1).epub.txt\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "task_out = task.format_input_conversation(dataset[0:16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(task_out[0][0]['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"../.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-03-16 08:53:48.474\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthetic_data.generation\u001b[0m:\u001b[36mget_generation_wrapper\u001b[0m:\u001b[36m427\u001b[0m - \u001b[1mLogging in to Hugging Face Hub\u001b[0m\n",
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    }
   ],
   "source": [
    "from synthetic_data.generation import get_generation_wrapper\n",
    "\n",
    "\n",
    "generation_wrapper = get_generation_wrapper(\"gemini-2.0-flash\")\n",
    "completions = await generation_wrapper.generate(\n",
    "    task_out\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_rows_batch = task.format_output_rows(completions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write a paragraph introducing several characters from an urban fantasy setting. The style should be concise and descriptive, similar to a character sheet or dossier. Each character entry should include their name, role/affiliation, gender, age (approximate), physical appearance, and a key skill or personality trait. Use short, declarative sentences and a straightforward, almost clinical tone.\n",
      "\n",
      "Present five characters. The first should be a powerful leader of shapeshifters, giving details about their animal form and fighting style. The second should be another shapeshifter, emphasizing their security role, paranoia, and a past connection with a previous mentioned character that was not romantic. The third should be a smaller-statured character, contrasting their appearance with their legal expertise and protectiveness over a main character. The fourth character should be female, highlighting her unique heritage as beastkin (a hybrid shapeshifter), detailing her past trauma, incredible skill, and current role. The final character should be male, from a different shapeshifter group, and currently engaged to the previous female character. Mention his attractiveness, flirtatious nature, and respect earned despite initial negative perceptions. Refer to past significant events that influenced current relationships, without explicitly naming them.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(output_rows_batch[0]['instruction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "from synthetic_data.gutenberg_parser import super_cleaner\n",
    "from synthetic_data.tasks.writing import find_valid_paragraph_chunks\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "tiktoken_encoder = tiktoken.get_encoding(\"o200k_base\")\n",
    "\n",
    "df_sampled = df.sample(100)\n",
    "for row in df.iter_rows(named=True):\n",
    "    text = row[\"text\"]\n",
    "    paragraphs = super_cleaner(text)\n",
    "\n",
    "    # find chunks of consecutive paragraphs with dialogue and at least 3 sentences\n",
    "    valid_chunks = find_valid_paragraph_chunks(paragraphs, tiktoken_encoder)\n",
    "    display(Markdown(f\"### {row['title']}\"))\n",
    "    for chunk in valid_chunks:\n",
    "        display(Markdown(chunk[0]))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from trl_wrapper.trainer_wrapper import TrainerWrapper, GRPO_WRITING_CONFIG, SMOL_LM_135M\n",
    "\n",
    "cfg = GRPO_WRITING_CONFIG\n",
    "cfg.train_batch_size = 2\n",
    "cfg.num_generations = 2\n",
    "cfg.model_id_or_path = SMOL_LM_135M\n",
    "cfg.notebook_mode = True\n",
    "cfg.max_samples = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-12 10:58:17.417\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtrl_wrapper.trainer_wrapper\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m289\u001b[0m - \u001b[1mSetting padding side to: right\u001b[0m\n",
      "\u001b[32m2025-04-12 10:58:17.430\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtrl_wrapper.trainer_wrapper\u001b[0m:\u001b[36minit_model\u001b[0m:\u001b[36m300\u001b[0m - \u001b[1mUsing device: mps\u001b[0m\n",
      "\u001b[32m2025-04-12 10:58:17.430\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtrl_wrapper.trainer_wrapper\u001b[0m:\u001b[36minit_model\u001b[0m:\u001b[36m314\u001b[0m - \u001b[1mLoading model HuggingFaceTB/SmolLM2-135M-Instruct with attn_impl: sdpa\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "wrapper = TrainerWrapper(cfg)\n",
    "wrapper.init_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-12 11:00:22.498\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtrl_wrapper.trainer_wrapper\u001b[0m:\u001b[36minit_data_module\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mUsing chat template override: smollmv2\u001b[0m\n",
      "\u001b[32m2025-04-12 11:00:22.498\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtrl_wrapper.wrapper_config\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m145\u001b[0m - \u001b[1mCache dir: ../dataset_caches/writing_g_r_p_o_data_module\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "wrapper.init_data_module()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['instruction', 'paragraph', 'text', 'title', 'author', 'id'],\n",
       "    num_rows: 10647\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrapper.data_module.train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Write a science fiction paragraph in a gritty, military style, focusing on a protagonist, Ensign Riley, who is being unfairly targeted by superiors on a spaceship. The tone should be weary and resentful, highlighting the protagonist\\'s exhaustion and frustration. Start with an alarm blaring and a ship-wide announcement of a \"containment failure.\"\\n\\nRiley should be abruptly awakened from a too-short sleep cycle following a long, mandated shift. He\\'s been consistently assigned unfavorable shifts despite regulations due to a vindictive superior, Lieutenant Commander Thorne. His sleep is further disrupted by more senior officers, Lieutenants Carr, Davis, and Flores, who deliberately inconvenience him, forcing him to perform demeaning tasks.\\n\\nInclude an incident where his personal belongings are tampered with, resulting in Riley having to scramble to prepare for duty. As a result of these deliberate delays, he arrives late and improperly dressed for his station. The paragraph should culminate in his being dismissed from duty by a senior officer, creating a sense of further injustice and resentment. Indicate the situation will reflect poorly on his permanent record.\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrapper.data_module.train_dataset[0]['instruction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-01 22:28:59.993\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtrl_wrapper.trainer_wrapper\u001b[0m:\u001b[36minit_trainer\u001b[0m:\u001b[36m388\u001b[0m - \u001b[1mSaving output to: ./runs/04-01-22-28-940771-smollm2-135m-instruct--txt-bt-dpo\u001b[0m\n",
      "\u001b[32m2025-04-01 22:28:59.995\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtrl_wrapper.trainer_wrapper\u001b[0m:\u001b[36minit_trainer\u001b[0m:\u001b[36m411\u001b[0m - \u001b[1mInitializing trainer, run_name: 04-01-22-28-940771-smollm2-135m-instruct--txt-bt-dpo, wandb project: gutenberg\u001b[0m\n",
      "\u001b[32m2025-04-01 22:28:59.995\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtrl_wrapper.trainer_wrapper\u001b[0m:\u001b[36minit_trainer\u001b[0m:\u001b[36m418\u001b[0m - \u001b[1mlogprobs cache location: ../dataset_caches/writing_d_p_o_data_module/b68b303b/ref_logprobs_cache peft config: False\u001b[0m\n",
      "Extracting prompt in train dataset: 100%|██████████| 9299/9299 [00:01<00:00, 9274.34 examples/s]\n",
      "Applying chat template to train dataset: 100%|██████████| 9299/9299 [00:00<00:00, 12389.00 examples/s]\n",
      "Tokenizing train dataset: 100%|██████████| 9299/9299 [00:18<00:00, 493.42 examples/s]\n",
      "Extracting prompt in eval dataset: 100%|██████████| 1034/1034 [00:00<00:00, 8973.96 examples/s]\n",
      "Applying chat template to eval dataset: 100%|██████████| 1034/1034 [00:00<00:00, 11906.12 examples/s]\n",
      "Tokenizing eval dataset: 100%|██████████| 1034/1034 [00:02<00:00, 513.38 examples/s]\n",
      "\u001b[32m2025-04-01 22:29:22.895\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtrl_wrapper.trainer_wrapper\u001b[0m:\u001b[36minit_trainer\u001b[0m:\u001b[36m637\u001b[0m - \u001b[1mPrecomputing reference logprobs, batch size: 16\u001b[0m\n",
      "\u001b[32m2025-04-01 22:29:22.896\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtrl_wrapper.trainer_wrapper\u001b[0m:\u001b[36minit_trainer\u001b[0m:\u001b[36m644\u001b[0m - \u001b[1mPrecomputing train logprobs\u001b[0m\n",
      "Train dataset reference log probs:   0%|          | 0/582 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "wrapper.init_trainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.reasoning import GSM8K_SYSTEM_PROMPT, CONNECTIONS_PROMPT\n",
    "from model.utils import get_available_device\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": CONNECTIONS_PROMPT},\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"train, panda, dove, series, wind, bear, orca, bass, string, skunk, speed, sand, zebra, tourist, desert, chain\",\n",
    "    },\n",
    "]\n",
    "tokenized_chat = wrapper.tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=True,\n",
    "    add_generation_prompt=True,\n",
    "    return_tensors=\"pt\",\n",
    "    return_attention_mask=True,\n",
    ")\n",
    "\n",
    "device = get_available_device()\n",
    "tokenized_chat = tokenized_chat.to(device)\n",
    "out = wrapper.model.generate(tokenized_chat, max_length=1024)\n",
    "print(wrapper.tokenizer.decode(out[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapper.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

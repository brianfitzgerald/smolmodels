{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brianfitzgerald/Documents/GitHub/smolmodels/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-04-20 16:50:26,709\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from trl_wrapper.trainer_wrapper import TrainerWrapper, WRITING_GRPO_CONFIG, SMOL_LM_135M\n",
    "\n",
    "cfg = WRITING_GRPO_CONFIG\n",
    "cfg.train_batch_size = 2\n",
    "cfg.num_generations = 2\n",
    "cfg.model_id_or_path = SMOL_LM_135M\n",
    "cfg.max_samples = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-20 16:50:27.951\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtrl_wrapper.trainer_wrapper\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m307\u001b[0m - \u001b[1mSetting padding side to: right\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "wrapper = TrainerWrapper(cfg, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-20 16:50:27.989\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtrl_wrapper.trainer_wrapper\u001b[0m:\u001b[36minit_data_module\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mUsing chat template override: smollmv2\u001b[0m\n",
      "Map: 100%|██████████| 10647/10647 [00:00<00:00, 28199.50 examples/s]\n",
      "Map: 100%|██████████| 1184/1184 [00:00<00:00, 29004.79 examples/s]\n",
      "\u001b[32m2025-04-20 16:50:28.823\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthetic_data.writing_judge\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mrun_mode: notebook\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "wrapper.init_data_module()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-20 16:50:28.914\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtrl_wrapper.trainer_wrapper\u001b[0m:\u001b[36minit_model\u001b[0m:\u001b[36m322\u001b[0m - \u001b[1mUsing device: mps\u001b[0m\n",
      "\u001b[32m2025-04-20 16:50:28.914\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtrl_wrapper.trainer_wrapper\u001b[0m:\u001b[36minit_model\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mLoading model HuggingFaceTB/SmolLM2-135M-Instruct with attn_impl: sdpa\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "wrapper.init_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'notebook'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrapper.data_module.config.run_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-20 16:50:29.694\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtrl_wrapper.trainer_wrapper\u001b[0m:\u001b[36minit_trainer\u001b[0m:\u001b[36m400\u001b[0m - \u001b[1mSaving output to: ./runs/04-20-16-50-9333-smollm2-135m-instruct-\u001b[0m\n",
      "\u001b[32m2025-04-20 16:50:29.695\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtrl_wrapper.trainer_wrapper\u001b[0m:\u001b[36minit_trainer\u001b[0m:\u001b[36m423\u001b[0m - \u001b[1mInitializing trainer, run_name: 04-20-16-50-9333-smollm2-135m-instruct-, wandb project: writing-grpo\u001b[0m\n",
      "\u001b[32m2025-04-20 16:50:29.695\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtrl_wrapper.trainer_wrapper\u001b[0m:\u001b[36minit_trainer\u001b[0m:\u001b[36m506\u001b[0m - \u001b[1mUsing vllm: False\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "wrapper.init_trainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-20 16:50:29.788\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtrl_wrapper.trainer_wrapper\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m648\u001b[0m - \u001b[1mStarting training.\u001b[0m\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n",
      "DynamicCache + torch.export is tested on torch 2.6.0+ and may not work on earlier versions.\n",
      "/Users/brianfitzgerald/Documents/GitHub/smolmodels/.venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "\u001b[32m2025-04-20 16:51:02.267\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthetic_data.tasks.writing\u001b[0m:\u001b[36mscore_writing\u001b[0m:\u001b[36m412\u001b[0m - \u001b[1mJudging 2 completions with gpt-4.1-nano\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "[[{'content': 'Write a paragraph in a style reminiscent of a suspenseful, action-oriented thriller novel. The tone should be urgent and serious, conveying a sense of danger and calculated risk. Describe a scene where a character infiltrates a secure area using a diversion. The character should disable a security measure remotely while physically approaching a perimeter, triggering a chain of events designed to create chaos. Include details of the immediate aftermath of the diversion, focusing on how the character uses the resulting confusion to their advantage and makes their escape. Then, transition to describing a secondary character, or characters, who are also attempting to evade capture by remaining inconspicuous in a public setting, aware they are being hunted. Describe how these characters must make a quick decision to ensure the safety of another escaping individual. Include the elements of surprise, quick tactical decision-making, and a daring rescue involving a vehicle. Maintain short, impactful sentences to build tension.\\n', 'role': 'user'}], [{'content': 'Write a paragraph in a style reminiscent of a suspenseful, action-oriented thriller novel. The tone should be urgent and serious, conveying a sense of danger and calculated risk. Describe a scene where a character infiltrates a secure area using a diversion. The character should disable a security measure remotely while physically approaching a perimeter, triggering a chain of events designed to create chaos. Include details of the immediate aftermath of the diversion, focusing on how the character uses the resulting confusion to their advantage and makes their escape. Then, transition to describing a secondary character, or characters, who are also attempting to evade capture by remaining inconspicuous in a public setting, aware they are being hunted. Describe how these characters must make a quick decision to ensure the safety of another escaping individual. Include the elements of surprise, quick tactical decision-making, and a daring rescue involving a vehicle. Maintain short, impactful sentences to build tension.\\n', 'role': 'user'}]]\n",
      "[[{'role': 'assistant', 'content': 'As the protagonist enters the secure area, a siren\\'s haunting melody echoes through the air, a reminder of the dangers that lie ahead. But as they approach the perimeter, small, swift, and unarmored vehicles move with a quiet rhythm, their purpose unclear. A lone vehicle with a sleek leather exterior pierces the darkness, its sleek design gleaming in the dim light. Amidst the chaos, it\\'s the vehicle\\'s hood flickers, revealing a hooded figure watching with a mixture of excitement and confusion. They\\'ve been watching for months, waiting for a chance to escape. Before they can prepare, a figure with a distinctive look and a small scar emerges from the shadows, their hood pulled up tight to reveal a face that\\'s been hiding in plain sight. \"I\\'m the one,\" the figure says, their voice firm but measured, \"I have a job. You have another.\" The door to the vehicle\\'s interior swings back, revealing a group of two individuals, each of whom are carrying a small, black leather carrying case. They are the last to step outside, their faces hidden in the hooded vehicle as they search for a way to escape. As they turn, a man with a face full of scars appears, his eyes scanning the room with a mix of desperation and caution. \"I\\'m trying to find my way,\" he says, his voice barely audible. \"But every path leads to destruction.\" The door to the vehicle starts slamming shut, revealing the figure in the case, seemingly out of nowhere. The vehicle shudders and bounces, its wheels rattling softly on the asphalt. The figure and the car blur together, each one moving with a speed that\\'s nearly imperceptible. The camera zooms to the moment when the vehicle\\'s hood opens to reveal a figure with a mane of curly red hair, a mop of blonde hair and a distinctive look. The figure is wearing a simple, yet elegant clothing, a pair of dark leather pants with a black skirt, and a pair of scuffed leather boots. The woman, with a small accent, is wearing a black hoodie that\\'s been worn many times before, and her eyes are an unusual shade of brown, almost as if she\\'s hiding something. The car\\'s hood swings back, revealing the body of a woman with gray hair and a bushy mustache, the face of a woman in her late 30s, with a few tiny dents and scratches above the left eyebrow. The vehicle\\'s hood'}], [{'role': 'assistant', 'content': 'As the comms system crackled in the warehouse\\'s central room, the figure of a female officer stumbled upon the entrance. She looked around, searching her surroundings, only to catch sight of the small, high-tech security system, a small, sleek device that served as a surveillance beacon.\\n\\nShe made her way down the corridor, the door slamming behind her as she navigated the dimly lit area. As she cleared her throat, the systems began to hum, with a single, pulsating light flickering to life in the vicinity of the perimeter, a subtle indicator of its state.\\n\\nThe officer made her way through the narrow hallways, her eyes adjusting to the dim light. She spotted a lone figure huddled in a corner, half-hidden behind a piece of wall-mounted security gear. The officer, who was still staring at her, noticed her glancing at an unknown number, and a tense, silent pause emerged.\\n\\nShe approached cautiously, her comms device on her wrist. \"I\\'m in,\" she said. \"Can you follow me?\"\\n\\nAs they stepped into a dimly lit elevator shaft, the officer reached her. \"Yes, sir,\" she said. \"Follow me.\"\\n\\nThe officer jumped into the elevator. As it slid up a short corridor, the room seemed to reek of mystery and disarray. The figure in the corner was now on the other side.\\n\\nThe officer pushed open the door. What followed was a disorienting, chaotic ride. She struggled to regain her footing, but each step proved futile.\\n\\nThe officer then slowly backed away, her eyes scanning the room. \"This place is not to be missed,\" she said. \"I need to know you are in danger.\"\\n\\nA wave of fear and panic washed over the officer. \"What did you do?\"\\n\\nThe officer smiled. \"No, I did not. I am Detective Jameson.\"\\n\\nAs she spoke, the figure shifted the room, and the officer was forced to remain there. \"What is happening?\"\\n\\nThe figure\\'s voice was shaking, trying to reassure her. \"I am trying to retrieve a valuable item. You will pay the price.\"\\n\\nThe officer\\'s grip on her hands tightened. \"How do you feel?\"\\n\\nThe officer hesitated, then looked down at her. \"I will be fine,\" she said.\\n\\nThe officer felt a small surge of fear and desperation. But she'}]]\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-20 16:51:05.194\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset.writing\u001b[0m:\u001b[36mllm_judge_func\u001b[0m:\u001b[36m150\u001b[0m - \u001b[1mSample scores - totals: [0.43, 0.28]\u001b[0m\n",
      "\u001b[32m2025-04-20 16:51:05.195\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset.writing\u001b[0m:\u001b[36mllm_judge_func\u001b[0m:\u001b[36m152\u001b[0m - \u001b[1m\tAdherence to Instructions: [10.0, 8.0]\u001b[0m\n",
      "\u001b[32m2025-04-20 16:51:05.195\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset.writing\u001b[0m:\u001b[36mllm_judge_func\u001b[0m:\u001b[36m152\u001b[0m - \u001b[1m\tBelievable Character Actions: [8.0, 5.0]\u001b[0m\n",
      "\u001b[32m2025-04-20 16:51:05.195\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset.writing\u001b[0m:\u001b[36mllm_judge_func\u001b[0m:\u001b[36m152\u001b[0m - \u001b[1m\tNuanced Characters: [7.0, 4.0]\u001b[0m\n",
      "\u001b[32m2025-04-20 16:51:05.196\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset.writing\u001b[0m:\u001b[36mllm_judge_func\u001b[0m:\u001b[36m152\u001b[0m - \u001b[1m\tConsistent Voice/Tone of Writing: [9.0, 10.0]\u001b[0m\n",
      "\u001b[32m2025-04-20 16:51:05.196\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset.writing\u001b[0m:\u001b[36mllm_judge_func\u001b[0m:\u001b[36m152\u001b[0m - \u001b[1m\tImagery and Descriptive Quality: [10.0, 6.0]\u001b[0m\n",
      "\u001b[32m2025-04-20 16:51:05.196\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset.writing\u001b[0m:\u001b[36mllm_judge_func\u001b[0m:\u001b[36m152\u001b[0m - \u001b[1m\tElegant Prose: [8.0, 4.0]\u001b[0m\n",
      "\u001b[32m2025-04-20 16:51:05.196\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset.writing\u001b[0m:\u001b[36mllm_judge_func\u001b[0m:\u001b[36m152\u001b[0m - \u001b[1m\tEmotionally Engaging: [6.0, 5.0]\u001b[0m\n",
      "\u001b[32m2025-04-20 16:51:05.196\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset.writing\u001b[0m:\u001b[36mllm_judge_func\u001b[0m:\u001b[36m152\u001b[0m - \u001b[1m\tEmotionally Complex: [5.0, 3.0]\u001b[0m\n",
      "\u001b[32m2025-04-20 16:51:05.197\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset.writing\u001b[0m:\u001b[36mllm_judge_func\u001b[0m:\u001b[36m152\u001b[0m - \u001b[1m\tCoherent: [6.0, 4.0]\u001b[0m\n",
      "\u001b[32m2025-04-20 16:51:05.197\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset.writing\u001b[0m:\u001b[36mllm_judge_func\u001b[0m:\u001b[36m152\u001b[0m - \u001b[1m\tMeandering: [4.0, 12.0]\u001b[0m\n",
      "\u001b[32m2025-04-20 16:51:05.197\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset.writing\u001b[0m:\u001b[36mllm_judge_func\u001b[0m:\u001b[36m152\u001b[0m - \u001b[1m\tWeak Dialogue: [7.0, 4.0]\u001b[0m\n",
      "\u001b[32m2025-04-20 16:51:05.197\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset.writing\u001b[0m:\u001b[36mllm_judge_func\u001b[0m:\u001b[36m152\u001b[0m - \u001b[1m\tTell-Don't-Show: [12.0, 7.0]\u001b[0m\n",
      "\u001b[32m2025-04-20 16:51:05.198\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset.writing\u001b[0m:\u001b[36mllm_judge_func\u001b[0m:\u001b[36m152\u001b[0m - \u001b[1m\tUnsurprising or Uncreative: [9.0, 6.0]\u001b[0m\n",
      "\u001b[32m2025-04-20 16:51:05.198\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset.writing\u001b[0m:\u001b[36mllm_judge_func\u001b[0m:\u001b[36m152\u001b[0m - \u001b[1m\tAmateurish: [8.0, 7.0]\u001b[0m\n",
      "\u001b[32m2025-04-20 16:51:05.198\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset.writing\u001b[0m:\u001b[36mllm_judge_func\u001b[0m:\u001b[36m152\u001b[0m - \u001b[1m\tPurple Prose: [11.0, 3.0]\u001b[0m\n",
      "\u001b[32m2025-04-20 16:51:05.198\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset.writing\u001b[0m:\u001b[36mllm_judge_func\u001b[0m:\u001b[36m152\u001b[0m - \u001b[1m\tOverwrought: [10.0, 4.0]\u001b[0m\n",
      "\u001b[32m2025-04-20 16:51:05.198\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset.writing\u001b[0m:\u001b[36mllm_judge_func\u001b[0m:\u001b[36m152\u001b[0m - \u001b[1m\tIncongruent Ending Positivity: [15.0, 8.0]\u001b[0m\n",
      "\u001b[32m2025-04-20 16:51:05.199\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset.writing\u001b[0m:\u001b[36mllm_judge_func\u001b[0m:\u001b[36m152\u001b[0m - \u001b[1m\tUnearned Transformations: [14.0, 5.0]\u001b[0m\n",
      "\u001b[32m2025-04-20 16:51:05.199\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset.writing\u001b[0m:\u001b[36mllm_judge_func\u001b[0m:\u001b[36m152\u001b[0m - \u001b[1m\tWell-earned Lightness or Darkness: [12.0, 6.0]\u001b[0m\n",
      "\u001b[32m2025-04-20 16:51:05.199\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset.writing\u001b[0m:\u001b[36mllm_judge_func\u001b[0m:\u001b[36m152\u001b[0m - \u001b[1m\tSentences Flow Naturally: [7.0, 5.0]\u001b[0m\n",
      "\u001b[32m2025-04-20 16:51:05.199\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset.writing\u001b[0m:\u001b[36mllm_judge_func\u001b[0m:\u001b[36m152\u001b[0m - \u001b[1m\tOverall Reader Engagement: [6.0, 4.0]\u001b[0m\n",
      "\u001b[32m2025-04-20 16:51:05.199\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset.writing\u001b[0m:\u001b[36mllm_judge_func\u001b[0m:\u001b[36m152\u001b[0m - \u001b[1m\tOverall Impression: [7.0, 4.0]\u001b[0m\n",
      "\u001b[32m2025-04-20 16:51:05.212\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmodel.reasoning\u001b[0m:\u001b[36mlogger_reward\u001b[0m:\u001b[36m229\u001b[0m - \u001b[1mGenerations:\u001b[0m\n",
      "\u001b[32m2025-04-20 16:51:05.213\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmodel.reasoning\u001b[0m:\u001b[36mlogger_reward\u001b[0m:\u001b[36m231\u001b[0m - \u001b[1m========================================\u001b[0m\n",
      "\u001b[32m2025-04-20 16:51:05.213\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmodel.reasoning\u001b[0m:\u001b[36mlogger_reward\u001b[0m:\u001b[36m232\u001b[0m - \u001b[1mPrompt 0: --------------------\u001b[0m\n",
      "\u001b[32m2025-04-20 16:51:05.213\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmodel.reasoning\u001b[0m:\u001b[36mlogger_reward\u001b[0m:\u001b[36m233\u001b[0m - \u001b[1mWrite a paragraph in a style reminiscent of a suspenseful, action-oriented thriller novel. The tone should be urgent and serious, conveying a sense of danger and calculated risk. Describe a scene where a character infiltrates a secure area using a diversion. The character should disable a security measure remotely while physically approaching a perimeter, triggering a chain of events designed to create chaos. Include details of the immediate aftermath of the diversion, focusing on how the character uses the resulting confusion to their advantage and makes their escape. Then, transition to describing a secondary character, or characters, who are also attempting to evade capture by remaining inconspicuous in a public setting, aware they are being hunted. Describe how these characters must make a quick decision to ensure the safety of another escaping individual. Include the elements of surprise, quick tactical decision-making, and a daring rescue involving a vehicle. Maintain short, impactful sentences to build tension.\n",
      "\u001b[0m\n",
      "\u001b[32m2025-04-20 16:51:05.213\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmodel.reasoning\u001b[0m:\u001b[36mlogger_reward\u001b[0m:\u001b[36m234\u001b[0m - \u001b[1mGeneration: --------------------\u001b[0m\n",
      "\u001b[32m2025-04-20 16:51:05.214\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmodel.reasoning\u001b[0m:\u001b[36mlogger_reward\u001b[0m:\u001b[36m235\u001b[0m - \u001b[1mAs the protagonist enters the secure area, a siren's haunting melody echoes through the air, a reminder of the dangers that lie ahead. But as they approach the perimeter, small, swift, and unarmored vehicles move with a quiet rhythm, their purpose unclear. A lone vehicle with a sleek leather exterior pierces the darkness, its sleek design gleaming in the dim light. Amidst the chaos, it's the vehicle's hood flickers, revealing a hooded figure watching with a mixture of excitement and confusion. They've been watching for months, waiting for a chance to escape. Before they can prepare, a figure with a distinctive look and a small scar emerges from the shadows, their hood pulled up tight to reveal a face that's been hiding in plain sight. \"I'm the one,\" the figure says, their voice firm but measured, \"I have a job. You have another.\" The door to the vehicle's interior swings back, revealing a group of two individuals, each of whom are carrying a small, black leather carrying case. They are the last to step outside, their faces hidden in the hooded vehicle as they search for a way to escape. As they turn, a man with a face full of scars appears, his eyes scanning the room with a mix of desperation and caution. \"I'm trying to find my way,\" he says, his voice barely audible. \"But every path leads to destruction.\" The door to the vehicle starts slamming shut, revealing the figure in the case, seemingly out of nowhere. The vehicle shudders and bounces, its wheels rattling softly on the asphalt. The figure and the car blur together, each one moving with a speed that's nearly imperceptible. The camera zooms to the moment when the vehicle's hood opens to reveal a figure with a mane of curly red hair, a mop of blonde hair and a distinctive look. The figure is wearing a simple, yet elegant clothing, a pair of dark leather pants with a black skirt, and a pair of scuffed leather boots. The woman, with a small accent, is wearing a black hoodie that's been worn many times before, and her eyes are an unusual shade of brown, almost as if she's hiding something. The car's hood swings back, revealing the body of a woman with gray hair and a bushy mustache, the face of a woman in her late 30s, with a few tiny dents and scratches above the left eyebrow. The vehicle's hood\u001b[0m\n",
      "\u001b[32m2025-04-20 16:51:05.214\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmodel.reasoning\u001b[0m:\u001b[36mlogger_reward\u001b[0m:\u001b[36m231\u001b[0m - \u001b[1m========================================\u001b[0m\n",
      "\u001b[32m2025-04-20 16:51:05.215\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmodel.reasoning\u001b[0m:\u001b[36mlogger_reward\u001b[0m:\u001b[36m232\u001b[0m - \u001b[1mPrompt 1: --------------------\u001b[0m\n",
      "\u001b[32m2025-04-20 16:51:05.215\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmodel.reasoning\u001b[0m:\u001b[36mlogger_reward\u001b[0m:\u001b[36m233\u001b[0m - \u001b[1mWrite a paragraph in a style reminiscent of a suspenseful, action-oriented thriller novel. The tone should be urgent and serious, conveying a sense of danger and calculated risk. Describe a scene where a character infiltrates a secure area using a diversion. The character should disable a security measure remotely while physically approaching a perimeter, triggering a chain of events designed to create chaos. Include details of the immediate aftermath of the diversion, focusing on how the character uses the resulting confusion to their advantage and makes their escape. Then, transition to describing a secondary character, or characters, who are also attempting to evade capture by remaining inconspicuous in a public setting, aware they are being hunted. Describe how these characters must make a quick decision to ensure the safety of another escaping individual. Include the elements of surprise, quick tactical decision-making, and a daring rescue involving a vehicle. Maintain short, impactful sentences to build tension.\n",
      "\u001b[0m\n",
      "\u001b[32m2025-04-20 16:51:05.215\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmodel.reasoning\u001b[0m:\u001b[36mlogger_reward\u001b[0m:\u001b[36m234\u001b[0m - \u001b[1mGeneration: --------------------\u001b[0m\n",
      "\u001b[32m2025-04-20 16:51:05.216\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmodel.reasoning\u001b[0m:\u001b[36mlogger_reward\u001b[0m:\u001b[36m235\u001b[0m - \u001b[1mAs the comms system crackled in the warehouse's central room, the figure of a female officer stumbled upon the entrance. She looked around, searching her surroundings, only to catch sight of the small, high-tech security system, a small, sleek device that served as a surveillance beacon.\n",
      "\n",
      "She made her way down the corridor, the door slamming behind her as she navigated the dimly lit area. As she cleared her throat, the systems began to hum, with a single, pulsating light flickering to life in the vicinity of the perimeter, a subtle indicator of its state.\n",
      "\n",
      "The officer made her way through the narrow hallways, her eyes adjusting to the dim light. She spotted a lone figure huddled in a corner, half-hidden behind a piece of wall-mounted security gear. The officer, who was still staring at her, noticed her glancing at an unknown number, and a tense, silent pause emerged.\n",
      "\n",
      "She approached cautiously, her comms device on her wrist. \"I'm in,\" she said. \"Can you follow me?\"\n",
      "\n",
      "As they stepped into a dimly lit elevator shaft, the officer reached her. \"Yes, sir,\" she said. \"Follow me.\"\n",
      "\n",
      "The officer jumped into the elevator. As it slid up a short corridor, the room seemed to reek of mystery and disarray. The figure in the corner was now on the other side.\n",
      "\n",
      "The officer pushed open the door. What followed was a disorienting, chaotic ride. She struggled to regain her footing, but each step proved futile.\n",
      "\n",
      "The officer then slowly backed away, her eyes scanning the room. \"This place is not to be missed,\" she said. \"I need to know you are in danger.\"\n",
      "\n",
      "A wave of fear and panic washed over the officer. \"What did you do?\"\n",
      "\n",
      "The officer smiled. \"No, I did not. I am Detective Jameson.\"\n",
      "\n",
      "As she spoke, the figure shifted the room, and the officer was forced to remain there. \"What is happening?\"\n",
      "\n",
      "The figure's voice was shaking, trying to reassure her. \"I am trying to retrieve a valuable item. You will pay the price.\"\n",
      "\n",
      "The officer's grip on her hands tightened. \"How do you feel?\"\n",
      "\n",
      "The officer hesitated, then looked down at her. \"I will be fine,\" she said.\n",
      "\n",
      "The officer felt a small surge of fear and desperation. But she\u001b[0m\n",
      "\u001b[32m2025-04-20 16:51:31.641\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthetic_data.tasks.writing\u001b[0m:\u001b[36mscore_writing\u001b[0m:\u001b[36m412\u001b[0m - \u001b[1mJudging 2 completions with gpt-4.1-nano\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "[[{'content': \"Write a science fiction scene in a guarded warehouse. The tone should be cynical and world-weary, reflecting a post-war setting where uneasy alliances are being forged. The scene involves a tense negotiation between a hardened military officer (Torin, referred to indirectly), her pragmatic colleague (Craig), a bureaucratic administrator (Ng), and a wealthy weapons manufacturer (Marteau). Marteau is attempting to sell weapons to factions previously considered enemies. He defends this decision by citing economic necessity and the inherent danger of unilateral disarmament. Torin expresses skepticism about Marteau's motives and the stability of the peace. Craig provides cynical commentary.\\n\\nInclude a discussion about the origins of a past war and the potential for future conflicts, mentioning the problematic nature of advanced technologies used by alien species. Marteau should display a detached, almost aristocratic disdain for political correctness and a keen awareness of the loopholes in existing regulations. He anticipates new legislation aimed at restricting weapons manufacturing. The scene should conclude with a tedious bureaucratic procedure handled by Ng, and a final attempt by Marteau to connect with Torin and Craig, hinting at future opportunities for collaboration despite their initial reservations. Use relatively short, punchy sentences and dialogue. Inject moments of dark humor.\\n\", 'role': 'user'}], [{'content': \"Write a science fiction scene in a guarded warehouse. The tone should be cynical and world-weary, reflecting a post-war setting where uneasy alliances are being forged. The scene involves a tense negotiation between a hardened military officer (Torin, referred to indirectly), her pragmatic colleague (Craig), a bureaucratic administrator (Ng), and a wealthy weapons manufacturer (Marteau). Marteau is attempting to sell weapons to factions previously considered enemies. He defends this decision by citing economic necessity and the inherent danger of unilateral disarmament. Torin expresses skepticism about Marteau's motives and the stability of the peace. Craig provides cynical commentary.\\n\\nInclude a discussion about the origins of a past war and the potential for future conflicts, mentioning the problematic nature of advanced technologies used by alien species. Marteau should display a detached, almost aristocratic disdain for political correctness and a keen awareness of the loopholes in existing regulations. He anticipates new legislation aimed at restricting weapons manufacturing. The scene should conclude with a tedious bureaucratic procedure handled by Ng, and a final attempt by Marteau to connect with Torin and Craig, hinting at future opportunities for collaboration despite their initial reservations. Use relatively short, punchy sentences and dialogue. Inject moments of dark humor.\\n\", 'role': 'user'}]]\n",
      "[[{'role': 'assistant', 'content': 'In the abandoned, lawless town of Eldrador, a lone figure from the outer rim approached a rusted and boarded-up store on the outskirts of town. \"Meet me there, traveler,\" the door creaked open with a hint of a menacing presence. The door was closed with a subtle, unsettling silence. \"We\\'re not here alone,\" a gruff voice boomed through the open window, \"or will you stand here and watch us?\" The door slammed shut when the voice rose, and a gruff-looking, two-wheeled vehicle sped away in a frenzied pursuit, as if a warped, unforgiving force was trying to shut it down.\\n\\nThe lone figure on the other side of the fence was a tall, gaunt man with piercing green eyes and a beard that was as long as his head. He was a seasoned military officer, with a scar above his left eyebrow and stubble from a past clash with a rival. A rugged, unruly beard had covered his features, and a thick, black belt adorned his shoulders. His boots were worn and stained, suggesting his arrival was an attempt at making a name for himself beyond the local militia.\\n\\nDespite his reputation as a straightforward leader, the man\\'s face was a map of sadness. His eyes, a deep, burning red, seemed like they were burning as he focused on the approaching vehicle. His voice was low, harsh, and with a hint of sarcasm.\\n\\nIn the vehicle, the imposing structure loomed in the distance, a large, sleek, black armored assault ship. Its surface was smooth, polished in a haze of black sand and metal, with numerous gun ports and hangar bays. A small, smoke-filled engine hummed to life, pulsing with a low, rumbling sound. In the center of the vehicle was a lone, hand-cranked engine, with the words etched onto the dash\\'s surface.\\n\\nThe man\\'s eyes flashed with fear as he approached the vehicle. \"This ship is mine, traveler,\" he said, his voice laced with a hint of malevolence. \"I\\'ve been using this ship for years, and I\\'ve seen better days.\"\\n\\nThe warlock grinned, his dark beard rising in deference. \"Aye, I\\'ve heard the rumors. It\\'s an honor to have you on board, and I believe the ship\\'s got the reputation for being a beacon of unity and cooperation'}], [{'role': 'assistant', 'content': 'As the tense negotiations resumed, the air in the room thickened with anticipation. The senior officer, Torin, leaned forward, her eyes gleaming with intensity, as if probing for any hint of deception. She smiled to herself, a calculated smile, as she presented her compelling argument to the team.\\n\\n\"The cost-benefit analysis is crucial, but let\\'s not forget the nature of the war, Karan... We can\\'t achieve peace without the resources we need to maintain it.\"\\n\\nWith a glint of purpose in her eyes, she began to murmur to herself, her voice barely audible over the din of the room. \"We\\'ll do whatever it takes to keep the peace, no matter the cost. And if that means compromising our way of life, so be it.\"\\n\\nAt that moment, the door creaked open, and a figure emerged from the shadows. The air was thick with tension, and the security team paused, waiting for their turn to intervene.\\n\\nMeanwhile, in the nearby reception area, the bureaucracy had been quietly negotiating with rogue systems. Rumors of advanced technology had started to trickle in, and some had even gone as far as to propose a new system that could potentially disrupt the peace.\\n\\nEager for a solution, a young, capable arms manufacturer, René, stepped up to the podium. He presented a proposal, one that seemed almost audacious. He had stolen technology from a rival manufacturer and used it to fabricate and create entirely new forms of assault weapons. His argument was that this technology could potentially make a major dent in the war on terror.\\n\\nEager to be at the forefront of the issue, Torin and Craig sat down across from René, the two men exchanging nervous glances. Together, they began to present their argument, one that had been simmering beneath the surface for months.\\n\\n\"And they\\'re willing to do it without us,\" René said, his tone a little rough. \"The technology is already in place, and we can use it to create something we can\\'t even imagine.\"\\n\\nTorin raised an eyebrow. \"What, you think it can\\'t be a useful tool?\"\\n\\nRené shrugged. \"Not really... It\\'s still in the dark ages. Not yet, anyway.\"\\n\\n\"But what about it?\" René asked quietly.\\n\\n\"The implications of that technology are enormous,\" said Torin. \"From a military perspective, if it can'}]]\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-20 16:51:34.649\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset.writing\u001b[0m:\u001b[36mllm_judge_func\u001b[0m:\u001b[36m150\u001b[0m - \u001b[1mSample scores - totals: [0.15, 0.46]\u001b[0m\n",
      "\u001b[32m2025-04-20 16:51:34.650\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset.writing\u001b[0m:\u001b[36mllm_judge_func\u001b[0m:\u001b[36m152\u001b[0m - \u001b[1m\tAdherence to Instructions: [2.0, 10.0]\u001b[0m\n",
      "\u001b[32m2025-04-20 16:51:34.650\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset.writing\u001b[0m:\u001b[36mllm_judge_func\u001b[0m:\u001b[36m152\u001b[0m - \u001b[1m\tBelievable Character Actions: [4.0, 8.0]\u001b[0m\n",
      "\u001b[32m2025-04-20 16:51:34.650\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset.writing\u001b[0m:\u001b[36mllm_judge_func\u001b[0m:\u001b[36m152\u001b[0m - \u001b[1m\tNuanced Characters: [3.0, 7.0]\u001b[0m\n",
      "\u001b[32m2025-04-20 16:51:34.651\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset.writing\u001b[0m:\u001b[36mllm_judge_func\u001b[0m:\u001b[36m152\u001b[0m - \u001b[1m\tConsistent Voice/Tone of Writing: [4.0, 10.0]\u001b[0m\n",
      "\u001b[32m2025-04-20 16:51:34.651\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset.writing\u001b[0m:\u001b[36mllm_judge_func\u001b[0m:\u001b[36m152\u001b[0m - \u001b[1m\tImagery and Descriptive Quality: [3.0, 9.0]\u001b[0m\n",
      "\u001b[32m2025-04-20 16:51:34.651\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset.writing\u001b[0m:\u001b[36mllm_judge_func\u001b[0m:\u001b[36m152\u001b[0m - \u001b[1m\tElegant Prose: [2.0, 8.0]\u001b[0m\n",
      "\u001b[32m2025-04-20 16:51:34.651\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset.writing\u001b[0m:\u001b[36mllm_judge_func\u001b[0m:\u001b[36m152\u001b[0m - \u001b[1m\tEmotionally Engaging: [2.0, 7.0]\u001b[0m\n",
      "\u001b[32m2025-04-20 16:51:34.651\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset.writing\u001b[0m:\u001b[36mllm_judge_func\u001b[0m:\u001b[36m152\u001b[0m - \u001b[1m\tEmotionally Complex: [2.0, 6.0]\u001b[0m\n",
      "\u001b[32m2025-04-20 16:51:34.652\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset.writing\u001b[0m:\u001b[36mllm_judge_func\u001b[0m:\u001b[36m152\u001b[0m - \u001b[1m\tCoherent: [3.0, 7.0]\u001b[0m\n",
      "\u001b[32m2025-04-20 16:51:34.652\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset.writing\u001b[0m:\u001b[36mllm_judge_func\u001b[0m:\u001b[36m152\u001b[0m - \u001b[1m\tMeandering: [4.0, 12.0]\u001b[0m\n",
      "\u001b[32m2025-04-20 16:51:34.652\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset.writing\u001b[0m:\u001b[36mllm_judge_func\u001b[0m:\u001b[36m152\u001b[0m - \u001b[1m\tWeak Dialogue: [2.0, 9.0]\u001b[0m\n",
      "\u001b[32m2025-04-20 16:51:34.652\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset.writing\u001b[0m:\u001b[36mllm_judge_func\u001b[0m:\u001b[36m152\u001b[0m - \u001b[1m\tTell-Don't-Show: [3.0, 11.0]\u001b[0m\n",
      "\u001b[32m2025-04-20 16:51:34.653\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset.writing\u001b[0m:\u001b[36mllm_judge_func\u001b[0m:\u001b[36m152\u001b[0m - \u001b[1m\tUnsurprising or Uncreative: [3.0, 10.0]\u001b[0m\n",
      "\u001b[32m2025-04-20 16:51:34.653\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset.writing\u001b[0m:\u001b[36mllm_judge_func\u001b[0m:\u001b[36m152\u001b[0m - \u001b[1m\tAmateurish: [4.0, 12.0]\u001b[0m\n",
      "\u001b[32m2025-04-20 16:51:34.653\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset.writing\u001b[0m:\u001b[36mllm_judge_func\u001b[0m:\u001b[36m152\u001b[0m - \u001b[1m\tPurple Prose: [2.0, 8.0]\u001b[0m\n",
      "\u001b[32m2025-04-20 16:51:34.653\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset.writing\u001b[0m:\u001b[36mllm_judge_func\u001b[0m:\u001b[36m152\u001b[0m - \u001b[1m\tOverwrought: [3.0, 9.0]\u001b[0m\n",
      "\u001b[32m2025-04-20 16:51:34.653\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset.writing\u001b[0m:\u001b[36mllm_judge_func\u001b[0m:\u001b[36m152\u001b[0m - \u001b[1m\tIncongruent Ending Positivity: [4.0, 13.0]\u001b[0m\n",
      "\u001b[32m2025-04-20 16:51:34.654\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset.writing\u001b[0m:\u001b[36mllm_judge_func\u001b[0m:\u001b[36m152\u001b[0m - \u001b[1m\tUnearned Transformations: [4.0, 12.0]\u001b[0m\n",
      "\u001b[32m2025-04-20 16:51:34.654\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset.writing\u001b[0m:\u001b[36mllm_judge_func\u001b[0m:\u001b[36m152\u001b[0m - \u001b[1m\tWell-earned Lightness or Darkness: [2.0, 10.0]\u001b[0m\n",
      "\u001b[32m2025-04-20 16:51:34.654\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset.writing\u001b[0m:\u001b[36mllm_judge_func\u001b[0m:\u001b[36m152\u001b[0m - \u001b[1m\tSentences Flow Naturally: [3.0, 9.0]\u001b[0m\n",
      "\u001b[32m2025-04-20 16:51:34.654\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset.writing\u001b[0m:\u001b[36mllm_judge_func\u001b[0m:\u001b[36m152\u001b[0m - \u001b[1m\tOverall Reader Engagement: [2.0, 8.0]\u001b[0m\n",
      "\u001b[32m2025-04-20 16:51:34.654\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset.writing\u001b[0m:\u001b[36mllm_judge_func\u001b[0m:\u001b[36m152\u001b[0m - \u001b[1m\tOverall Impression: [3.0, 7.0]\u001b[0m\n",
      "\u001b[32m2025-04-20 16:51:34.659\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmodel.reasoning\u001b[0m:\u001b[36mlogger_reward\u001b[0m:\u001b[36m229\u001b[0m - \u001b[1mGenerations:\u001b[0m\n",
      "\u001b[32m2025-04-20 16:51:34.660\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmodel.reasoning\u001b[0m:\u001b[36mlogger_reward\u001b[0m:\u001b[36m231\u001b[0m - \u001b[1m========================================\u001b[0m\n",
      "\u001b[32m2025-04-20 16:51:34.660\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmodel.reasoning\u001b[0m:\u001b[36mlogger_reward\u001b[0m:\u001b[36m232\u001b[0m - \u001b[1mPrompt 0: --------------------\u001b[0m\n",
      "\u001b[32m2025-04-20 16:51:34.660\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmodel.reasoning\u001b[0m:\u001b[36mlogger_reward\u001b[0m:\u001b[36m233\u001b[0m - \u001b[1mWrite a science fiction scene in a guarded warehouse. The tone should be cynical and world-weary, reflecting a post-war setting where uneasy alliances are being forged. The scene involves a tense negotiation between a hardened military officer (Torin, referred to indirectly), her pragmatic colleague (Craig), a bureaucratic administrator (Ng), and a wealthy weapons manufacturer (Marteau). Marteau is attempting to sell weapons to factions previously considered enemies. He defends this decision by citing economic necessity and the inherent danger of unilateral disarmament. Torin expresses skepticism about Marteau's motives and the stability of the peace. Craig provides cynical commentary.\n",
      "\n",
      "Include a discussion about the origins of a past war and the potential for future conflicts, mentioning the problematic nature of advanced technologies used by alien species. Marteau should display a detached, almost aristocratic disdain for political correctness and a keen awareness of the loopholes in existing regulations. He anticipates new legislation aimed at restricting weapons manufacturing. The scene should conclude with a tedious bureaucratic procedure handled by Ng, and a final attempt by Marteau to connect with Torin and Craig, hinting at future opportunities for collaboration despite their initial reservations. Use relatively short, punchy sentences and dialogue. Inject moments of dark humor.\n",
      "\u001b[0m\n",
      "\u001b[32m2025-04-20 16:51:34.660\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmodel.reasoning\u001b[0m:\u001b[36mlogger_reward\u001b[0m:\u001b[36m234\u001b[0m - \u001b[1mGeneration: --------------------\u001b[0m\n",
      "\u001b[32m2025-04-20 16:51:34.660\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmodel.reasoning\u001b[0m:\u001b[36mlogger_reward\u001b[0m:\u001b[36m235\u001b[0m - \u001b[1mIn the abandoned, lawless town of Eldrador, a lone figure from the outer rim approached a rusted and boarded-up store on the outskirts of town. \"Meet me there, traveler,\" the door creaked open with a hint of a menacing presence. The door was closed with a subtle, unsettling silence. \"We're not here alone,\" a gruff voice boomed through the open window, \"or will you stand here and watch us?\" The door slammed shut when the voice rose, and a gruff-looking, two-wheeled vehicle sped away in a frenzied pursuit, as if a warped, unforgiving force was trying to shut it down.\n",
      "\n",
      "The lone figure on the other side of the fence was a tall, gaunt man with piercing green eyes and a beard that was as long as his head. He was a seasoned military officer, with a scar above his left eyebrow and stubble from a past clash with a rival. A rugged, unruly beard had covered his features, and a thick, black belt adorned his shoulders. His boots were worn and stained, suggesting his arrival was an attempt at making a name for himself beyond the local militia.\n",
      "\n",
      "Despite his reputation as a straightforward leader, the man's face was a map of sadness. His eyes, a deep, burning red, seemed like they were burning as he focused on the approaching vehicle. His voice was low, harsh, and with a hint of sarcasm.\n",
      "\n",
      "In the vehicle, the imposing structure loomed in the distance, a large, sleek, black armored assault ship. Its surface was smooth, polished in a haze of black sand and metal, with numerous gun ports and hangar bays. A small, smoke-filled engine hummed to life, pulsing with a low, rumbling sound. In the center of the vehicle was a lone, hand-cranked engine, with the words etched onto the dash's surface.\n",
      "\n",
      "The man's eyes flashed with fear as he approached the vehicle. \"This ship is mine, traveler,\" he said, his voice laced with a hint of malevolence. \"I've been using this ship for years, and I've seen better days.\"\n",
      "\n",
      "The warlock grinned, his dark beard rising in deference. \"Aye, I've heard the rumors. It's an honor to have you on board, and I believe the ship's got the reputation for being a beacon of unity and cooperation\u001b[0m\n",
      "\u001b[32m2025-04-20 16:51:34.661\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmodel.reasoning\u001b[0m:\u001b[36mlogger_reward\u001b[0m:\u001b[36m231\u001b[0m - \u001b[1m========================================\u001b[0m\n",
      "\u001b[32m2025-04-20 16:51:34.661\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmodel.reasoning\u001b[0m:\u001b[36mlogger_reward\u001b[0m:\u001b[36m232\u001b[0m - \u001b[1mPrompt 1: --------------------\u001b[0m\n",
      "\u001b[32m2025-04-20 16:51:34.661\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmodel.reasoning\u001b[0m:\u001b[36mlogger_reward\u001b[0m:\u001b[36m233\u001b[0m - \u001b[1mWrite a science fiction scene in a guarded warehouse. The tone should be cynical and world-weary, reflecting a post-war setting where uneasy alliances are being forged. The scene involves a tense negotiation between a hardened military officer (Torin, referred to indirectly), her pragmatic colleague (Craig), a bureaucratic administrator (Ng), and a wealthy weapons manufacturer (Marteau). Marteau is attempting to sell weapons to factions previously considered enemies. He defends this decision by citing economic necessity and the inherent danger of unilateral disarmament. Torin expresses skepticism about Marteau's motives and the stability of the peace. Craig provides cynical commentary.\n",
      "\n",
      "Include a discussion about the origins of a past war and the potential for future conflicts, mentioning the problematic nature of advanced technologies used by alien species. Marteau should display a detached, almost aristocratic disdain for political correctness and a keen awareness of the loopholes in existing regulations. He anticipates new legislation aimed at restricting weapons manufacturing. The scene should conclude with a tedious bureaucratic procedure handled by Ng, and a final attempt by Marteau to connect with Torin and Craig, hinting at future opportunities for collaboration despite their initial reservations. Use relatively short, punchy sentences and dialogue. Inject moments of dark humor.\n",
      "\u001b[0m\n",
      "\u001b[32m2025-04-20 16:51:34.661\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmodel.reasoning\u001b[0m:\u001b[36mlogger_reward\u001b[0m:\u001b[36m234\u001b[0m - \u001b[1mGeneration: --------------------\u001b[0m\n",
      "\u001b[32m2025-04-20 16:51:34.661\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmodel.reasoning\u001b[0m:\u001b[36mlogger_reward\u001b[0m:\u001b[36m235\u001b[0m - \u001b[1mAs the tense negotiations resumed, the air in the room thickened with anticipation. The senior officer, Torin, leaned forward, her eyes gleaming with intensity, as if probing for any hint of deception. She smiled to herself, a calculated smile, as she presented her compelling argument to the team.\n",
      "\n",
      "\"The cost-benefit analysis is crucial, but let's not forget the nature of the war, Karan... We can't achieve peace without the resources we need to maintain it.\"\n",
      "\n",
      "With a glint of purpose in her eyes, she began to murmur to herself, her voice barely audible over the din of the room. \"We'll do whatever it takes to keep the peace, no matter the cost. And if that means compromising our way of life, so be it.\"\n",
      "\n",
      "At that moment, the door creaked open, and a figure emerged from the shadows. The air was thick with tension, and the security team paused, waiting for their turn to intervene.\n",
      "\n",
      "Meanwhile, in the nearby reception area, the bureaucracy had been quietly negotiating with rogue systems. Rumors of advanced technology had started to trickle in, and some had even gone as far as to propose a new system that could potentially disrupt the peace.\n",
      "\n",
      "Eager for a solution, a young, capable arms manufacturer, René, stepped up to the podium. He presented a proposal, one that seemed almost audacious. He had stolen technology from a rival manufacturer and used it to fabricate and create entirely new forms of assault weapons. His argument was that this technology could potentially make a major dent in the war on terror.\n",
      "\n",
      "Eager to be at the forefront of the issue, Torin and Craig sat down across from René, the two men exchanging nervous glances. Together, they began to present their argument, one that had been simmering beneath the surface for months.\n",
      "\n",
      "\"And they're willing to do it without us,\" René said, his tone a little rough. \"The technology is already in place, and we can use it to create something we can't even imagine.\"\n",
      "\n",
      "Torin raised an eyebrow. \"What, you think it can't be a useful tool?\"\n",
      "\n",
      "René shrugged. \"Not really... It's still in the dark ages. Not yet, anyway.\"\n",
      "\n",
      "\"But what about it?\" René asked quietly.\n",
      "\n",
      "\"The implications of that technology are enormous,\" said Torin. \"From a military perspective, if it can\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mwrapper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/smolmodels/notebooks/../trl_wrapper/trainer_wrapper.py:649\u001b[0m, in \u001b[0;36mTrainerWrapper.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    647\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtrain\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    648\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting training.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 649\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/smolmodels/.venv/lib/python3.11/site-packages/transformers/trainer.py:2245\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2243\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2244\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2245\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2246\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2250\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/smolmodels/.venv/lib/python3.11/site-packages/transformers/trainer.py:2560\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2553\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2554\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[1;32m   2555\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2556\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m!=\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED\n\u001b[1;32m   2557\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[1;32m   2558\u001b[0m )\n\u001b[1;32m   2559\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[0;32m-> 2560\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2562\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2563\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2564\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2565\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2566\u001b[0m ):\n\u001b[1;32m   2567\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2568\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/Documents/GitHub/smolmodels/.venv/lib/python3.11/site-packages/transformers/trainer.py:3730\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   3727\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mtrain):\n\u001b[1;32m   3728\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m-> 3730\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3731\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_sagemaker_mp_enabled():\n\u001b[1;32m   3732\u001b[0m     loss_mb \u001b[38;5;241m=\u001b[39m smp_forward_backward(model, inputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps)\n",
      "File \u001b[0;32m~/Documents/GitHub/smolmodels/.venv/lib/python3.11/site-packages/trl/extras/profiling.py:87\u001b[0m, in \u001b[0;36mprofiling_decorator.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m profiling_context(\u001b[38;5;28mself\u001b[39m, func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m):\n\u001b[0;32m---> 87\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/smolmodels/.venv/lib/python3.11/site-packages/trl/trainer/grpo_trainer.py:647\u001b[0m, in \u001b[0;36mGRPOTrainer._prepare_inputs\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    645\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    646\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_iterations \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 647\u001b[0m         inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_and_score_completions\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    648\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffered_inputs[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_step \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps] \u001b[38;5;241m=\u001b[39m inputs\n\u001b[1;32m    649\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/GitHub/smolmodels/.venv/lib/python3.11/site-packages/trl/trainer/grpo_trainer.py:719\u001b[0m, in \u001b[0;36mGRPOTrainer._generate_and_score_completions\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    714\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    715\u001b[0m     \u001b[38;5;66;03m# Regular generation path\u001b[39;00m\n\u001b[1;32m    716\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m unwrap_model_for_generation(\n\u001b[1;32m    717\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_wrapped, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator, gather_deepspeed3_params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mds3_gather_for_generation\n\u001b[1;32m    718\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m unwrapped_model:\n\u001b[0;32m--> 719\u001b[0m         prompt_completion_ids \u001b[38;5;241m=\u001b[39m \u001b[43munwrapped_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprompt_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    723\u001b[0m     \u001b[38;5;66;03m# Compute prompt length and extract completion ids\u001b[39;00m\n\u001b[1;32m    724\u001b[0m     prompt_length \u001b[38;5;241m=\u001b[39m prompt_ids\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/GitHub/smolmodels/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/smolmodels/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:2465\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, **kwargs)\u001b[0m\n\u001b[1;32m   2457\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2458\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2459\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   2460\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2461\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2462\u001b[0m     )\n\u001b[1;32m   2464\u001b[0m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[0;32m-> 2465\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2466\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2467\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2468\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2469\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2470\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2471\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2472\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2473\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2475\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[1;32m   2476\u001b[0m     \u001b[38;5;66;03m# 11. interleave input_ids with `num_beams` additional sequences per batch\u001b[39;00m\n\u001b[1;32m   2477\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2478\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2479\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[1;32m   2480\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2481\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2482\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/GitHub/smolmodels/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:3434\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   3432\u001b[0m     is_prefill \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   3433\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3434\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   3436\u001b[0m \u001b[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[39;00m\n\u001b[1;32m   3437\u001b[0m model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_model_kwargs_for_generation(\n\u001b[1;32m   3438\u001b[0m     outputs,\n\u001b[1;32m   3439\u001b[0m     model_kwargs,\n\u001b[1;32m   3440\u001b[0m     is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   3441\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/GitHub/smolmodels/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/smolmodels/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/GitHub/smolmodels/.venv/lib/python3.11/site-packages/transformers/utils/generic.py:965\u001b[0m, in \u001b[0;36mcan_return_tuple.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    962\u001b[0m     set_attribute_for_modules(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_is_top_level_module\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    964\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 965\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    966\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_requested_to_return_tuple \u001b[38;5;129;01mor\u001b[39;00m (is_configured_to_return_tuple \u001b[38;5;129;01mand\u001b[39;00m is_top_level_module):\n\u001b[1;32m    967\u001b[0m         output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mto_tuple()\n",
      "File \u001b[0;32m~/Documents/GitHub/smolmodels/.venv/lib/python3.11/site-packages/transformers/utils/deprecation.py:172\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action\u001b[38;5;241m.\u001b[39mNOTIFY, Action\u001b[38;5;241m.\u001b[39mNOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[1;32m    170\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/smolmodels/.venv/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:821\u001b[0m, in \u001b[0;36mLlamaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, cache_position, logits_to_keep, **kwargs)\u001b[0m\n\u001b[1;32m    816\u001b[0m output_hidden_states \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    817\u001b[0m     output_hidden_states \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39moutput_hidden_states\n\u001b[1;32m    818\u001b[0m )\n\u001b[1;32m    820\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m--> 821\u001b[0m outputs: BaseModelOutputWithPast \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    822\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    823\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    824\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    828\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    829\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlast_hidden_state\n\u001b[1;32m    835\u001b[0m \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GitHub/smolmodels/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/smolmodels/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/GitHub/smolmodels/.venv/lib/python3.11/site-packages/transformers/utils/generic.py:965\u001b[0m, in \u001b[0;36mcan_return_tuple.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    962\u001b[0m     set_attribute_for_modules(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_is_top_level_module\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    964\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 965\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    966\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_requested_to_return_tuple \u001b[38;5;129;01mor\u001b[39;00m (is_configured_to_return_tuple \u001b[38;5;129;01mand\u001b[39;00m is_top_level_module):\n\u001b[1;32m    967\u001b[0m         output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mto_tuple()\n",
      "File \u001b[0;32m~/Documents/GitHub/smolmodels/.venv/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:559\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, cache_position, **flash_attn_kwargs)\u001b[0m\n\u001b[1;32m    556\u001b[0m     all_hidden_states \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (hidden_states,)\n\u001b[1;32m    558\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgradient_checkpointing \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:\n\u001b[0;32m--> 559\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gradient_checkpointing_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    560\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecoder_layer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mflash_attn_kwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    561\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    568\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    569\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    570\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    571\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m decoder_layer(\n\u001b[1;32m    572\u001b[0m         hidden_states,\n\u001b[1;32m    573\u001b[0m         attention_mask\u001b[38;5;241m=\u001b[39mcausal_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    580\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mflash_attn_kwargs,\n\u001b[1;32m    581\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/GitHub/smolmodels/.venv/lib/python3.11/site-packages/torch/_compile.py:32\u001b[0m, in \u001b[0;36m_disable_dynamo.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     29\u001b[0m     disable_fn \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mdisable(fn, recursive)\n\u001b[1;32m     30\u001b[0m     fn\u001b[38;5;241m.\u001b[39m__dynamo_disable \u001b[38;5;241m=\u001b[39m disable_fn\n\u001b[0;32m---> 32\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdisable_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/smolmodels/.venv/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:632\u001b[0m, in \u001b[0;36mDisableContext.__call__.<locals>._fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    630\u001b[0m prior \u001b[38;5;241m=\u001b[39m _maybe_set_eval_frame(callback)\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 632\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    634\u001b[0m     _maybe_set_eval_frame(prior)\n",
      "File \u001b[0;32m~/Documents/GitHub/smolmodels/.venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:489\u001b[0m, in \u001b[0;36mcheckpoint\u001b[0;34m(function, use_reentrant, context_fn, determinism_check, debug, *args, **kwargs)\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m context_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m noop_context_fn \u001b[38;5;129;01mor\u001b[39;00m debug \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m    485\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    486\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing `context_fn` or `debug` is only supported when \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    487\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_reentrant=False.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    488\u001b[0m         )\n\u001b[0;32m--> 489\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mCheckpointFunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreserve\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    491\u001b[0m     gen \u001b[38;5;241m=\u001b[39m _checkpoint_without_reentrant_generator(\n\u001b[1;32m    492\u001b[0m         function, preserve, context_fn, determinism_check, debug, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    493\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/GitHub/smolmodels/.venv/lib/python3.11/site-packages/torch/autograd/function.py:575\u001b[0m, in \u001b[0;36mFunction.apply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n\u001b[1;32m    573\u001b[0m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[1;32m    574\u001b[0m     args \u001b[38;5;241m=\u001b[39m _functorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[0;32m--> 575\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_setup_ctx_defined:\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    579\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    580\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    581\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstaticmethod. For more details, please see \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    582\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/main/notes/extending.func.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    583\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/GitHub/smolmodels/.venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:264\u001b[0m, in \u001b[0;36mCheckpointFunction.forward\u001b[0;34m(ctx, run_function, preserve_rng_state, *args)\u001b[0m\n\u001b[1;32m    261\u001b[0m ctx\u001b[38;5;241m.\u001b[39msave_for_backward(\u001b[38;5;241m*\u001b[39mtensor_inputs)\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 264\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mrun_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/Documents/GitHub/smolmodels/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/smolmodels/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/GitHub/smolmodels/.venv/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:333\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n\u001b[1;32m    332\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[0;32m--> 333\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost_attention_layernorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    334\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp(hidden_states)\n\u001b[1;32m    335\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n",
      "File \u001b[0;32m~/Documents/GitHub/smolmodels/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/smolmodels/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/GitHub/smolmodels/.venv/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:82\u001b[0m, in \u001b[0;36mLlamaRMSNorm.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m     80\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m hidden_states\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m     81\u001b[0m variance \u001b[38;5;241m=\u001b[39m hidden_states\u001b[38;5;241m.\u001b[39mpow(\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 82\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m hidden_states \u001b[38;5;241m*\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrsqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvariance\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvariance_epsilon\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m*\u001b[39m hidden_states\u001b[38;5;241m.\u001b[39mto(input_dtype)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "wrapper.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataset_pd = pd.read_parquet(\n",
    "    \"../dataset_files/gutenberg_backtranslate_from_txt.parquet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'instruction' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(wrapper\u001b[38;5;241m.\u001b[39mdata_module\u001b[38;5;241m.\u001b[39mbench\u001b[38;5;241m.\u001b[39mformat_prompt(\u001b[43minstruction\u001b[49m, completion))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'instruction' is not defined"
     ]
    }
   ],
   "source": [
    "print(wrapper.data_module.bench.format_prompt(instruction, completion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-15 20:44:05.754\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthetic_data.tasks.writing\u001b[0m:\u001b[36mscore_writing\u001b[0m:\u001b[36m412\u001b[0m - \u001b[1mJudging 1 completions with gpt-4.1-nano\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.14]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion, instruction = dataset_pd.loc[500]['text'], dataset_pd.loc[500]['instruction']\n",
    "wrapper.data_module.reward_functions()[0]([instruction], [completion])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

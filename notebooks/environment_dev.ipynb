{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brianfitzgerald/Documents/GitHub/smolmodels/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/brianfitzgerald/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /Users/brianfitzgerald/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "from gyms.twenty_questions.env import TwentyQuestionsPolicyEnvironment\n",
    "from synthetic_data.generation import get_generation_wrapper\n",
    "\n",
    "\n",
    "generation_wrapper = get_generation_wrapper(\"gpt-4o-mini\")\n",
    "env = TwentyQuestionsPolicyEnvironment(generation_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-03-01 21:01:37.918\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthetic_data.generation\u001b[0m:\u001b[36mgenerate\u001b[0m:\u001b[36m177\u001b[0m - \u001b[1mGenerating 1 requests with gpt-4o-mini, max RPS: 83.33333333333333\u001b[0m\n",
      "\u001b[32m2025-03-01 21:01:39.311\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgyms.twenty_questions.env\u001b[0m:\u001b[36mstep\u001b[0m:\u001b[36m166\u001b[0m - \u001b[1mResponse: <thought>\n",
      "To effectively narrow down the possibilities, I need to focus on the characteristics of the secret object, person, or concept. I should determine whether it belongs to a specific category, such as whether it is a living thing, an inanimate object, or an abstract concept. This will help me refine my search significantly. Since I have no prior context about the secret, I will start by asking a broad question that can help me identify the general category it falls into.\n",
      "</thought>\n",
      "\n",
      "<output>\n",
      "Question: Is it a living organism?\n",
      "</output>\u001b[0m\n",
      "\u001b[32m2025-03-01 21:01:39.312\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgyms.twenty_questions.env\u001b[0m:\u001b[36mstep\u001b[0m:\u001b[36m179\u001b[0m - \u001b[1mOutput: Guesser: Is it a living organism?\u001b[0m\n",
      "\u001b[32m2025-03-01 21:01:39.313\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthetic_data.generation\u001b[0m:\u001b[36mgenerate\u001b[0m:\u001b[36m177\u001b[0m - \u001b[1mGenerating 1 requests with gpt-4o-mini, max RPS: 83.33333333333333\u001b[0m\n",
      "\u001b[32m2025-03-01 21:01:39.612\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgyms.twenty_questions.env\u001b[0m:\u001b[36mstep\u001b[0m:\u001b[36m166\u001b[0m - \u001b[1mResponse: <response>No</response>\u001b[0m\n",
      "\u001b[32m2025-03-01 21:01:39.613\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgyms.twenty_questions.env\u001b[0m:\u001b[36mstep\u001b[0m:\u001b[36m179\u001b[0m - \u001b[1mOutput: Oracle: No\u001b[0m\n",
      "\u001b[32m2025-03-01 21:01:39.614\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthetic_data.generation\u001b[0m:\u001b[36mgenerate\u001b[0m:\u001b[36m177\u001b[0m - \u001b[1mGenerating 1 requests with gpt-4o-mini, max RPS: 83.33333333333333\u001b[0m\n",
      "\u001b[32m2025-03-01 21:01:40.646\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgyms.twenty_questions.env\u001b[0m:\u001b[36mstep\u001b[0m:\u001b[36m166\u001b[0m - \u001b[1mResponse: <thought>\n",
      "Since the answer is not a living organism, I can narrow down the possibilities to inanimate objects, concepts, or phenomena. To further refine my guesses, I should determine if it is something commonly found in everyday life or if it belongs to a more specialized category. Asking whether it is a man-made object will help clarify this distinction.\n",
      "</thought>\n",
      "\n",
      "<output>\n",
      "Question: Is it a man-made object? \n",
      "</output>\u001b[0m\n",
      "\u001b[32m2025-03-01 21:01:40.648\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgyms.twenty_questions.env\u001b[0m:\u001b[36mstep\u001b[0m:\u001b[36m179\u001b[0m - \u001b[1mOutput: Guesser: Is it a man-made object?\u001b[0m\n",
      "\u001b[32m2025-03-01 21:01:40.649\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthetic_data.generation\u001b[0m:\u001b[36mgenerate\u001b[0m:\u001b[36m177\u001b[0m - \u001b[1mGenerating 1 requests with gpt-4o-mini, max RPS: 83.33333333333333\u001b[0m\n",
      "\u001b[32m2025-03-01 21:01:41.568\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgyms.twenty_questions.env\u001b[0m:\u001b[36mstep\u001b[0m:\u001b[36m166\u001b[0m - \u001b[1mResponse: <response>Yes</response>\u001b[0m\n",
      "\u001b[32m2025-03-01 21:01:41.570\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgyms.twenty_questions.env\u001b[0m:\u001b[36mstep\u001b[0m:\u001b[36m179\u001b[0m - \u001b[1mOutput: Oracle: Yes\u001b[0m\n",
      "\u001b[32m2025-03-01 21:01:41.571\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthetic_data.generation\u001b[0m:\u001b[36mgenerate\u001b[0m:\u001b[36m177\u001b[0m - \u001b[1mGenerating 1 requests with gpt-4o-mini, max RPS: 83.33333333333333\u001b[0m\n",
      "\u001b[32m2025-03-01 21:01:42.667\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgyms.twenty_questions.env\u001b[0m:\u001b[36mstep\u001b[0m:\u001b[36m166\u001b[0m - \u001b[1mResponse: <thought>\n",
      "Since the secret object is a man-made item, I want to narrow down the category it belongs to. Man-made objects can range from tools and appliances to vehicles and technology. Asking if it is commonly used in households will help me determine if it is something familiar and widely utilized or something more specialized.\n",
      "</thought>\n",
      "\n",
      "<output>\n",
      "Question: Is it commonly found in households? \n",
      "</output>\u001b[0m\n",
      "\u001b[32m2025-03-01 21:01:42.668\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgyms.twenty_questions.env\u001b[0m:\u001b[36mstep\u001b[0m:\u001b[36m179\u001b[0m - \u001b[1mOutput: Guesser: Is it commonly found in households?\u001b[0m\n",
      "\u001b[32m2025-03-01 21:01:42.669\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthetic_data.generation\u001b[0m:\u001b[36mgenerate\u001b[0m:\u001b[36m177\u001b[0m - \u001b[1mGenerating 1 requests with gpt-4o-mini, max RPS: 83.33333333333333\u001b[0m\n",
      "\u001b[32m2025-03-01 21:01:42.993\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgyms.twenty_questions.env\u001b[0m:\u001b[36mstep\u001b[0m:\u001b[36m166\u001b[0m - \u001b[1mResponse: Oracle: Yes\u001b[0m\n",
      "\u001b[32m2025-03-01 21:01:42.994\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgyms.twenty_questions.env\u001b[0m:\u001b[36mstep\u001b[0m:\u001b[36m179\u001b[0m - \u001b[1mOutput: Oracle: \u001b[0m\n",
      "\u001b[32m2025-03-01 21:01:42.995\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthetic_data.generation\u001b[0m:\u001b[36mgenerate\u001b[0m:\u001b[36m177\u001b[0m - \u001b[1mGenerating 1 requests with gpt-4o-mini, max RPS: 83.33333333333333\u001b[0m\n",
      "\u001b[32m2025-03-01 21:01:44.010\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgyms.twenty_questions.env\u001b[0m:\u001b[36mstep\u001b[0m:\u001b[36m166\u001b[0m - \u001b[1mResponse: <thought>\n",
      "Since the object is man-made and I need to determine its commonality in households, asking whether it is commonly found in households will help narrow down the possibilities significantly. If it is found in households, I can then explore its specific type or function. If not, I can consider other environments where it might be found, such as workplaces or outdoors.\n",
      "</thought>\n",
      "\n",
      "<output>\n",
      "Question: Is it commonly found in households?\n",
      "</output>\u001b[0m\n",
      "\u001b[32m2025-03-01 21:01:44.011\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgyms.twenty_questions.env\u001b[0m:\u001b[36mstep\u001b[0m:\u001b[36m179\u001b[0m - \u001b[1mOutput: Guesser: Is it commonly found in households?\u001b[0m\n",
      "\u001b[32m2025-03-01 21:01:44.012\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthetic_data.generation\u001b[0m:\u001b[36mgenerate\u001b[0m:\u001b[36m177\u001b[0m - \u001b[1mGenerating 1 requests with gpt-4o-mini, max RPS: 83.33333333333333\u001b[0m\n",
      "\u001b[32m2025-03-01 21:01:44.261\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgyms.twenty_questions.env\u001b[0m:\u001b[36mstep\u001b[0m:\u001b[36m166\u001b[0m - \u001b[1mResponse: Oracle: Yes\u001b[0m\n",
      "\u001b[32m2025-03-01 21:01:44.262\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgyms.twenty_questions.env\u001b[0m:\u001b[36mstep\u001b[0m:\u001b[36m179\u001b[0m - \u001b[1mOutput: Oracle: \u001b[0m\n",
      "\u001b[32m2025-03-01 21:01:44.263\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthetic_data.generation\u001b[0m:\u001b[36mgenerate\u001b[0m:\u001b[36m177\u001b[0m - \u001b[1mGenerating 1 requests with gpt-4o-mini, max RPS: 83.33333333333333\u001b[0m\n",
      "\u001b[32m2025-03-01 21:01:48.625\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgyms.twenty_questions.env\u001b[0m:\u001b[36mstep\u001b[0m:\u001b[36m166\u001b[0m - \u001b[1mResponse: <thought>\n",
      "Since the previous question about whether the object is commonly found in households was not answered, I will ask a different question that can help narrow down the category of the man-made object. I need to determine if it is something that is primarily used for a specific function or purpose. This will help to eliminate a broad range of possibilities.\n",
      "</thought>\n",
      "\n",
      "<output>\n",
      "Question: Is it primarily used for entertainment? \n",
      "</output>\u001b[0m\n",
      "\u001b[32m2025-03-01 21:01:48.627\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgyms.twenty_questions.env\u001b[0m:\u001b[36mstep\u001b[0m:\u001b[36m179\u001b[0m - \u001b[1mOutput: Guesser: Is it primarily used for entertainment?\u001b[0m\n",
      "\u001b[32m2025-03-01 21:01:48.627\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthetic_data.generation\u001b[0m:\u001b[36mgenerate\u001b[0m:\u001b[36m177\u001b[0m - \u001b[1mGenerating 1 requests with gpt-4o-mini, max RPS: 83.33333333333333\u001b[0m\n",
      "\u001b[32m2025-03-01 21:01:48.928\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgyms.twenty_questions.env\u001b[0m:\u001b[36mstep\u001b[0m:\u001b[36m166\u001b[0m - \u001b[1mResponse: Oracle: No\u001b[0m\n",
      "\u001b[32m2025-03-01 21:01:48.928\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgyms.twenty_questions.env\u001b[0m:\u001b[36mstep\u001b[0m:\u001b[36m179\u001b[0m - \u001b[1mOutput: Oracle: \u001b[0m\n",
      "\u001b[32m2025-03-01 21:01:48.928\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthetic_data.generation\u001b[0m:\u001b[36mgenerate\u001b[0m:\u001b[36m177\u001b[0m - \u001b[1mGenerating 1 requests with gpt-4o-mini, max RPS: 83.33333333333333\u001b[0m\n",
      "\u001b[32m2025-03-01 21:01:50.469\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgyms.twenty_questions.env\u001b[0m:\u001b[36mstep\u001b[0m:\u001b[36m166\u001b[0m - \u001b[1mResponse: Guesser: Is it primarily used for entertainment?\u001b[0m\n",
      "\u001b[32m2025-03-01 21:01:50.470\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgyms.twenty_questions.env\u001b[0m:\u001b[36mstep\u001b[0m:\u001b[36m179\u001b[0m - \u001b[1mOutput: Guesser: \u001b[0m\n",
      "\u001b[32m2025-03-01 21:01:50.471\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthetic_data.generation\u001b[0m:\u001b[36mgenerate\u001b[0m:\u001b[36m177\u001b[0m - \u001b[1mGenerating 1 requests with gpt-4o-mini, max RPS: 83.33333333333333\u001b[0m\n",
      "\u001b[32m2025-03-01 21:01:50.877\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgyms.twenty_questions.env\u001b[0m:\u001b[36mstep\u001b[0m:\u001b[36m166\u001b[0m - \u001b[1mResponse: Guesser: Is it primarily used for entertainment?\u001b[0m\n",
      "\u001b[32m2025-03-01 21:01:50.878\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgyms.twenty_questions.env\u001b[0m:\u001b[36mstep\u001b[0m:\u001b[36m179\u001b[0m - \u001b[1mOutput: Oracle: \u001b[0m\n",
      "\u001b[32m2025-03-01 21:01:50.880\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthetic_data.generation\u001b[0m:\u001b[36mgenerate\u001b[0m:\u001b[36m177\u001b[0m - \u001b[1mGenerating 1 requests with gpt-4o-mini, max RPS: 83.33333333333333\u001b[0m\n",
      "\u001b[32m2025-03-01 21:01:51.193\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgyms.twenty_questions.env\u001b[0m:\u001b[36mstep\u001b[0m:\u001b[36m166\u001b[0m - \u001b[1mResponse: Guesser: Is it primarily used for entertainment?\u001b[0m\n",
      "\u001b[32m2025-03-01 21:01:51.195\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgyms.twenty_questions.env\u001b[0m:\u001b[36mstep\u001b[0m:\u001b[36m179\u001b[0m - \u001b[1mOutput: Guesser: \u001b[0m\n",
      "\u001b[32m2025-03-01 21:01:51.196\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthetic_data.generation\u001b[0m:\u001b[36mgenerate\u001b[0m:\u001b[36m177\u001b[0m - \u001b[1mGenerating 1 requests with gpt-4o-mini, max RPS: 83.33333333333333\u001b[0m\n",
      "\u001b[32m2025-03-01 21:01:51.480\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgyms.twenty_questions.env\u001b[0m:\u001b[36mstep\u001b[0m:\u001b[36m166\u001b[0m - \u001b[1mResponse: Oracle: \u001b[0m\n",
      "\u001b[32m2025-03-01 21:01:51.481\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgyms.twenty_questions.env\u001b[0m:\u001b[36mstep\u001b[0m:\u001b[36m179\u001b[0m - \u001b[1mOutput: Oracle: \u001b[0m\n",
      "\u001b[32m2025-03-01 21:01:51.482\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthetic_data.generation\u001b[0m:\u001b[36mgenerate\u001b[0m:\u001b[36m177\u001b[0m - \u001b[1mGenerating 1 requests with gpt-4o-mini, max RPS: 83.33333333333333\u001b[0m\n",
      "\u001b[32m2025-03-01 21:01:52.617\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgyms.twenty_questions.env\u001b[0m:\u001b[36mstep\u001b[0m:\u001b[36m166\u001b[0m - \u001b[1mResponse: <thought>\n",
      "I have gathered that the secret object is a man-made item, but I still do not know if it is commonly found in households or if it is used for entertainment. Since I have already asked about its presence in households and its use for entertainment, I will focus on whether it is electronic, as that can help narrow down the possibilities significantly.\n",
      "</thought>\n",
      "\n",
      "<output>\n",
      "Question: Is it an electronic device? \n",
      "</output>\u001b[0m\n",
      "\u001b[32m2025-03-01 21:01:52.618\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgyms.twenty_questions.env\u001b[0m:\u001b[36mstep\u001b[0m:\u001b[36m179\u001b[0m - \u001b[1mOutput: Guesser: Is it an electronic device?\u001b[0m\n",
      "\u001b[32m2025-03-01 21:01:52.620\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthetic_data.generation\u001b[0m:\u001b[36mgenerate\u001b[0m:\u001b[36m177\u001b[0m - \u001b[1mGenerating 1 requests with gpt-4o-mini, max RPS: 83.33333333333333\u001b[0m\n",
      "\u001b[32m2025-03-01 21:01:53.237\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgyms.twenty_questions.env\u001b[0m:\u001b[36mstep\u001b[0m:\u001b[36m166\u001b[0m - \u001b[1mResponse: <response>No</response>\u001b[0m\n",
      "\u001b[32m2025-03-01 21:01:53.238\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgyms.twenty_questions.env\u001b[0m:\u001b[36mstep\u001b[0m:\u001b[36m179\u001b[0m - \u001b[1mOutput: Oracle: No\u001b[0m\n",
      "\u001b[32m2025-03-01 21:01:53.241\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthetic_data.generation\u001b[0m:\u001b[36mgenerate\u001b[0m:\u001b[36m177\u001b[0m - \u001b[1mGenerating 1 requests with gpt-4o-mini, max RPS: 83.33333333333333\u001b[0m\n",
      "\u001b[32m2025-03-01 21:01:53.845\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgyms.twenty_questions.env\u001b[0m:\u001b[36mstep\u001b[0m:\u001b[36m166\u001b[0m - \u001b[1mResponse: Guesser: Is it a tool used for practical purposes?\u001b[0m\n",
      "\u001b[32m2025-03-01 21:01:53.847\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgyms.twenty_questions.env\u001b[0m:\u001b[36mstep\u001b[0m:\u001b[36m179\u001b[0m - \u001b[1mOutput: Guesser: \u001b[0m\n",
      "\u001b[32m2025-03-01 21:01:53.848\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthetic_data.generation\u001b[0m:\u001b[36mgenerate\u001b[0m:\u001b[36m177\u001b[0m - \u001b[1mGenerating 1 requests with gpt-4o-mini, max RPS: 83.33333333333333\u001b[0m\n",
      "\u001b[32m2025-03-01 21:01:54.138\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgyms.twenty_questions.env\u001b[0m:\u001b[36mstep\u001b[0m:\u001b[36m166\u001b[0m - \u001b[1mResponse: Oracle: \u001b[0m\n",
      "\u001b[32m2025-03-01 21:01:54.139\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgyms.twenty_questions.env\u001b[0m:\u001b[36mstep\u001b[0m:\u001b[36m179\u001b[0m - \u001b[1mOutput: Oracle: \u001b[0m\n",
      "\u001b[32m2025-03-01 21:01:54.140\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthetic_data.generation\u001b[0m:\u001b[36mgenerate\u001b[0m:\u001b[36m177\u001b[0m - \u001b[1mGenerating 1 requests with gpt-4o-mini, max RPS: 83.33333333333333\u001b[0m\n",
      "\u001b[32m2025-03-01 21:01:54.770\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgyms.twenty_questions.env\u001b[0m:\u001b[36mstep\u001b[0m:\u001b[36m166\u001b[0m - \u001b[1mResponse: Guesser: Is it a tool used for a specific task?\u001b[0m\n",
      "\u001b[32m2025-03-01 21:01:54.771\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgyms.twenty_questions.env\u001b[0m:\u001b[36mstep\u001b[0m:\u001b[36m179\u001b[0m - \u001b[1mOutput: Guesser: \u001b[0m\n",
      "\u001b[32m2025-03-01 21:01:54.772\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthetic_data.generation\u001b[0m:\u001b[36mgenerate\u001b[0m:\u001b[36m177\u001b[0m - \u001b[1mGenerating 1 requests with gpt-4o-mini, max RPS: 83.33333333333333\u001b[0m\n",
      "\u001b[32m2025-03-01 21:01:55.078\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgyms.twenty_questions.env\u001b[0m:\u001b[36mstep\u001b[0m:\u001b[36m166\u001b[0m - \u001b[1mResponse: Oracle: \u001b[0m\n",
      "\u001b[32m2025-03-01 21:01:55.080\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgyms.twenty_questions.env\u001b[0m:\u001b[36mstep\u001b[0m:\u001b[36m179\u001b[0m - \u001b[1mOutput: Oracle: \u001b[0m\n",
      "\u001b[32m2025-03-01 21:01:55.081\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgyms.twenty_questions.env\u001b[0m:\u001b[36mstep\u001b[0m:\u001b[36m185\u001b[0m - \u001b[1mThe word was Hammer\u001b[0m\n",
      "\u001b[32m2025-03-01 21:01:55.083\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthetic_data.generation\u001b[0m:\u001b[36mgenerate\u001b[0m:\u001b[36m177\u001b[0m - \u001b[1mGenerating 1 requests with gpt-4o-mini, max RPS: 83.33333333333333\u001b[0m\n",
      "\u001b[32m2025-03-01 21:01:55.563\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgyms.twenty_questions.env\u001b[0m:\u001b[36mstep\u001b[0m:\u001b[36m166\u001b[0m - \u001b[1mResponse: Guesser: Is it made of paper?\u001b[0m\n",
      "\u001b[32m2025-03-01 21:01:55.564\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgyms.twenty_questions.env\u001b[0m:\u001b[36mstep\u001b[0m:\u001b[36m179\u001b[0m - \u001b[1mOutput: Guesser: \u001b[0m\n",
      "\u001b[32m2025-03-01 21:01:55.566\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthetic_data.generation\u001b[0m:\u001b[36mgenerate\u001b[0m:\u001b[36m177\u001b[0m - \u001b[1mGenerating 1 requests with gpt-4o-mini, max RPS: 83.33333333333333\u001b[0m\n",
      "\u001b[32m2025-03-01 21:01:55.997\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgyms.twenty_questions.env\u001b[0m:\u001b[36mstep\u001b[0m:\u001b[36m166\u001b[0m - \u001b[1mResponse: Oracle: \u001b[0m\n",
      "\u001b[32m2025-03-01 21:01:55.999\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgyms.twenty_questions.env\u001b[0m:\u001b[36mstep\u001b[0m:\u001b[36m179\u001b[0m - \u001b[1mOutput: Oracle: \u001b[0m\n",
      "\u001b[32m2025-03-01 21:01:56.000\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthetic_data.generation\u001b[0m:\u001b[36mgenerate\u001b[0m:\u001b[36m177\u001b[0m - \u001b[1mGenerating 1 requests with gpt-4o-mini, max RPS: 83.33333333333333\u001b[0m\n",
      "\u001b[32m2025-03-01 21:01:56.303\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgyms.twenty_questions.env\u001b[0m:\u001b[36mstep\u001b[0m:\u001b[36m166\u001b[0m - \u001b[1mResponse: Guesser: Is it a tool?\u001b[0m\n",
      "\u001b[32m2025-03-01 21:01:56.305\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgyms.twenty_questions.env\u001b[0m:\u001b[36mstep\u001b[0m:\u001b[36m179\u001b[0m - \u001b[1mOutput: Guesser: \u001b[0m\n",
      "\u001b[32m2025-03-01 21:01:56.306\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthetic_data.generation\u001b[0m:\u001b[36mgenerate\u001b[0m:\u001b[36m177\u001b[0m - \u001b[1mGenerating 1 requests with gpt-4o-mini, max RPS: 83.33333333333333\u001b[0m\n",
      "\u001b[32m2025-03-01 21:01:56.589\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgyms.twenty_questions.env\u001b[0m:\u001b[36mstep\u001b[0m:\u001b[36m166\u001b[0m - \u001b[1mResponse: Oracle: \u001b[0m\n",
      "\u001b[32m2025-03-01 21:01:56.590\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgyms.twenty_questions.env\u001b[0m:\u001b[36mstep\u001b[0m:\u001b[36m179\u001b[0m - \u001b[1mOutput: Oracle: \u001b[0m\n",
      "\u001b[32m2025-03-01 21:01:56.590\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthetic_data.generation\u001b[0m:\u001b[36mgenerate\u001b[0m:\u001b[36m177\u001b[0m - \u001b[1mGenerating 1 requests with gpt-4o-mini, max RPS: 83.33333333333333\u001b[0m\n",
      "\u001b[32m2025-03-01 21:01:57.413\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgyms.twenty_questions.env\u001b[0m:\u001b[36mstep\u001b[0m:\u001b[36m166\u001b[0m - \u001b[1mResponse: Guesser: Is it a tool used for a specific purpose?\u001b[0m\n",
      "\u001b[32m2025-03-01 21:01:57.414\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgyms.twenty_questions.env\u001b[0m:\u001b[36mstep\u001b[0m:\u001b[36m179\u001b[0m - \u001b[1mOutput: Guesser: \u001b[0m\n",
      "\u001b[32m2025-03-01 21:01:57.415\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthetic_data.generation\u001b[0m:\u001b[36mgenerate\u001b[0m:\u001b[36m177\u001b[0m - \u001b[1mGenerating 1 requests with gpt-4o-mini, max RPS: 83.33333333333333\u001b[0m\n",
      "\u001b[32m2025-03-01 21:01:57.870\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgyms.twenty_questions.env\u001b[0m:\u001b[36mstep\u001b[0m:\u001b[36m166\u001b[0m - \u001b[1mResponse: Oracle: \u001b[0m\n",
      "\u001b[32m2025-03-01 21:01:57.870\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgyms.twenty_questions.env\u001b[0m:\u001b[36mstep\u001b[0m:\u001b[36m179\u001b[0m - \u001b[1mOutput: Oracle: \u001b[0m\n",
      "\u001b[32m2025-03-01 21:01:57.871\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthetic_data.generation\u001b[0m:\u001b[36mgenerate\u001b[0m:\u001b[36m177\u001b[0m - \u001b[1mGenerating 1 requests with gpt-4o-mini, max RPS: 83.33333333333333\u001b[0m\n",
      "\u001b[32m2025-03-01 21:01:58.350\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgyms.twenty_questions.env\u001b[0m:\u001b[36mstep\u001b[0m:\u001b[36m166\u001b[0m - \u001b[1mResponse: Guesser: Is it a tool used for a specific task?\u001b[0m\n",
      "\u001b[32m2025-03-01 21:01:58.350\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgyms.twenty_questions.env\u001b[0m:\u001b[36mstep\u001b[0m:\u001b[36m179\u001b[0m - \u001b[1mOutput: Guesser: \u001b[0m\n",
      "\u001b[32m2025-03-01 21:01:58.351\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthetic_data.generation\u001b[0m:\u001b[36mgenerate\u001b[0m:\u001b[36m177\u001b[0m - \u001b[1mGenerating 1 requests with gpt-4o-mini, max RPS: 83.33333333333333\u001b[0m\n",
      "\u001b[32m2025-03-01 21:01:58.662\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgyms.twenty_questions.env\u001b[0m:\u001b[36mstep\u001b[0m:\u001b[36m166\u001b[0m - \u001b[1mResponse: Oracle: \u001b[0m\n",
      "\u001b[32m2025-03-01 21:01:58.662\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgyms.twenty_questions.env\u001b[0m:\u001b[36mstep\u001b[0m:\u001b[36m179\u001b[0m - \u001b[1mOutput: Oracle: \u001b[0m\n",
      "\u001b[32m2025-03-01 21:01:58.662\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthetic_data.generation\u001b[0m:\u001b[36mgenerate\u001b[0m:\u001b[36m177\u001b[0m - \u001b[1mGenerating 1 requests with gpt-4o-mini, max RPS: 83.33333333333333\u001b[0m\n",
      "\u001b[32m2025-03-01 21:01:59.682\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgyms.twenty_questions.env\u001b[0m:\u001b[36mstep\u001b[0m:\u001b[36m166\u001b[0m - \u001b[1mResponse: Guesser: \u001b[0m\n",
      "\u001b[32m2025-03-01 21:01:59.684\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgyms.twenty_questions.env\u001b[0m:\u001b[36mstep\u001b[0m:\u001b[36m179\u001b[0m - \u001b[1mOutput: Guesser: \u001b[0m\n",
      "\u001b[32m2025-03-01 21:01:59.685\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthetic_data.generation\u001b[0m:\u001b[36mgenerate\u001b[0m:\u001b[36m177\u001b[0m - \u001b[1mGenerating 1 requests with gpt-4o-mini, max RPS: 83.33333333333333\u001b[0m\n",
      "\u001b[32m2025-03-01 21:01:59.982\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgyms.twenty_questions.env\u001b[0m:\u001b[36mstep\u001b[0m:\u001b[36m166\u001b[0m - \u001b[1mResponse: Oracle: \u001b[0m\n",
      "\u001b[32m2025-03-01 21:01:59.983\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgyms.twenty_questions.env\u001b[0m:\u001b[36mstep\u001b[0m:\u001b[36m179\u001b[0m - \u001b[1mOutput: Oracle: \u001b[0m\n",
      "\u001b[32m2025-03-01 21:01:59.984\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthetic_data.generation\u001b[0m:\u001b[36mgenerate\u001b[0m:\u001b[36m177\u001b[0m - \u001b[1mGenerating 1 requests with gpt-4o-mini, max RPS: 83.33333333333333\u001b[0m\n",
      "\u001b[32m2025-03-01 21:02:00.390\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgyms.twenty_questions.env\u001b[0m:\u001b[36mstep\u001b[0m:\u001b[36m166\u001b[0m - \u001b[1mResponse: Guesser: \u001b[0m\n",
      "\u001b[32m2025-03-01 21:02:00.392\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgyms.twenty_questions.env\u001b[0m:\u001b[36mstep\u001b[0m:\u001b[36m179\u001b[0m - \u001b[1mOutput: Guesser: \u001b[0m\n",
      "\u001b[32m2025-03-01 21:02:00.393\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthetic_data.generation\u001b[0m:\u001b[36mgenerate\u001b[0m:\u001b[36m177\u001b[0m - \u001b[1mGenerating 1 requests with gpt-4o-mini, max RPS: 83.33333333333333\u001b[0m\n",
      "\u001b[32m2025-03-01 21:02:00.707\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgyms.twenty_questions.env\u001b[0m:\u001b[36mstep\u001b[0m:\u001b[36m166\u001b[0m - \u001b[1mResponse: Oracle: \u001b[0m\n",
      "\u001b[32m2025-03-01 21:02:00.708\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgyms.twenty_questions.env\u001b[0m:\u001b[36mstep\u001b[0m:\u001b[36m179\u001b[0m - \u001b[1mOutput: Oracle: \u001b[0m\n",
      "\u001b[32m2025-03-01 21:02:00.709\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthetic_data.generation\u001b[0m:\u001b[36mgenerate\u001b[0m:\u001b[36m177\u001b[0m - \u001b[1mGenerating 1 requests with gpt-4o-mini, max RPS: 83.33333333333333\u001b[0m\n",
      "\u001b[32m2025-03-01 21:02:00.967\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgyms.twenty_questions.env\u001b[0m:\u001b[36mstep\u001b[0m:\u001b[36m166\u001b[0m - \u001b[1mResponse: Guesser: \u001b[0m\n",
      "\u001b[32m2025-03-01 21:02:00.968\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgyms.twenty_questions.env\u001b[0m:\u001b[36mstep\u001b[0m:\u001b[36m179\u001b[0m - \u001b[1mOutput: Guesser: \u001b[0m\n",
      "\u001b[32m2025-03-01 21:02:00.969\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthetic_data.generation\u001b[0m:\u001b[36mgenerate\u001b[0m:\u001b[36m177\u001b[0m - \u001b[1mGenerating 1 requests with gpt-4o-mini, max RPS: 83.33333333333333\u001b[0m\n",
      "\u001b[32m2025-03-01 21:02:01.290\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgyms.twenty_questions.env\u001b[0m:\u001b[36mstep\u001b[0m:\u001b[36m166\u001b[0m - \u001b[1mResponse: Oracle: \u001b[0m\n",
      "\u001b[32m2025-03-01 21:02:01.291\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgyms.twenty_questions.env\u001b[0m:\u001b[36mstep\u001b[0m:\u001b[36m179\u001b[0m - \u001b[1mOutput: Oracle: \u001b[0m\n",
      "\u001b[32m2025-03-01 21:02:01.291\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthetic_data.generation\u001b[0m:\u001b[36mgenerate\u001b[0m:\u001b[36m177\u001b[0m - \u001b[1mGenerating 1 requests with gpt-4o-mini, max RPS: 83.33333333333333\u001b[0m\n",
      "\u001b[32m2025-03-01 21:02:01.626\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgyms.twenty_questions.env\u001b[0m:\u001b[36mstep\u001b[0m:\u001b[36m166\u001b[0m - \u001b[1mResponse: Guesser: \u001b[0m\n",
      "\u001b[32m2025-03-01 21:02:01.627\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgyms.twenty_questions.env\u001b[0m:\u001b[36mstep\u001b[0m:\u001b[36m179\u001b[0m - \u001b[1mOutput: Guesser: \u001b[0m\n",
      "\u001b[32m2025-03-01 21:02:01.627\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthetic_data.generation\u001b[0m:\u001b[36mgenerate\u001b[0m:\u001b[36m177\u001b[0m - \u001b[1mGenerating 1 requests with gpt-4o-mini, max RPS: 83.33333333333333\u001b[0m\n",
      "\u001b[32m2025-03-01 21:02:02.038\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgyms.twenty_questions.env\u001b[0m:\u001b[36mstep\u001b[0m:\u001b[36m166\u001b[0m - \u001b[1mResponse: Oracle: \u001b[0m\n",
      "\u001b[32m2025-03-01 21:02:02.039\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgyms.twenty_questions.env\u001b[0m:\u001b[36mstep\u001b[0m:\u001b[36m179\u001b[0m - \u001b[1mOutput: Oracle: \u001b[0m\n",
      "\u001b[32m2025-03-01 21:02:02.041\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthetic_data.generation\u001b[0m:\u001b[36mgenerate\u001b[0m:\u001b[36m177\u001b[0m - \u001b[1mGenerating 1 requests with gpt-4o-mini, max RPS: 83.33333333333333\u001b[0m\n",
      "\u001b[32m2025-03-01 21:02:02.445\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgyms.twenty_questions.env\u001b[0m:\u001b[36mstep\u001b[0m:\u001b[36m166\u001b[0m - \u001b[1mResponse: Guesser: \u001b[0m\n",
      "\u001b[32m2025-03-01 21:02:02.446\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgyms.twenty_questions.env\u001b[0m:\u001b[36mstep\u001b[0m:\u001b[36m179\u001b[0m - \u001b[1mOutput: Guesser: \u001b[0m\n",
      "\u001b[32m2025-03-01 21:02:02.446\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthetic_data.generation\u001b[0m:\u001b[36mgenerate\u001b[0m:\u001b[36m177\u001b[0m - \u001b[1mGenerating 1 requests with gpt-4o-mini, max RPS: 83.33333333333333\u001b[0m\n",
      "\u001b[32m2025-03-01 21:02:02.908\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgyms.twenty_questions.env\u001b[0m:\u001b[36mstep\u001b[0m:\u001b[36m166\u001b[0m - \u001b[1mResponse: Oracle: \u001b[0m\n",
      "\u001b[32m2025-03-01 21:02:02.908\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgyms.twenty_questions.env\u001b[0m:\u001b[36mstep\u001b[0m:\u001b[36m179\u001b[0m - \u001b[1mOutput: Oracle: \u001b[0m\n",
      "\u001b[32m2025-03-01 21:02:02.909\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthetic_data.generation\u001b[0m:\u001b[36mgenerate\u001b[0m:\u001b[36m177\u001b[0m - \u001b[1mGenerating 1 requests with gpt-4o-mini, max RPS: 83.33333333333333\u001b[0m\n",
      "\u001b[32m2025-03-01 21:02:03.409\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgyms.twenty_questions.env\u001b[0m:\u001b[36mstep\u001b[0m:\u001b[36m166\u001b[0m - \u001b[1mResponse: Guesser: \u001b[0m\n",
      "\u001b[32m2025-03-01 21:02:03.409\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgyms.twenty_questions.env\u001b[0m:\u001b[36mstep\u001b[0m:\u001b[36m179\u001b[0m - \u001b[1mOutput: Guesser: \u001b[0m\n",
      "\u001b[32m2025-03-01 21:02:03.410\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthetic_data.generation\u001b[0m:\u001b[36mgenerate\u001b[0m:\u001b[36m177\u001b[0m - \u001b[1mGenerating 1 requests with gpt-4o-mini, max RPS: 83.33333333333333\u001b[0m\n",
      "\u001b[32m2025-03-01 21:02:03.777\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgyms.twenty_questions.env\u001b[0m:\u001b[36mstep\u001b[0m:\u001b[36m166\u001b[0m - \u001b[1mResponse: Oracle: \u001b[0m\n",
      "\u001b[32m2025-03-01 21:02:03.777\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgyms.twenty_questions.env\u001b[0m:\u001b[36mstep\u001b[0m:\u001b[36m179\u001b[0m - \u001b[1mOutput: Oracle: \u001b[0m\n",
      "\u001b[32m2025-03-01 21:02:03.778\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthetic_data.generation\u001b[0m:\u001b[36mgenerate\u001b[0m:\u001b[36m177\u001b[0m - \u001b[1mGenerating 1 requests with gpt-4o-mini, max RPS: 83.33333333333333\u001b[0m\n",
      "\u001b[32m2025-03-01 21:02:04.135\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgyms.twenty_questions.env\u001b[0m:\u001b[36mstep\u001b[0m:\u001b[36m166\u001b[0m - \u001b[1mResponse: Guesser: \u001b[0m\n",
      "\u001b[32m2025-03-01 21:02:04.136\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgyms.twenty_questions.env\u001b[0m:\u001b[36mstep\u001b[0m:\u001b[36m179\u001b[0m - \u001b[1mOutput: Guesser: \u001b[0m\n",
      "\u001b[32m2025-03-01 21:02:04.137\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthetic_data.generation\u001b[0m:\u001b[36mgenerate\u001b[0m:\u001b[36m177\u001b[0m - \u001b[1mGenerating 1 requests with gpt-4o-mini, max RPS: 83.33333333333333\u001b[0m\n",
      "\u001b[32m2025-03-01 21:02:04.865\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgyms.twenty_questions.env\u001b[0m:\u001b[36mstep\u001b[0m:\u001b[36m166\u001b[0m - \u001b[1mResponse: Oracle: \u001b[0m\n",
      "\u001b[32m2025-03-01 21:02:04.866\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgyms.twenty_questions.env\u001b[0m:\u001b[36mstep\u001b[0m:\u001b[36m179\u001b[0m - \u001b[1mOutput: Oracle: \u001b[0m\n",
      "\u001b[32m2025-03-01 21:02:04.867\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthetic_data.generation\u001b[0m:\u001b[36mgenerate\u001b[0m:\u001b[36m177\u001b[0m - \u001b[1mGenerating 1 requests with gpt-4o-mini, max RPS: 83.33333333333333\u001b[0m\n"
     ]
    },
    {
     "ename": "CancelledError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCancelledError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done:\n\u001b[0;32m----> 4\u001b[0m     done, reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m env\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/Documents/GitHub/smolmodels/notebooks/../gyms/twenty_questions/env.py:165\u001b[0m, in \u001b[0;36mTwentyQuestionsPolicyEnvironment.step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    157\u001b[0m query_conv: Conversation \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    158\u001b[0m     _conv_template_guesser(\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconversation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_conversation_length \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_count\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m _conv_template_oracle(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurr_word, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconversation)\n\u001b[1;32m    163\u001b[0m )\n\u001b[1;32m    164\u001b[0m \u001b[38;5;66;03m# logger.info(pprint(query_conv))\u001b[39;00m\n\u001b[0;32m--> 165\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerator\u001b[38;5;241m.\u001b[39mgenerate([query_conv])\n\u001b[1;32m    166\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResponse: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_role \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moracle\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/Documents/GitHub/smolmodels/notebooks/../synthetic_data/generation.py:180\u001b[0m, in \u001b[0;36mOpenAIGenerationWrapper.generate\u001b[0;34m(self, conversations)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    177\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m    178\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerating \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(completion_requests)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requests with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, max RPS: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mmax_rps\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    179\u001b[0m     )\n\u001b[0;32m--> 180\u001b[0m     results: List[ChatCompletion] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mgather(\n\u001b[1;32m    181\u001b[0m         \u001b[38;5;241m*\u001b[39mcompletion_requests\n\u001b[1;32m    182\u001b[0m     )\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m results:\n\u001b[1;32m    184\u001b[0m         logger\u001b[38;5;241m.\u001b[39merror(results)\n",
      "File \u001b[0;32m~/Documents/GitHub/smolmodels/.venv/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py:1927\u001b[0m, in \u001b[0;36mAsyncCompletions.create\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m   1885\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m   1886\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m   1887\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1924\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m   1925\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m AsyncStream[ChatCompletionChunk]:\n\u001b[1;32m   1926\u001b[0m     validate_response_format(response_format)\n\u001b[0;32m-> 1927\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post(\n\u001b[1;32m   1928\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/chat/completions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1929\u001b[0m         body\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mawait\u001b[39;00m async_maybe_transform(\n\u001b[1;32m   1930\u001b[0m             {\n\u001b[1;32m   1931\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: messages,\n\u001b[1;32m   1932\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model,\n\u001b[1;32m   1933\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio\u001b[39m\u001b[38;5;124m\"\u001b[39m: audio,\n\u001b[1;32m   1934\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrequency_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: frequency_penalty,\n\u001b[1;32m   1935\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction_call\u001b[39m\u001b[38;5;124m\"\u001b[39m: function_call,\n\u001b[1;32m   1936\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunctions\u001b[39m\u001b[38;5;124m\"\u001b[39m: functions,\n\u001b[1;32m   1937\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogit_bias\u001b[39m\u001b[38;5;124m\"\u001b[39m: logit_bias,\n\u001b[1;32m   1938\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: logprobs,\n\u001b[1;32m   1939\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_completion_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_completion_tokens,\n\u001b[1;32m   1940\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_tokens,\n\u001b[1;32m   1941\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[1;32m   1942\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodalities\u001b[39m\u001b[38;5;124m\"\u001b[39m: modalities,\n\u001b[1;32m   1943\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m: n,\n\u001b[1;32m   1944\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparallel_tool_calls\u001b[39m\u001b[38;5;124m\"\u001b[39m: parallel_tool_calls,\n\u001b[1;32m   1945\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m\"\u001b[39m: prediction,\n\u001b[1;32m   1946\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpresence_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: presence_penalty,\n\u001b[1;32m   1947\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreasoning_effort\u001b[39m\u001b[38;5;124m\"\u001b[39m: reasoning_effort,\n\u001b[1;32m   1948\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_format\u001b[39m\u001b[38;5;124m\"\u001b[39m: response_format,\n\u001b[1;32m   1949\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m\"\u001b[39m: seed,\n\u001b[1;32m   1950\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mservice_tier\u001b[39m\u001b[38;5;124m\"\u001b[39m: service_tier,\n\u001b[1;32m   1951\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop\u001b[39m\u001b[38;5;124m\"\u001b[39m: stop,\n\u001b[1;32m   1952\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstore\u001b[39m\u001b[38;5;124m\"\u001b[39m: store,\n\u001b[1;32m   1953\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream,\n\u001b[1;32m   1954\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream_options\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream_options,\n\u001b[1;32m   1955\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: temperature,\n\u001b[1;32m   1956\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_choice\u001b[39m\u001b[38;5;124m\"\u001b[39m: tool_choice,\n\u001b[1;32m   1957\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtools\u001b[39m\u001b[38;5;124m\"\u001b[39m: tools,\n\u001b[1;32m   1958\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_logprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_logprobs,\n\u001b[1;32m   1959\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_p\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_p,\n\u001b[1;32m   1960\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m: user,\n\u001b[1;32m   1961\u001b[0m             },\n\u001b[1;32m   1962\u001b[0m             completion_create_params\u001b[38;5;241m.\u001b[39mCompletionCreateParams,\n\u001b[1;32m   1963\u001b[0m         ),\n\u001b[1;32m   1964\u001b[0m         options\u001b[38;5;241m=\u001b[39mmake_request_options(\n\u001b[1;32m   1965\u001b[0m             extra_headers\u001b[38;5;241m=\u001b[39mextra_headers, extra_query\u001b[38;5;241m=\u001b[39mextra_query, extra_body\u001b[38;5;241m=\u001b[39mextra_body, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[1;32m   1966\u001b[0m         ),\n\u001b[1;32m   1967\u001b[0m         cast_to\u001b[38;5;241m=\u001b[39mChatCompletion,\n\u001b[1;32m   1968\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1969\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mAsyncStream[ChatCompletionChunk],\n\u001b[1;32m   1970\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/GitHub/smolmodels/.venv/lib/python3.11/site-packages/openai/_base_client.py:1856\u001b[0m, in \u001b[0;36mAsyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, files, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1842\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1843\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1844\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1851\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_AsyncStreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1852\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _AsyncStreamT:\n\u001b[1;32m   1853\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1854\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mawait\u001b[39;00m async_to_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1855\u001b[0m     )\n\u001b[0;32m-> 1856\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(cast_to, opts, stream\u001b[38;5;241m=\u001b[39mstream, stream_cls\u001b[38;5;241m=\u001b[39mstream_cls)\n",
      "File \u001b[0;32m~/Documents/GitHub/smolmodels/.venv/lib/python3.11/site-packages/openai/_base_client.py:1550\u001b[0m, in \u001b[0;36mAsyncAPIClient.request\u001b[0;34m(self, cast_to, options, stream, stream_cls, remaining_retries)\u001b[0m\n\u001b[1;32m   1547\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1548\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1550\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[1;32m   1551\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1552\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   1553\u001b[0m     stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[1;32m   1554\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[1;32m   1555\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[1;32m   1556\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/GitHub/smolmodels/.venv/lib/python3.11/site-packages/openai/_base_client.py:1589\u001b[0m, in \u001b[0;36mAsyncAPIClient._request\u001b[0;34m(self, cast_to, options, stream, stream_cls, retries_taken)\u001b[0m\n\u001b[1;32m   1586\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauth\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcustom_auth\n\u001b[1;32m   1588\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1589\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39msend(\n\u001b[1;32m   1590\u001b[0m         request,\n\u001b[1;32m   1591\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_stream_response_body(request\u001b[38;5;241m=\u001b[39mrequest),\n\u001b[1;32m   1592\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   1593\u001b[0m     )\n\u001b[1;32m   1594\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m   1595\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered httpx.TimeoutException\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Documents/GitHub/smolmodels/.venv/lib/python3.11/site-packages/httpx/_client.py:1629\u001b[0m, in \u001b[0;36mAsyncClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m   1625\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_timeout(request)\n\u001b[1;32m   1627\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m-> 1629\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_handling_auth(\n\u001b[1;32m   1630\u001b[0m     request,\n\u001b[1;32m   1631\u001b[0m     auth\u001b[38;5;241m=\u001b[39mauth,\n\u001b[1;32m   1632\u001b[0m     follow_redirects\u001b[38;5;241m=\u001b[39mfollow_redirects,\n\u001b[1;32m   1633\u001b[0m     history\u001b[38;5;241m=\u001b[39m[],\n\u001b[1;32m   1634\u001b[0m )\n\u001b[1;32m   1635\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1636\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[0;32m~/Documents/GitHub/smolmodels/.venv/lib/python3.11/site-packages/httpx/_client.py:1657\u001b[0m, in \u001b[0;36mAsyncClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m   1654\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m auth_flow\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__anext__\u001b[39m()\n\u001b[1;32m   1656\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1657\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_handling_redirects(\n\u001b[1;32m   1658\u001b[0m         request,\n\u001b[1;32m   1659\u001b[0m         follow_redirects\u001b[38;5;241m=\u001b[39mfollow_redirects,\n\u001b[1;32m   1660\u001b[0m         history\u001b[38;5;241m=\u001b[39mhistory,\n\u001b[1;32m   1661\u001b[0m     )\n\u001b[1;32m   1662\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1663\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/GitHub/smolmodels/.venv/lib/python3.11/site-packages/httpx/_client.py:1694\u001b[0m, in \u001b[0;36mAsyncClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m   1691\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m   1692\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m hook(request)\n\u001b[0;32m-> 1694\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_single_request(request)\n\u001b[1;32m   1695\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1696\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/Documents/GitHub/smolmodels/.venv/lib/python3.11/site-packages/httpx/_client.py:1730\u001b[0m, in \u001b[0;36mAsyncClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1725\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1726\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an sync request with an AsyncClient instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1727\u001b[0m     )\n\u001b[1;32m   1729\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[0;32m-> 1730\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m transport\u001b[38;5;241m.\u001b[39mhandle_async_request(request)\n\u001b[1;32m   1732\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, AsyncByteStream)\n\u001b[1;32m   1733\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[0;32m~/Documents/GitHub/smolmodels/.venv/lib/python3.11/site-packages/httpx/_transports/default.py:394\u001b[0m, in \u001b[0;36mAsyncHTTPTransport.handle_async_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    381\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m    382\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    383\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    391\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    392\u001b[0m )\n\u001b[1;32m    393\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 394\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool\u001b[38;5;241m.\u001b[39mhandle_async_request(req)\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mAsyncIterable)\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[1;32m    399\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[1;32m    400\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    401\u001b[0m     stream\u001b[38;5;241m=\u001b[39mAsyncResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[1;32m    402\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    403\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/GitHub/smolmodels/.venv/lib/python3.11/site-packages/httpcore/_async/connection_pool.py:256\u001b[0m, in \u001b[0;36mAsyncConnectionPool.handle_async_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    253\u001b[0m         closing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_requests_to_connections()\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 256\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mAsyncIterable)\n",
      "File \u001b[0;32m~/Documents/GitHub/smolmodels/.venv/lib/python3.11/site-packages/httpcore/_async/connection_pool.py:236\u001b[0m, in \u001b[0;36mAsyncConnectionPool.handle_async_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    232\u001b[0m connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m pool_request\u001b[38;5;241m.\u001b[39mwait_for_connection(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 236\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m connection\u001b[38;5;241m.\u001b[39mhandle_async_request(\n\u001b[1;32m    237\u001b[0m         pool_request\u001b[38;5;241m.\u001b[39mrequest\n\u001b[1;32m    238\u001b[0m     )\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[1;32m    244\u001b[0m     pool_request\u001b[38;5;241m.\u001b[39mclear_connection()\n",
      "File \u001b[0;32m~/Documents/GitHub/smolmodels/.venv/lib/python3.11/site-packages/httpcore/_async/connection.py:103\u001b[0m, in \u001b[0;36mAsyncHTTPConnection.handle_async_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39mhandle_async_request(request)\n",
      "File \u001b[0;32m~/Documents/GitHub/smolmodels/.venv/lib/python3.11/site-packages/httpcore/_async/http11.py:136\u001b[0m, in \u001b[0;36mAsyncHTTP11Connection.handle_async_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    135\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[0;32m--> 136\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/Documents/GitHub/smolmodels/.venv/lib/python3.11/site-packages/httpcore/_async/http11.py:106\u001b[0m, in \u001b[0;36mAsyncHTTP11Connection.handle_async_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m     99\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    100\u001b[0m     (\n\u001b[1;32m    101\u001b[0m         http_version,\n\u001b[1;32m    102\u001b[0m         status,\n\u001b[1;32m    103\u001b[0m         reason_phrase,\n\u001b[1;32m    104\u001b[0m         headers,\n\u001b[1;32m    105\u001b[0m         trailing_data,\n\u001b[0;32m--> 106\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_receive_response_headers(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    107\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    108\u001b[0m         http_version,\n\u001b[1;32m    109\u001b[0m         status,\n\u001b[1;32m    110\u001b[0m         reason_phrase,\n\u001b[1;32m    111\u001b[0m         headers,\n\u001b[1;32m    112\u001b[0m     )\n\u001b[1;32m    114\u001b[0m network_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\n",
      "File \u001b[0;32m~/Documents/GitHub/smolmodels/.venv/lib/python3.11/site-packages/httpcore/_async/http11.py:177\u001b[0m, in \u001b[0;36mAsyncHTTP11Connection._receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    174\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 177\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_receive_event(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[1;32m    179\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GitHub/smolmodels/.venv/lib/python3.11/site-packages/httpcore/_async/http11.py:217\u001b[0m, in \u001b[0;36mAsyncHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    214\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 217\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\u001b[38;5;241m.\u001b[39mread(\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mREAD_NUM_BYTES, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[1;32m    219\u001b[0m     )\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[0;32m~/Documents/GitHub/smolmodels/.venv/lib/python3.11/site-packages/httpcore/_backends/anyio.py:35\u001b[0m, in \u001b[0;36mAnyIOStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m anyio\u001b[38;5;241m.\u001b[39mfail_after(timeout):\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 35\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stream\u001b[38;5;241m.\u001b[39mreceive(max_bytes\u001b[38;5;241m=\u001b[39mmax_bytes)\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m anyio\u001b[38;5;241m.\u001b[39mEndOfStream:  \u001b[38;5;66;03m# pragma: nocover\u001b[39;00m\n\u001b[1;32m     37\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/Documents/GitHub/smolmodels/.venv/lib/python3.11/site-packages/anyio/streams/tls.py:204\u001b[0m, in \u001b[0;36mTLSStream.receive\u001b[0;34m(self, max_bytes)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mreceive\u001b[39m(\u001b[38;5;28mself\u001b[39m, max_bytes: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m65536\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbytes\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_sslobject_method(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ssl_object\u001b[38;5;241m.\u001b[39mread, max_bytes)\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n\u001b[1;32m    206\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m EndOfStream\n",
      "File \u001b[0;32m~/Documents/GitHub/smolmodels/.venv/lib/python3.11/site-packages/anyio/streams/tls.py:147\u001b[0m, in \u001b[0;36mTLSStream._call_sslobject_method\u001b[0;34m(self, func, *args)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_write_bio\u001b[38;5;241m.\u001b[39mpending:\n\u001b[1;32m    145\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransport_stream\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_write_bio\u001b[38;5;241m.\u001b[39mread())\n\u001b[0;32m--> 147\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransport_stream\u001b[38;5;241m.\u001b[39mreceive()\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m EndOfStream:\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_bio\u001b[38;5;241m.\u001b[39mwrite_eof()\n",
      "File \u001b[0;32m~/Documents/GitHub/smolmodels/.venv/lib/python3.11/site-packages/anyio/_backends/_asyncio.py:1246\u001b[0m, in \u001b[0;36mSocketStream.receive\u001b[0;34m(self, max_bytes)\u001b[0m\n\u001b[1;32m   1240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1241\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_protocol\u001b[38;5;241m.\u001b[39mread_event\u001b[38;5;241m.\u001b[39mis_set()\n\u001b[1;32m   1242\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transport\u001b[38;5;241m.\u001b[39mis_closing()\n\u001b[1;32m   1243\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_protocol\u001b[38;5;241m.\u001b[39mis_at_eof\n\u001b[1;32m   1244\u001b[0m ):\n\u001b[1;32m   1245\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transport\u001b[38;5;241m.\u001b[39mresume_reading()\n\u001b[0;32m-> 1246\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_protocol\u001b[38;5;241m.\u001b[39mread_event\u001b[38;5;241m.\u001b[39mwait()\n\u001b[1;32m   1247\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transport\u001b[38;5;241m.\u001b[39mpause_reading()\n\u001b[1;32m   1248\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/share/uv/python/cpython-3.11.11-macos-aarch64-none/lib/python3.11/asyncio/locks.py:213\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_waiters\u001b[38;5;241m.\u001b[39mappend(fut)\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 213\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m fut\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[0;31mCancelledError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "done = False\n",
    "while not done:\n",
    "    done, reward = await env.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

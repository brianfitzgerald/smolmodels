{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from trl_wrapper.trainer_wrapper import TrainerWrapper, CONNECTIONS_CONFIG, QWEN_1_5_B\n",
    "\n",
    "cfg = CONNECTIONS_CONFIG\n",
    "cfg.train_batch_size = 2\n",
    "cfg.num_generations = 2\n",
    "cfg.model_id_or_path = QWEN_1_5_B\n",
    "cfg.notebook_mode = True\n",
    "cfg.max_samples = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-12 09:40:17.456\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtrl_wrapper.trainer_wrapper\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m285\u001b[0m - \u001b[1mSetting padding side to: left\u001b[0m\n",
      "\u001b[32m2025-04-12 09:40:17.456\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtrl_wrapper.trainer_wrapper\u001b[0m:\u001b[36minit_model\u001b[0m:\u001b[36m296\u001b[0m - \u001b[1mUsing device: mps\u001b[0m\n",
      "\u001b[32m2025-04-12 09:40:17.457\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtrl_wrapper.trainer_wrapper\u001b[0m:\u001b[36minit_model\u001b[0m:\u001b[36m310\u001b[0m - \u001b[1mLoading model Qwen/Qwen2.5-1.5B-Instruct with attn_impl: sdpa\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "wrapper = TrainerWrapper(cfg)\n",
    "wrapper.init_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.reasoning import ConnectionsDataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-12 09:40:22.095\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtrl_wrapper.wrapper_config\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m145\u001b[0m - \u001b[1mCache dir: ../dataset_caches/connections_data_module\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "conn = ConnectionsDataModule(wrapper.tokenizer, wrapper.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-12 09:40:22.148\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtrl_wrapper.wrapper_config\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m145\u001b[0m - \u001b[1mCache dir: ../dataset_caches/connections_data_module\u001b[0m\n",
      "Map: 100%|██████████| 100000/100000 [00:07<00:00, 12690.86 examples/s]\n"
     ]
    }
   ],
   "source": [
    "wrapper.init_data_module()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-12 09:41:16.580\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtrl_wrapper.trainer_wrapper\u001b[0m:\u001b[36minit_trainer\u001b[0m:\u001b[36m373\u001b[0m - \u001b[1mSaving output to: ./runs/04-12-9-41-741094-qwen2.5-1.5b-instruct-\u001b[0m\n",
      "\u001b[32m2025-04-12 09:41:16.582\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtrl_wrapper.trainer_wrapper\u001b[0m:\u001b[36minit_trainer\u001b[0m:\u001b[36m396\u001b[0m - \u001b[1mInitializing trainer, run_name: 04-12-9-41-741094-qwen2.5-1.5b-instruct-, wandb project: qwen-connections-grpo\u001b[0m\n",
      "\u001b[32m2025-04-12 09:41:16.582\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtrl_wrapper.trainer_wrapper\u001b[0m:\u001b[36minit_trainer\u001b[0m:\u001b[36m479\u001b[0m - \u001b[1mUsing vllm: False\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "wrapper.init_trainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-12 09:41:16.688\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtrl_wrapper.trainer_wrapper\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m644\u001b[0m - \u001b[1mStarting training.\u001b[0m\n",
      "/Users/brianfitzgerald/Documents/GitHub/smolmodels/.venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "\u001b[32m2025-04-12 09:42:01.576\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmodel.reasoning\u001b[0m:\u001b[36mxmlcount_reward_func\u001b[0m:\u001b[36m59\u001b[0m - \u001b[1mXML count rewards: [-0.09699999999999998, 0.11299999999999999]\u001b[0m\n",
      "\u001b[32m2025-04-12 09:42:01.576\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmodel.reasoning\u001b[0m:\u001b[36mstrict_format_reward_func\u001b[0m:\u001b[36m105\u001b[0m - \u001b[1mStrict format rewards: [0.25, 0.25]\u001b[0m\n",
      "\u001b[32m2025-04-12 09:42:01.577\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmodel.reasoning\u001b[0m:\u001b[36msoft_group_reward\u001b[0m:\u001b[36m203\u001b[0m - \u001b[1mSoft accuracy scores: [0.375, 0.5]\u001b[0m\n",
      "\u001b[32m2025-04-12 09:42:01.577\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmodel.reasoning\u001b[0m:\u001b[36mgroup_size_reward\u001b[0m:\u001b[36m249\u001b[0m - \u001b[1mGroup size rewards: [0.25, 1.0]\u001b[0m\n",
      "\u001b[32m2025-04-12 09:42:01.578\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmodel.reasoning\u001b[0m:\u001b[36mhard_group_reward\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1mHard accuracy scores: [0.25, 0.0]\u001b[0m\n",
      "\u001b[32m2025-04-12 09:42:01.578\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmodel.reasoning\u001b[0m:\u001b[36mn_groups_reward\u001b[0m:\u001b[36m260\u001b[0m - \u001b[1mNumber of groups rewards: [0.0, 0.25]\u001b[0m\n",
      "\u001b[32m2025-04-12 09:42:01.579\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmodel.reasoning\u001b[0m:\u001b[36mlogger_reward\u001b[0m:\u001b[36m223\u001b[0m - \u001b[1mGenerations:\u001b[0m\n",
      "\u001b[32m2025-04-12 09:42:01.579\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmodel.reasoning\u001b[0m:\u001b[36mlogger_reward\u001b[0m:\u001b[36m225\u001b[0m - \u001b[1m========================================\u001b[0m\n",
      "\u001b[32m2025-04-12 09:42:01.579\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmodel.reasoning\u001b[0m:\u001b[36mlogger_reward\u001b[0m:\u001b[36m226\u001b[0m - \u001b[1mPrompt: --------------------\u001b[0m\n",
      "\u001b[32m2025-04-12 09:42:01.579\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmodel.reasoning\u001b[0m:\u001b[36mlogger_reward\u001b[0m:\u001b[36m227\u001b[0m - \u001b[1mcosmetic, external, shallow, surface, buffalo, deer, fish, moose, brave, confront, face, meet, cat, cow, mountain, triangle\u001b[0m\n",
      "\u001b[32m2025-04-12 09:42:01.579\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmodel.reasoning\u001b[0m:\u001b[36mlogger_reward\u001b[0m:\u001b[36m228\u001b[0m - \u001b[1mGeneration: --------------------\u001b[0m\n",
      "\u001b[32m2025-04-12 09:42:01.580\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmodel.reasoning\u001b[0m:\u001b[36mlogger_reward\u001b[0m:\u001b[36m229\u001b[0m - \u001b[1m<reasoning>\n",
      "Let's start by grouping the words based on their meanings. \"Buffalo,\" \"deer,\" \"fish,\" and \"moose\" are all animals, so they could be grouped together. \"Face,\" \"meet,\" and \"confront\" are related to interactions between people, so they could be grouped together. \"Cosmetic\" and \"external\" are related to the appearance of things, so they could be grouped together. \"Triangle\" and \"surface\" are related to shapes and surfaces, so they could be grouped together. \"Mountain\" and \"cow\" are related to geographical features, so they could be grouped together. \"Brave\" and \"cat\" are related to courage and animals, so they could be grouped together. \"Surface\" and \"face\" are related to the appearance of things, so they could be grouped together. \"Shallow\" and \"external\" are related to the depth and appearance of things, so they could be grouped together. \"Triangle\" and \"face\" are related to shapes and appearances, so they could be grouped together.\n",
      "\n",
      "</reasoning>\n",
      "<answer>\n",
      "<group> buffalo, deer, fish, moose </group>\n",
      "<group> face, meet, confront, brave </group>\n",
      "<group> cosmetic, external </group>\n",
      "<group> triangle, surface </group>\n",
      "<group> mountain, cow </group>\n",
      "<group> surface, face </group>\n",
      "<group> shallow, external </group>\n",
      "<group> triangle, face </group>\n",
      "</answer>\u001b[0m\n",
      "\u001b[32m2025-04-12 09:42:01.580\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmodel.reasoning\u001b[0m:\u001b[36mlogger_reward\u001b[0m:\u001b[36m230\u001b[0m - \u001b[1mAnswer: --------------------\u001b[0m\n",
      "\u001b[32m2025-04-12 09:42:01.580\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmodel.reasoning\u001b[0m:\u001b[36mlogger_reward\u001b[0m:\u001b[36m231\u001b[0m - \u001b[1m<answer><group>cosmetic, external, shallow, surface</group>\n",
      "<group>buffalo, deer, fish, moose</group>\n",
      "<group>brave, confront, face, meet</group>\n",
      "<group>cat, cow, mountain, triangle</group></answer>\u001b[0m\n",
      "\u001b[32m2025-04-12 09:42:01.580\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmodel.reasoning\u001b[0m:\u001b[36mlogger_reward\u001b[0m:\u001b[36m225\u001b[0m - \u001b[1m========================================\u001b[0m\n",
      "\u001b[32m2025-04-12 09:42:01.580\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmodel.reasoning\u001b[0m:\u001b[36mlogger_reward\u001b[0m:\u001b[36m226\u001b[0m - \u001b[1mPrompt: --------------------\u001b[0m\n",
      "\u001b[32m2025-04-12 09:42:01.580\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmodel.reasoning\u001b[0m:\u001b[36mlogger_reward\u001b[0m:\u001b[36m227\u001b[0m - \u001b[1mcosmetic, external, shallow, surface, buffalo, deer, fish, moose, brave, confront, face, meet, cat, cow, mountain, triangle\u001b[0m\n",
      "\u001b[32m2025-04-12 09:42:01.580\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmodel.reasoning\u001b[0m:\u001b[36mlogger_reward\u001b[0m:\u001b[36m228\u001b[0m - \u001b[1mGeneration: --------------------\u001b[0m\n",
      "\u001b[32m2025-04-12 09:42:01.581\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmodel.reasoning\u001b[0m:\u001b[36mlogger_reward\u001b[0m:\u001b[36m229\u001b[0m - \u001b[1m<reasoning>\n",
      "Alright, I'm looking for four groups of related words. Let's start with the words: cosmetic, external, shallow, surface, buffalo, deer, fish, moose, brave, confront, face, meet, cat, cow, mountain, triangle.\n",
      "First, I notice that \"face\" and \"brave\" seem to be related to \"personality\" or \"character.\" So, I'll start with that: \"face\" and \"brave\" are related.\n",
      "\n",
      "Next, \"cow\" and \"deer\" seem to be related to \"animals\" or \"beasts.\" So, I'll add \"cow\" and \"deer\" to the group.\n",
      "\n",
      "\"Buffalo\" and \"moose\" seem to be related to \"animals\" or \"beasts.\" So, I'll add \"buffalo\" and \"moose\" to the group.\n",
      "\n",
      "\"Triangle\" and \"surface\" seem to be related to \"shape\" or \"form.\" So, I'll add \"triangle\" and \"surface\" to the group.\n",
      "\n",
      "\"Confront\" and \"meet\" seem to be related to \"interaction\" or \"contact.\" So, I'll add \"confront\" and \"meet\" to the group.\n",
      "\n",
      "\"Surface\" and \"external\" seem to be related to \"location\" or \"position.\" So, I'll add \"surface\" and \"external\" to the group.\n",
      "\n",
      "\"Shallow\" and \"external\" seem to be related to \"depth\" or \"level.\" So, I'll add \"shallow\" and \"external\" to the group.\n",
      "\n",
      "\"Mountain\" and \"cow\" seem to be related to \"location\" or \"position.\" So, I'll add \"mountain\" and \"cow\" to the group.\n",
      "\n",
      "\"Cat\" and \"external\" seem to be related to \"location\" or \"position.\" So, I'll add \"cat\" and \"external\" to the group.\n",
      "\n",
      "</reasoning>\n",
      "<answer>\n",
      "<group>face, brave, cow, deer</group>\n",
      "<group>buffalo, moose, triangle, surface</group>\n",
      "<group>confront, meet, external, surface</group>\n",
      "<group>shallow, external, mountain, cow</group>\n",
      "</answer>\u001b[0m\n",
      "\u001b[32m2025-04-12 09:42:01.581\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmodel.reasoning\u001b[0m:\u001b[36mlogger_reward\u001b[0m:\u001b[36m230\u001b[0m - \u001b[1mAnswer: --------------------\u001b[0m\n",
      "\u001b[32m2025-04-12 09:42:01.581\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmodel.reasoning\u001b[0m:\u001b[36mlogger_reward\u001b[0m:\u001b[36m231\u001b[0m - \u001b[1m<answer><group>cosmetic, external, shallow, surface</group>\n",
      "<group>buffalo, deer, fish, moose</group>\n",
      "<group>brave, confront, face, meet</group>\n",
      "<group>cat, cow, mountain, triangle</group></answer>\u001b[0m\n",
      "\u001b[32m2025-04-12 09:42:41.240\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmodel.reasoning\u001b[0m:\u001b[36mxmlcount_reward_func\u001b[0m:\u001b[36m59\u001b[0m - \u001b[1mXML count rewards: [0.137, 0.121]\u001b[0m\n",
      "\u001b[32m2025-04-12 09:42:41.242\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmodel.reasoning\u001b[0m:\u001b[36mstrict_format_reward_func\u001b[0m:\u001b[36m105\u001b[0m - \u001b[1mStrict format rewards: [0.25, 0.25]\u001b[0m\n",
      "\u001b[32m2025-04-12 09:42:41.243\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmodel.reasoning\u001b[0m:\u001b[36msoft_group_reward\u001b[0m:\u001b[36m203\u001b[0m - \u001b[1mSoft accuracy scores: [0.9375, 0.9375]\u001b[0m\n",
      "\u001b[32m2025-04-12 09:42:41.244\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmodel.reasoning\u001b[0m:\u001b[36mgroup_size_reward\u001b[0m:\u001b[36m249\u001b[0m - \u001b[1mGroup size rewards: [0.75, 0.5]\u001b[0m\n",
      "\u001b[32m2025-04-12 09:42:41.244\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmodel.reasoning\u001b[0m:\u001b[36mhard_group_reward\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1mHard accuracy scores: [0.75, 0.5]\u001b[0m\n",
      "\u001b[32m2025-04-12 09:42:41.245\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmodel.reasoning\u001b[0m:\u001b[36mn_groups_reward\u001b[0m:\u001b[36m260\u001b[0m - \u001b[1mNumber of groups rewards: [0.25, 0.25]\u001b[0m\n",
      "\u001b[32m2025-04-12 09:42:41.245\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmodel.reasoning\u001b[0m:\u001b[36mlogger_reward\u001b[0m:\u001b[36m223\u001b[0m - \u001b[1mGenerations:\u001b[0m\n",
      "\u001b[32m2025-04-12 09:42:41.245\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmodel.reasoning\u001b[0m:\u001b[36mlogger_reward\u001b[0m:\u001b[36m225\u001b[0m - \u001b[1m========================================\u001b[0m\n",
      "\u001b[32m2025-04-12 09:42:41.245\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmodel.reasoning\u001b[0m:\u001b[36mlogger_reward\u001b[0m:\u001b[36m226\u001b[0m - \u001b[1mPrompt: --------------------\u001b[0m\n",
      "\u001b[32m2025-04-12 09:42:41.246\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmodel.reasoning\u001b[0m:\u001b[36mlogger_reward\u001b[0m:\u001b[36m227\u001b[0m - \u001b[1mbill, invoice, receipt, statement, banner, prince, stark, wayne, ditto, likewise, same, second, ear, mar, mer, sat\u001b[0m\n",
      "\u001b[32m2025-04-12 09:42:41.246\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmodel.reasoning\u001b[0m:\u001b[36mlogger_reward\u001b[0m:\u001b[36m228\u001b[0m - \u001b[1mGeneration: --------------------\u001b[0m\n",
      "\u001b[32m2025-04-12 09:42:41.246\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmodel.reasoning\u001b[0m:\u001b[36mlogger_reward\u001b[0m:\u001b[36m229\u001b[0m - \u001b[1m<reasoning>\n",
      "Let's break down the words into groups based on their meanings and common associations.\n",
      "\n",
      "1. **Bill, Invoice, Receipt, Statement, Banner**: These words are related to financial transactions and documents. They all involve the concept of a document or record of a financial transaction. They can be grouped together as \"financial documents.\"\n",
      "\n",
      "2. **Prince, Stark, Wayne**: These are names of characters from the fictional universe of the Game of Thrones series. They are not related to financial transactions or documents, so they can be grouped together as \"characters from Game of Thrones.\"\n",
      "\n",
      "3. **Ditto, Likewise, Same, Second**: These words are related to repetition or similarity. They can be grouped together as \"repetition or similarity.\"\n",
      "\n",
      "4. **Ear, Mar, Mer, Sat**: These words are related to the concept of \"second\" or \"second place\" in a competition or race. They can be grouped together as \"second place.\"\n",
      "\n",
      "</reasoning>\n",
      "<answer>\n",
      "<group>\n",
      "bill, invoice, receipt, statement\n",
      "</group>\n",
      "<group>\n",
      "prince, stark, wayne\n",
      "</group>\n",
      "<group>\n",
      "ditto, likewise, same, second\n",
      "</group>\n",
      "<group>\n",
      "ear, mar, mer, sat\n",
      "</group>\n",
      "</answer>\u001b[0m\n",
      "\u001b[32m2025-04-12 09:42:41.246\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmodel.reasoning\u001b[0m:\u001b[36mlogger_reward\u001b[0m:\u001b[36m230\u001b[0m - \u001b[1mAnswer: --------------------\u001b[0m\n",
      "\u001b[32m2025-04-12 09:42:41.246\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmodel.reasoning\u001b[0m:\u001b[36mlogger_reward\u001b[0m:\u001b[36m231\u001b[0m - \u001b[1m<answer><group>bill, invoice, receipt, statement</group>\n",
      "<group>banner, prince, stark, wayne</group>\n",
      "<group>ditto, likewise, same, second</group>\n",
      "<group>ear, mar, mer, sat</group></answer>\u001b[0m\n",
      "\u001b[32m2025-04-12 09:42:41.246\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmodel.reasoning\u001b[0m:\u001b[36mlogger_reward\u001b[0m:\u001b[36m225\u001b[0m - \u001b[1m========================================\u001b[0m\n",
      "\u001b[32m2025-04-12 09:42:41.246\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmodel.reasoning\u001b[0m:\u001b[36mlogger_reward\u001b[0m:\u001b[36m226\u001b[0m - \u001b[1mPrompt: --------------------\u001b[0m\n",
      "\u001b[32m2025-04-12 09:42:41.247\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmodel.reasoning\u001b[0m:\u001b[36mlogger_reward\u001b[0m:\u001b[36m227\u001b[0m - \u001b[1mbill, invoice, receipt, statement, banner, prince, stark, wayne, ditto, likewise, same, second, ear, mar, mer, sat\u001b[0m\n",
      "\u001b[32m2025-04-12 09:42:41.247\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmodel.reasoning\u001b[0m:\u001b[36mlogger_reward\u001b[0m:\u001b[36m228\u001b[0m - \u001b[1mGeneration: --------------------\u001b[0m\n",
      "\u001b[32m2025-04-12 09:42:41.247\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmodel.reasoning\u001b[0m:\u001b[36mlogger_reward\u001b[0m:\u001b[36m229\u001b[0m - \u001b[1m<reasoning>\n",
      "Let's analyze the words and try to group them into four groups based on their meanings and usage.\n",
      "\n",
      "1. \"bill\", \"invoice\", \"receipt\", \"statement\" - These words are all related to financial documents and records. They are used to track and record financial transactions.\n",
      "2. \"banner\", \"prince\", \"stark\", \"wayne\" - These words are all names of fictional characters from the Marvel Comics. They are all associated with the superhero character \"Iron Man\".\n",
      "3. \"ditto\", \"likewise\", \"same\" - These words are used to indicate agreement or similarity in a statement.\n",
      "4. \"second\", \"ear\", \"mar\", \"mer\", \"sat\" - These words are all related to the number two or the ear. They can be grouped based on their numerical and biological meanings.\n",
      "\n",
      "</reasoning>\n",
      "<answer>\n",
      "<group>\n",
      "bill, invoice, receipt, statement\n",
      "</group>\n",
      "<group>\n",
      "banner, prince, stark, wayne\n",
      "</group>\n",
      "<group>\n",
      "ditto, likewise, same\n",
      "</group>\n",
      "<group>\n",
      "second, ear, mar, mer, sat\n",
      "</group>\n",
      "</answer>\u001b[0m\n",
      "\u001b[32m2025-04-12 09:42:41.247\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmodel.reasoning\u001b[0m:\u001b[36mlogger_reward\u001b[0m:\u001b[36m230\u001b[0m - \u001b[1mAnswer: --------------------\u001b[0m\n",
      "\u001b[32m2025-04-12 09:42:41.248\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmodel.reasoning\u001b[0m:\u001b[36mlogger_reward\u001b[0m:\u001b[36m231\u001b[0m - \u001b[1m<answer><group>bill, invoice, receipt, statement</group>\n",
      "<group>banner, prince, stark, wayne</group>\n",
      "<group>ditto, likewise, same, second</group>\n",
      "<group>ear, mar, mer, sat</group></answer>\u001b[0m\n",
      "\u001b[32m2025-04-12 09:43:42.675\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmodel.reasoning\u001b[0m:\u001b[36mxmlcount_reward_func\u001b[0m:\u001b[36m59\u001b[0m - \u001b[1mXML count rewards: [-0.02100000000000002, 0.125]\u001b[0m\n",
      "\u001b[32m2025-04-12 09:43:42.677\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmodel.reasoning\u001b[0m:\u001b[36mstrict_format_reward_func\u001b[0m:\u001b[36m105\u001b[0m - \u001b[1mStrict format rewards: [0.0, 0.0]\u001b[0m\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mwrapper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/smolmodels/notebooks/../trl_wrapper/trainer_wrapper.py:645\u001b[0m, in \u001b[0;36mTrainerWrapper.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    643\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtrain\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    644\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting training.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 645\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/smolmodels/.venv/lib/python3.11/site-packages/transformers/trainer.py:2245\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2243\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2244\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2245\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2246\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2250\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/smolmodels/.venv/lib/python3.11/site-packages/transformers/trainer.py:2560\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2553\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2554\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[1;32m   2555\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2556\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m!=\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED\n\u001b[1;32m   2557\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[1;32m   2558\u001b[0m )\n\u001b[1;32m   2559\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[0;32m-> 2560\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2562\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2563\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2564\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2565\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2566\u001b[0m ):\n\u001b[1;32m   2567\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2568\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/Documents/GitHub/smolmodels/.venv/lib/python3.11/site-packages/transformers/trainer.py:3730\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   3727\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mtrain):\n\u001b[1;32m   3728\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m-> 3730\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3731\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_sagemaker_mp_enabled():\n\u001b[1;32m   3732\u001b[0m     loss_mb \u001b[38;5;241m=\u001b[39m smp_forward_backward(model, inputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps)\n",
      "File \u001b[0;32m~/Documents/GitHub/smolmodels/.venv/lib/python3.11/site-packages/trl/extras/profiling.py:87\u001b[0m, in \u001b[0;36mprofiling_decorator.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m profiling_context(\u001b[38;5;28mself\u001b[39m, func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m):\n\u001b[0;32m---> 87\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/smolmodels/.venv/lib/python3.11/site-packages/trl/trainer/grpo_trainer.py:647\u001b[0m, in \u001b[0;36mGRPOTrainer._prepare_inputs\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    645\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    646\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_iterations \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 647\u001b[0m         inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_and_score_completions\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    648\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffered_inputs[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_step \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps] \u001b[38;5;241m=\u001b[39m inputs\n\u001b[1;32m    649\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/GitHub/smolmodels/.venv/lib/python3.11/site-packages/trl/trainer/grpo_trainer.py:799\u001b[0m, in \u001b[0;36mGRPOTrainer._generate_and_score_completions\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    797\u001b[0m keys \u001b[38;5;241m=\u001b[39m [key \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m inputs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompletion\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[1;32m    798\u001b[0m reward_kwargs \u001b[38;5;241m=\u001b[39m {key: [example[key] \u001b[38;5;28;01mfor\u001b[39;00m example \u001b[38;5;129;01min\u001b[39;00m inputs] \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m keys}\n\u001b[0;32m--> 799\u001b[0m output_reward_func \u001b[38;5;241m=\u001b[39m \u001b[43mreward_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mreward_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;66;03m# Convert None values to NaN\u001b[39;00m\n\u001b[1;32m    801\u001b[0m output_reward_func \u001b[38;5;241m=\u001b[39m [reward \u001b[38;5;28;01mif\u001b[39;00m reward \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mnan \u001b[38;5;28;01mfor\u001b[39;00m reward \u001b[38;5;129;01min\u001b[39;00m output_reward_func]\n",
      "File \u001b[0;32m~/Documents/GitHub/smolmodels/notebooks/../model/reasoning.py:199\u001b[0m, in \u001b[0;36msoft_group_reward\u001b[0;34m(prompts, completions, **kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m model_generations \u001b[38;5;241m=\u001b[39m _generations(completions)\n\u001b[1;32m    198\u001b[0m generation_groups \u001b[38;5;241m=\u001b[39m [parse_groups(r) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m model_generations]\n\u001b[0;32m--> 199\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscore_connections_soft\u001b[49m\u001b[43m(\u001b[49m\u001b[43manswers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43manswers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43manswer_groups\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgeneration_groups\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    203\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSoft accuracy scores: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscores\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m scores\n",
      "File \u001b[0;32m~/Documents/GitHub/smolmodels/notebooks/../model/reasoning.py:200\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    197\u001b[0m model_generations \u001b[38;5;241m=\u001b[39m _generations(completions)\n\u001b[1;32m    198\u001b[0m generation_groups \u001b[38;5;241m=\u001b[39m [parse_groups(r) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m model_generations]\n\u001b[1;32m    199\u001b[0m scores \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m--> 200\u001b[0m     \u001b[43mscore_connections_soft\u001b[49m\u001b[43m(\u001b[49m\u001b[43manswers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m answers, groups \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manswer_groups\u001b[39m\u001b[38;5;124m\"\u001b[39m], generation_groups)\n\u001b[1;32m    202\u001b[0m ]\n\u001b[1;32m    203\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSoft accuracy scores: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscores\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m scores\n",
      "File \u001b[0;32m~/Documents/GitHub/smolmodels/notebooks/../model/reasoning.py:188\u001b[0m, in \u001b[0;36mscore_connections_soft\u001b[0;34m(solution_groups, submitted_groups)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     best_match_counts \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(solution_sets)\n\u001b[0;32m--> 188\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbest_match_counts\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msolution_groups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubmitted_groups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "wrapper.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

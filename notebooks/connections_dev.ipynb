{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from trl_wrapper.trainer_wrapper import TrainerWrapper, GRPO_CONNECTIONS_CONFIG, SMOL_LM_135M\n",
    "\n",
    "cfg = GRPO_CONNECTIONS_CONFIG\n",
    "cfg.train_batch_size = 2\n",
    "cfg.num_generations = 2\n",
    "cfg.model_id_or_path = SMOL_LM_135M\n",
    "cfg.notebook_mode = True\n",
    "cfg.max_samples = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapper = TrainerWrapper(cfg)\n",
    "wrapper.init_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.reasoning import ConnectionsDataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = ConnectionsDataModule(wrapper.tokenizer, wrapper.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pandas as pd\n",
    "dataset = pd.read_json(\"../dataset_files/connections_prompts.jsonl\", lines=True)\n",
    "df_groups = pd.json_normalize(dataset['solution'], 'groups')\n",
    "\n",
    "group_list = [\n",
    "    {\n",
    "        \"groups\": (g := df_groups.sample(4, replace=False).reset_index(drop=True)).to_dict(orient=\"records\"),\n",
    "        \"words\": list(itertools.chain.from_iterable(g['words'].dropna()))\n",
    "    }\n",
    "    for _ in range(100000)\n",
    "]\n",
    "\n",
    "out = pd.DataFrame(group_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapper.init_data_module()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapper.init_trainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.reasoning import GSM8K_SYSTEM_PROMPT, CONNECTIONS_PROMPT\n",
    "from model.utils import get_available_device\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": CONNECTIONS_PROMPT},\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"train, panda, dove, series, wind, bear, orca, bass, string, skunk, speed, sand, zebra, tourist, desert, chain\",\n",
    "    },\n",
    "]\n",
    "tokenized_chat = wrapper.tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=True,\n",
    "    add_generation_prompt=True,\n",
    "    return_tensors=\"pt\",\n",
    "    return_attention_mask=True,\n",
    ")\n",
    "\n",
    "device = get_available_device()\n",
    "tokenized_chat = tokenized_chat.to(device)\n",
    "out = wrapper.model.generate(tokenized_chat, max_length=1024)\n",
    "print(wrapper.tokenizer.decode(out[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapper.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

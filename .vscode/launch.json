{
    "version": "0.2.0",
    "configurations": [
        {
            "name": "Train - TRL",
            "type": "debugpy",
            "request": "launch",
            "program": "train_trl.py",
            "justMyCode": false,
            "args": [
                "--config",
                "qwen-math",
                "--notebook_mode"
            ]
        },
        {
            "name": "Evaluate",
            "type": "debugpy",
            "request": "launch",
            "program": "evaluate.py",
        },
        {
            "name": "Generate",
            "type": "debugpy",
            "request": "launch",
            "program": "generate.py",
            "args": [
                "--task_name",
                "gutenberg_backtranslation"
            ],
        },
        {
            "name": "Generate - 20 Qs",
            "type": "debugpy",
            "request": "launch",
            "program": "generate.py",
            "args": [
                "--environment_name",
                "twenty_questions",
                "--n_epochs",
                "20",
                "--batch_size",
                "32"
            ],
        },
        {
            "name": "vLLM Server",
            "type": "debugpy",
            "request": "launch",
            "program": "scripts/run_vllm.py",
            "justMyCode": false,
            "args": [
                "--run",
                "01-09-17-46-208302-llama-3.2-3b-instruct-openo1-composite-1e-5",
                // "--model",
                // "meta-llama/Llama-3.2-3B-Instruct"
            ]
        },
        {
            "name": "llama.cpp Inference",
            "type": "debugpy",
            "request": "launch",
            "program": "gguf_inference.py",
            "justMyCode": false,
        },
        {
            "name": "Gradio UI",
            "type": "debugpy",
            "request": "launch",
            "program": "gradio_ui.py",
            "justMyCode": false,
        },
    ]
}